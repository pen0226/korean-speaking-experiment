"""
save_reference_score.py
TOPIK ì°¸ê³ ìš© ì ìˆ˜ ì €ì¥ ëª¨ë“ˆ (í™€ë¦¬ìŠ¤í‹± ë£¨ë¸Œë¦­ - ì±„ì ì ê°ê° ê¸°ë°˜ + ì´ìœ  ì»¬ëŸ¼ ì¶”ê°€)
"""

import pandas as pd
import os
import re
from datetime import datetime
from config import KST

def calculate_content_task_score_holistic(transcript):
    """
    ë‚´ìš© ë° ê³¼ì œ ìˆ˜í–‰ ì ìˆ˜ ê³„ì‚° (Task Completion Check ë°˜ì˜ - í™€ë¦¬ìŠ¤í‹± ë°©ì‹ 1-5ì  + ì´ìœ )
    
    Args:
        transcript: STT ì „ì‚¬ í…ìŠ¤íŠ¸
        
    Returns:
        tuple: (ì ìˆ˜, ì´ìœ ) - (int, str)
    """
    if not transcript or not transcript.strip():
        return 1, "No meaningful content detected"
    
    # ê³¼ê±° ë°©í•™ ì²´í¬ (ë” ì •í™•í•œ í‚¤ì›Œë“œ)
    past_keywords = ["ì§€ë‚œ", "ì‘ë…„", "ì—¬ë¦„", "ê²¨ìš¸", "ë°©í•™", "íœ´ê°€", "ì—¬í–‰", "ê°”ì–´ìš”", "í–ˆì–´ìš”", "ë¨¹ì—ˆì–´ìš”", "ë´¤ì–´ìš”", "ë†€ì•˜ì–´ìš”"]
    past_mentioned = sum(1 for k in past_keywords if k in transcript)
    
    # ë¯¸ë˜ ê³„íš ì²´í¬ (ë” ì •í™•í•œ í‚¤ì›Œë“œ)
    future_keywords = ["ë‹¤ìŒ", "ë‚´ë…„", "í•  ê±°ì˜ˆìš”", "ê°ˆ ê±°ì˜ˆìš”", "í•˜ë ¤ê³ ", "ê³„íš", "í•˜ê³  ì‹¶ì–´ìš”", "ê°ˆ ì˜ˆì •", "í•  ê³„íš"]
    future_mentioned = sum(1 for k in future_keywords if k in transcript)
    
    # ì´ìœ  ì²´í¬
    reason_keywords = ["ì™œëƒí•˜ë©´", "ë•Œë¬¸ì—", "í•´ì„œ", "ì¢‹ì•„í•´ì„œ", "ì‹¶ì–´ì„œ", "ìœ„í•´ì„œ", "ì¬ë¯¸ìˆì–´ì„œ", "ë°°ìš°ê³  ì‹¶ì–´ì„œ"]
    reason_mentioned = any(k in transcript for k in reason_keywords)
    
    word_count = len(transcript.split())
    sentence_count = len([s for s in transcript.split('.') if s.strip()])
    
    # ğŸ†• ë‘ ì£¼ì œ ëª¨ë‘ ë‹¤ë¤˜ëŠ”ì§€ ëª…í™•íˆ ì²´í¬
    both_topics = past_mentioned >= 2 and future_mentioned >= 2
    one_topic_only = (past_mentioned >= 2 and future_mentioned < 2) or (past_mentioned < 2 and future_mentioned >= 2)
    
    # í™€ë¦¬ìŠ¤í‹± í‰ê°€ (Task Completion ì¤‘ì‹¬)
    if both_topics and reason_mentioned and word_count >= 60:
        # 5ì : ë‘ ì£¼ì œ ì™„ì „íˆ ë‹¤ë£¨ê³ , ì´ìœ ë„ ëª…í™•, ì²´ê³„ì  êµ¬ì„±
        if word_count >= 80 and sentence_count >= 4:
            return 5, f"Both topics FULLY covered with clear reasons ({word_count} words, past:{past_mentioned} keywords, future:{future_mentioned} keywords)"
        # 4ì : ë‘ ì£¼ì œ ë‹¤ë£¨ì§€ë§Œ í•œìª½ì´ ì•½ê°„ ë¶€ì¡±í•˜ê±°ë‚˜ ì´ìœ ê°€ ì•½í•¨
        else:
            return 4, f"Both topics covered with reasons ({word_count} words, past:{past_mentioned}, future:{future_mentioned})"
    elif both_topics and word_count >= 40:
        # 3ì : ë‘ ì£¼ì œ ì–¸ê¸‰í•˜ì§€ë§Œ ë‚´ìš©ì´ ì–•ê±°ë‚˜ êµ¬ì„±ì´ ì–´ìƒ‰
        reason_text = " with some reasons" if reason_mentioned else " but lacks clear reasons"
        return 3, f"Both topics mentioned but shallow content ({word_count} words){reason_text}"
    elif one_topic_only and word_count >= 20:
        # 2ì : í•œ ì£¼ì œë§Œ ì œëŒ€ë¡œ ë‹¤ë£¨ê±°ë‚˜ ë§¤ìš° ì§§ìŒ
        if past_mentioned >= 2:
            missing = "future plans (ë‹¤ìŒ ë°©í•™ ê³„íš)"
        else:
            missing = "past vacation (ì§€ë‚œ ë°©í•™)"
        return 2, f"Only one topic covered adequately, MISSING {missing} ({word_count} words)"
    else:
        # 1ì : ìµœì†Œí•œì˜ ì‘ë‹µë§Œ ì‹œë„ ë˜ëŠ” ë‘ ì£¼ì œ ëª¨ë‘ ë¯¸í¡
        return 1, f"Task not completed - both topics missing or minimal ({word_count} words, past:{past_mentioned}, future:{future_mentioned})"


def calculate_language_use_score_holistic(transcript):
    """
    ì–¸ì–´ ì‚¬ìš© ì ìˆ˜ ê³„ì‚° (í™€ë¦¬ìŠ¤í‹± ë°©ì‹ 1-5ì  + ì´ìœ )
    
    Args:
        transcript: STT ì „ì‚¬ í…ìŠ¤íŠ¸
        
    Returns:
        tuple: (ì ìˆ˜, ì´ìœ ) - (int, str)
    """
    if not transcript or not transcript.strip():
        return 1, "No language use detected"
    
    words = transcript.split()
    word_count = len(words)
    
    # ê¸°ë³¸ì ì¸ ë¬¸ë²• íŒ¨í„´ í™•ì¸
    basic_patterns = ["í–ˆì–´ìš”", "ê°”ì–´ìš”", "í•  ê±°ì˜ˆìš”", "ì´ì—ìš”", "ì˜ˆìš”", "ìŠµë‹ˆë‹¤", "í•´ìš”", "ì™€ìš”", "ë´¤ì–´ìš”"]
    pattern_count = sum(1 for pattern in basic_patterns if pattern in transcript)
    
    # ì–´íœ˜ ë‹¤ì–‘ì„± í™•ì¸
    unique_words = set(words)
    diversity_ratio = len(unique_words) / word_count if word_count > 0 else 0
    
    # í™€ë¦¬ìŠ¤í‹± í‰ê°€ (ì „ì²´ì  ì¸ìƒ ê¸°ë°˜)
    if word_count >= 60 and pattern_count >= 4 and diversity_ratio >= 0.75:
        # 5ì : ë¬¸ë²• ì •í™•í•˜ê³  ì–´íœ˜ í’ë¶€, ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„
        return 5, f"Accurate grammar with rich vocabulary and natural expressions ({word_count} words, {pattern_count} patterns, {diversity_ratio:.2f} diversity)"
    elif word_count >= 50 and pattern_count >= 3 and diversity_ratio >= 0.65:
        # 4ì : ëŒ€ì²´ë¡œ ì •í™•í•˜ì§€ë§Œ ëª‡ ê°€ì§€ ì‹¤ìˆ˜
        return 4, f"Mostly accurate with minor mistakes ({word_count} words, {pattern_count} patterns, {diversity_ratio:.2f} diversity)"
    elif word_count >= 30 and pattern_count >= 2 and diversity_ratio >= 0.50:
        # 3ì : ì˜ì‚¬ì†Œí†µ ê°€ëŠ¥í•˜ì§€ë§Œ ë¬¸ë²•/ì–´íœ˜ ì˜¤ë¥˜ ëˆˆì— ë”
        return 3, f"Communicable but grammar/vocabulary errors noticeable ({word_count} words, {pattern_count} patterns, {diversity_ratio:.2f} diversity)"
    elif word_count >= 20 and pattern_count >= 1:
        # 2ì : ê¸°ë³¸ ì˜ì‚¬ì†Œí†µ ê°€ëŠ¥í•˜ì§€ë§Œ ì˜¤ë¥˜ ë§ìŒ
        return 2, f"Basic communication possible but many errors ({word_count} words, {pattern_count} patterns)"
    else:
        # 1ì : ë§¤ìš° ê¸°ì´ˆì , ì˜¤ë¥˜ë¡œ ì¸í•´ ì´í•´ ì–´ë ¤ì›€
        return 1, f"Very basic, errors hinder understanding ({word_count} words, {pattern_count} patterns)"


def calculate_delivery_score_holistic(transcript, duration):
    """
    ë°œí™” ì „ë‹¬ë ¥ ì ìˆ˜ ê³„ì‚° (í™€ë¦¬ìŠ¤í‹± ë°©ì‹ 1-5ì  + ì´ìœ ) - 60ì´ˆ/70ì´ˆ ê¸°ì¤€
    
    Args:
        transcript: STT ì „ì‚¬ í…ìŠ¤íŠ¸
        duration: ë°œí™” ê¸¸ì´ (ì´ˆ)
        
    Returns:
        tuple: (ì ìˆ˜, ì´ìœ ) - (int, str)
    """
    if not transcript or not transcript.strip() or duration <= 0:
        return 1, "No delivery detected or invalid duration"
    
    word_count = len(transcript.split())
    
    # ğŸ”¥ í•µì‹¬: 60ì´ˆ ë¯¸ë§Œì€ ìµœëŒ€ 2ì ë§Œ ê°€ëŠ¥
    if duration < 60:
        if duration >= 45:
            return 2, f"Length insufficient for higher scores ({duration:.1f}s, 45-60s range, max 2 points)"
        else:
            return 1, f"Extremely short delivery ({duration:.1f}s, under 45s)"
    
    # 60ì´ˆ ì´ìƒë¶€í„° 3-5ì  ê°€ëŠ¥
    words_per_minute = (word_count / duration) * 60 if duration > 0 else 0
    
    # ë¬¸ì¥ ì™„ì„±ë„ ì¶”ì • (STT ê¸°ë°˜)
    sentences = transcript.count('.') + transcript.count('!') + transcript.count('?')
    if sentences == 0:  # ë¬¸ì¥ ë¶€í˜¸ê°€ ì—†ìœ¼ë©´ ì–´ë¯¸ë¡œ ì¶”ì •
        sentences = len([s for s in transcript.split() if s.endswith(('ìš”', 'ë‹¤', 'ê¹Œ', 'ì–´ìš”', 'ì•„ìš”'))])
    
    # í™€ë¦¬ìŠ¤í‹± í‰ê°€
    if duration >= 70:
        # 70ì´ˆ ì´ìƒ: 4-5ì  ê°€ëŠ¥
        if words_per_minute >= 60 and sentences >= 4 and word_count >= 60:
            # 5ì : ì¶©ë¶„í•œ ê¸¸ì´, ìœ ì°½í•˜ê³  ìì—°ìŠ¤ëŸ¬ì›€
            return 5, f"Sufficient length, fluent and natural ({duration:.1f}s, {words_per_minute:.1f} wpm, {sentences} sentences)"
        else:
            # 4ì : ì¶©ë¶„í•œ ê¸¸ì´, ì•½ê°„ì˜ ë§ì„¤ì„ì€ ìˆì§€ë§Œ ì „ë°˜ì ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ì›€
            return 4, f"Sufficient length, minor hesitation but generally natural ({duration:.1f}s, {words_per_minute:.1f} wpm)"
    else:
        # 60-70ì´ˆ: 3ì 
        # 3ì : ê¸°ë³¸ ìš”êµ¬ ì¶©ì¡±, ë‚´ìš©ì€ ì „ë‹¬ë˜ì§€ë§Œ ì–´ìƒ‰í•¨ì´ë‚˜ ì§§ì€ ë©ˆì¶¤
        return 3, f"Adequate length but some awkwardness or short pauses ({duration:.1f}s, 60-70s range)"


def calculate_total_topik_score(content_score, language_score, delivery_score):
    """
    ì „ì²´ TOPIK ì ìˆ˜ ê³„ì‚° (ë‹¨ìˆœ í•©ì‚°)
    
    Args:
        content_score: ë‚´ìš© ì ìˆ˜ (1-5)
        language_score: ì–¸ì–´ ì ìˆ˜ (1-5)
        delivery_score: ì „ë‹¬ë ¥ ì ìˆ˜ (1-5)
        
    Returns:
        int: ì „ì²´ ì ìˆ˜ (3-15ì )
    """
    return content_score + language_score + delivery_score


def save_reference_score(session_id, attempt, transcript, duration, timestamp=None):
    """
    TOPIK ì°¸ê³ ìš© ì ìˆ˜ ì €ì¥ (í™€ë¦¬ìŠ¤í‹± ë£¨ë¸Œë¦­ ì ìš© + ì´ìœ  ì»¬ëŸ¼ ì¶”ê°€)
    
    ===== EXCEL ë°ì´í„° êµ¬ì¡° ë¬¸ì„œí™” =====
    ì´ í•¨ìˆ˜ëŠ” TOPIK ê¸°ë°˜ ì°¸ê³ ìš© ì ìˆ˜ë¥¼ Excel íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    íŒŒì¼ëª… í˜•ì‹: reference_scores_{timestamp}.xlsx
    
    ğŸ“Š Excel ì»¬ëŸ¼ êµ¬ì¡°:
    
    1. ê¸°ë³¸ ì •ë³´:
       - session_id: ì„¸ì…˜ ê³ ìœ ë²ˆí˜¸ (CSV íŒŒì¼ê³¼ ì—°ê²° í‚¤)
       - attempt: ì‹œë„ ë²ˆí˜¸ (1=ì²«ë²ˆì§¸ ë…¹ìŒ, 2=ë‘ë²ˆì§¸ ë…¹ìŒ)
       - transcript: STT ì „ì‚¬ í…ìŠ¤íŠ¸ (ì ìˆ˜ ì‚°ì • ê·¼ê±°)
       - duration_s: ë…¹ìŒ ê¸¸ì´ (ì´ˆ, 60ì´ˆ ë¯¸ë§Œì€ ì ìˆ˜ ì œí•œ)
       - timestamp: ì ìˆ˜ ìƒì„± ì‹œê°
    
    2. TOPIK 3ì˜ì—­ í™€ë¦¬ìŠ¤í‹± ì ìˆ˜ (ê° 1-5ì ):
       - topik_content_task_score_auto: ë‚´ìš© ë° ê³¼ì œ ìˆ˜í–‰ ì ìˆ˜
         â†’ ì—¬ë¦„ë°©í•™+í•œêµ­ê³„íš ë‘ ì£¼ì œ ëª¨ë‘ ë‹¤ë¤˜ëŠ”ì§€, ì´ìœ  ì„¤ëª…í–ˆëŠ”ì§€ í‰ê°€
       - topik_language_use_score_auto: ì–¸ì–´ ì‚¬ìš© ì ìˆ˜  
         â†’ ë¬¸ë²• ì •í™•ì„±, ì–´íœ˜ ë‹¤ì–‘ì„±, ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ ì¢…í•© í‰ê°€
       - topik_delivery_score(stt)_auto: ì „ë‹¬ë ¥ ì ìˆ˜ (STT ê¸°ë°˜)
         â†’ ë°œí™” ê¸¸ì´, ìœ ì°½ì„±, ì™„ì„±ë„ ì¢…í•© í‰ê°€ (60ì´ˆ ë¯¸ë§Œì€ ìµœëŒ€ 2ì )
    
    3. ì ìˆ˜ ì‚°ì • ì´ìœ  (ìë™ ìƒì„±):
       - topik_content_task_reason: ë‚´ìš© ì ìˆ˜ ì´ìœ  ì„¤ëª…
       - topik_language_use_reason: ì–¸ì–´ ì‚¬ìš© ì ìˆ˜ ì´ìœ  ì„¤ëª…  
       - topik_delivery_reason: ì „ë‹¬ë ¥ ì ìˆ˜ ì´ìœ  ì„¤ëª…
    
    4. ì´ì :
       - topik_total_score_auto: 3ì˜ì—­ ë‹¨ìˆœ í•©ì‚° (3-15ì )
    
    ğŸ¯ ì ìˆ˜ ê¸°ì¤€ (í™€ë¦¬ìŠ¤í‹± ë£¨ë¸Œë¦­):
    - 5ì : ë§¤ìš° ìš°ìˆ˜ (ë©´ì ‘ ì¤€ë¹„ ì™„ë£Œ ìˆ˜ì¤€)
    - 4ì : ìš°ìˆ˜ (ì•½ê°„ì˜ ê°œì„ ìœ¼ë¡œ ë©´ì ‘ ì¤€ë¹„ ê°€ëŠ¥)
    - 3ì : ë³´í†µ (ê¸°ë³¸ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±, ì¶”ê°€ ì—°ìŠµ í•„ìš”)
    - 2ì : ë¯¸í¡ (ìƒë‹¹í•œ ê°œì„  í•„ìš”)
    - 1ì : ë§¤ìš° ë¯¸í¡ (ê¸°ì´ˆë¶€í„° ë‹¤ì‹œ ì—°ìŠµ í•„ìš”)
    
    ğŸ“ˆ í™œìš© ëª©ì :
    - CSVì˜ AI ì ìˆ˜ì™€ ë¹„êµí•˜ì—¬ ìë™ì±„ì  ì •í™•ì„± ê²€ì¦
    - ì „ë¬¸ê°€ ì±„ì  ê¸°ì¤€ê³¼ ë¹„êµ ì—°êµ¬
    - í•™ìŠµì ì§„ë‹¨ ë° ë ˆë²¨ í‰ê°€ ê¸°ì¤€ ê°œë°œ
    - í”¼ë“œë°± ì‹œìŠ¤í…œ ê°œì„ ì„ ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ ì ìˆ˜
    
    Args:
        session_id: ì„¸ì…˜ ID
        attempt: ì‹œë„ ë²ˆí˜¸ (1 or 2)
        transcript: ì „ì‚¬ í…ìŠ¤íŠ¸
        duration: ê¸¸ì´ (ì´ˆ)
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„ (í•„ìˆ˜ - main.pyì—ì„œ ì „ë‹¬)
        
    Returns:
        str: ì €ì¥ëœ íŒŒì¼ëª…
    """
    if not timestamp:
        timestamp = datetime.now(KST).strftime("%Y%m%d_%H%M%S")  # ğŸ”¥ KST ì¶”ê°€
    
    # í™€ë¦¬ìŠ¤í‹± ë°©ì‹ìœ¼ë¡œ 3ì˜ì—­ ì ìˆ˜ + ì´ìœ  ê³„ì‚°
    content_task_score, content_task_reason = calculate_content_task_score_holistic(transcript)
    language_use_score, language_use_reason = calculate_language_use_score_holistic(transcript)
    delivery_score, delivery_reason = calculate_delivery_score_holistic(transcript, duration)
    total_score = calculate_total_topik_score(content_task_score, language_use_score, delivery_score)
    
    # timestamp ê¸°ë°˜ íŒŒì¼ëª…
    filename = f"data/reference_scores_{timestamp}.xlsx"
    
    # ìƒˆ ë°ì´í„° (í™€ë¦¬ìŠ¤í‹± ë£¨ë¸Œë¦­ ì»¬ëŸ¼ + ì´ìœ  ì»¬ëŸ¼ + ìƒì„¸ ì£¼ì„)
    new_data = {
        # === ê¸°ë³¸ ì‹ë³„ ì •ë³´ ===
        'session_id': session_id,              # ì„¸ì…˜ ê³ ìœ ë²ˆí˜¸ (CSVì™€ ì—°ê²°)
        'attempt': attempt,                    # ì‹œë„ ë²ˆí˜¸ (1=í”¼ë“œë°± ì „, 2=í”¼ë“œë°± í›„)
        'transcript': transcript,              # STT ì „ì‚¬ í…ìŠ¤íŠ¸ (ì±„ì  ê·¼ê±°)
        'duration_s': duration,                # ë…¹ìŒ ê¸¸ì´ (ì´ˆ) - 60ì´ˆ ë¯¸ë§Œì€ ì ìˆ˜ ì œí•œ
        'timestamp': timestamp,                # ì ìˆ˜ ìƒì„± ì‹œê° (íŒŒì¼ëª…ê³¼ ë™ì¼)
        
        # === TOPIK 3ì˜ì—­ í™€ë¦¬ìŠ¤í‹± ì ìˆ˜ (ê° 1-5ì ) ===
        'topik_content_task_score_auto': content_task_score,        # ë‚´ìš© ë° ê³¼ì œ ìˆ˜í–‰ (ì—¬ë¦„ë°©í•™+í•œêµ­ê³„íš ì£¼ì œ ì™„ì„±ë„)
        'topik_language_use_score_auto': language_use_score,        # ì–¸ì–´ ì‚¬ìš© (ë¬¸ë²• ì •í™•ì„± + ì–´íœ˜ ë‹¤ì–‘ì„±)  
        'topik_delivery_score(stt)_auto': delivery_score,           # ì „ë‹¬ë ¥ (ìœ ì°½ì„± + ë°œí™” ê¸¸ì´, STT ê¸°ë°˜)
        
        # === ì ìˆ˜ ì‚°ì • ì´ìœ  (ìë™ ìƒì„±, íˆ¬ëª…ì„± í™•ë³´) ===
        'topik_content_task_reason': content_task_reason,           # ë‚´ìš© ì ìˆ˜ ê·¼ê±° ì„¤ëª…
        'topik_language_use_reason': language_use_reason,           # ì–¸ì–´ ì‚¬ìš© ì ìˆ˜ ê·¼ê±° ì„¤ëª…
        'topik_delivery_reason': delivery_reason,                   # ì „ë‹¬ë ¥ ì ìˆ˜ ê·¼ê±° ì„¤ëª…
        
        # === ì´ì  (ì—°êµ¬ ë¶„ì„ìš©) ===
        'topik_total_score_auto': total_score,                      # 3ì˜ì—­ ë‹¨ìˆœ í•©ì‚° (3-15ì )
    }
    
    # íŒŒì¼ ìˆìœ¼ë©´ ê¸°ì¡´ ë°ì´í„°ì— ì¶”ê°€, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    try:
        os.makedirs("data", exist_ok=True)
        
        if os.path.exists(filename):
            df = pd.read_excel(filename)
            df = pd.concat([df, pd.DataFrame([new_data])], ignore_index=True)
        else:
            df = pd.DataFrame([new_data])
        
        df.to_excel(filename, index=False)
        
        # í™€ë¦¬ìŠ¤í‹± ì ìˆ˜ ë¡œê·¸ ì¶œë ¥
        duration_status = "âœ… 60s+" if duration >= 60 else "âŒ <60s"
        quality_level = get_score_quality_description(total_score)
        
        print(f"âœ… Holistic TOPIK scores with reasons saved: {filename}")
        print(f"   ğŸ“Š Content: {content_task_score}/5 ({content_task_reason})")
        print(f"   ğŸ“Š Language: {language_use_score}/5 ({language_use_reason})")
        print(f"   ğŸ“Š Delivery: {delivery_score}/5 ({delivery_reason})")
        print(f"   ğŸ¯ Total: {total_score}/15 ({quality_level})")
        print(f"   â±ï¸ Duration: {duration:.1f}s ({duration_status}), Words: {len(transcript.split())}")
        return filename
        
    except Exception as e:
        print(f"âš ï¸ Reference score save failed: {e}")
        return None


def get_score_quality_description(total_score):
    """
    ì´ì ì— ë”°ë¥¸ í’ˆì§ˆ ì„¤ëª… ë°˜í™˜
    
    Args:
        total_score: ì´ ì ìˆ˜ (3-15)
        
    Returns:
        str: í’ˆì§ˆ ì„¤ëª…
    """
    if total_score >= 13:
        return "Excellent"
    elif total_score >= 11:
        return "Good"
    elif total_score >= 8:
        return "Fair"
    elif total_score >= 6:
        return "Poor"
    else:
        return "Very Poor"


def get_latest_reference_file(timestamp=None):
    """
    timestampì— í•´ë‹¹í•˜ëŠ” reference íŒŒì¼ ê²½ë¡œ ë°˜í™˜
    
    Args:
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        
    Returns:
        str: íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None
    """
    if timestamp:
        filename = f"data/reference_scores_{timestamp}.xlsx"
        if os.path.exists(filename):
            return filename
    
    # timestampê°€ ì—†ê±°ë‚˜ íŒŒì¼ì´ ì—†ìœ¼ë©´ ê°€ì¥ ìµœì‹  íŒŒì¼ ì°¾ê¸°
    import glob
    pattern = "data/reference_scores_*.xlsx"
    files = glob.glob(pattern)
    if files:
        return max(files, key=os.path.getctime)
    
    return None


def display_score_summary(session_id, attempt, scores):
    """
    ì ìˆ˜ ìš”ì•½ ì¶œë ¥ (í™€ë¦¬ìŠ¤í‹± ë£¨ë¸Œë¦­ + ì´ìœ  ë°˜ì˜)
    
    Args:
        session_id: ì„¸ì…˜ ID
        attempt: ì‹œë„ ë²ˆí˜¸
        scores: ì ìˆ˜ ë”•ì…”ë„ˆë¦¬
    """
    total_score = scores.get('topik_total_score_auto', 0)
    quality_desc = get_score_quality_description(total_score)
    
    print(f"\nğŸ“Š Holistic TOPIK Scores with Reasons - {session_id} (Attempt {attempt})")
    print(f"   Content & Task: {scores.get('topik_content_task_score_auto', 0)}/5")
    print(f"   â†’ {scores.get('topik_content_task_reason', 'No reason available')}")
    print(f"   Language Use: {scores.get('topik_language_use_score_auto', 0)}/5")
    print(f"   â†’ {scores.get('topik_language_use_reason', 'No reason available')}")
    print(f"   Delivery (STT): {scores.get('topik_delivery_score(stt)_auto', 0)}/5")
    print(f"   â†’ {scores.get('topik_delivery_reason', 'No reason available')}")
    print(f"   ğŸ“ˆ Total: {total_score}/15 ({quality_desc})")
    print(f"   ğŸ¯ Holistic Rubric: Overall impression-based scoring with detailed reasoning")
    print("=" * 80)