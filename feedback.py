"""
feedback.py
GPTë¥¼ ì´ìš©í•œ í•œêµ­ì–´ í•™ìŠµ í”¼ë“œë°± ìƒì„± (ì´ì¤‘ í‰ê°€ ì‹œìŠ¤í…œ: ì—°êµ¬ìš© + í•™ìƒìš©)
"""

import openai
import json
import time
import re  # ì¶”ê°€: Simple explanation ë ˆì´ë¸” ì œê±°ìš©
import streamlit as st
from config import (
    OPENAI_API_KEY, 
    EXPERIMENT_QUESTION, 
    GPT_SYSTEM_PROMPT, 
    STT_RUBRIC,
    FEEDBACK_PROMPT_TEMPLATE,
    IMPROVEMENT_PROMPT_TEMPLATE,
    FALLBACK_FEEDBACK_DATA,
    FALLBACK_IMPROVEMENT_DATA,
    GRAMMAR_ERROR_TYPES,
    FEEDBACK_LEVEL,
    GPT_FEEDBACK_MAX_TOKENS,
    GPT_FEEDBACK_MAX_CHARS
)


# === ê°„ì†Œí™”ëœ ì˜¤ë¥˜ ë¶„ë¥˜ ìƒìˆ˜ ===
INDIVIDUAL_PARTICLES = ["ì„", "ë¥¼", "ì€", "ëŠ”", "ì´", "ê°€", "ì—ì„œ", "ì—ê²Œ", "ì—", "ì™€", "ê³¼", "ì˜", "ë¡œ", "ìœ¼ë¡œ"]
TIME_INDICATORS = ["ì–´ì œ", "ë‚´ì¼", "ì§€ê¸ˆ", "ì˜¤ëŠ˜", "ë‚´ë…„", "ì‘ë…„", "ë‹¤ìŒ ì£¼", "ì§€ë‚œì£¼", "ë°©ê¸ˆ", "ë‚˜ì¤‘ì—"]
VERB_ENDINGS = ["ì˜ˆìš”", "ì´ì—ìš”", "ì•„ìš”", "ì–´ìš”", "ìŠµë‹ˆë‹¤", "ì„¸ìš”", "ã…‚ë‹ˆë‹¤", "ë‹¤", "ã„´ë‹¤", "ëŠ”ë‹¤"]
TENSE_MARKERS = ["í–ˆì–´ìš”", "í•  ê±°ì˜ˆìš”", "í•˜ê³  ìˆì–´ìš”", "í•œ ì ì´", "í–ˆì—ˆì–´ìš”", "í• ê²Œìš”"]

# ì´ˆê¸‰ í•™ìŠµì ìì£¼ í‹€ë¦¬ëŠ” íŒ¨í„´
COMMON_BEGINNER_ERRORS = {
    "ì¢‹ì•„ìš”_ì¢‹ì•„í•´ìš”": {"pattern": "ì¢‹ì•„ìš”", "correct": "ì¢‹ì•„í•´ìš”", "type": "Verb Ending"},
    "ì…ë‹ˆë‹¤_ì´ì—ìš”": {"pattern": "ì…ë‹ˆë‹¤", "correct": "ì´ì—ìš”", "type": "Verb Ending"},
    "ì „ê³µì´ì—ìš”_ì „ê³µí•´ìš”": {"pattern": "ì „ê³µì´ì—ìš”", "correct": "ì „ê³µí•´ìš”", "type": "Verb Ending"}
}


# === ì´ì¤‘ í‰ê°€ ì‹œìŠ¤í…œ: ì—°êµ¬ìš© í•¨ìˆ˜ë“¤ ===

def count_grammar_errors(grammar_issues):
    """
    GPTê°€ ì°¾ì€ ì‹¤ì œ ë¬¸ë²• ì˜¤ë¥˜ë§Œ ì •í™•íˆ ì¹´ìš´íŒ…
    
    Args:
        grammar_issues: GPTê°€ ìƒì„±í•œ ë¬¸ë²• ì´ìŠˆ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        int: ì‹¤ì œ ìœ íš¨í•œ ë¬¸ë²• ì˜¤ë¥˜ ê°œìˆ˜
    """
    valid_errors = 0
    for issue in grammar_issues:
        if isinstance(issue, str) and '|' in issue:
            # "error_type|original|fix|explanation" í˜•ì‹ ê²€ì¦
            parts = issue.split('|')
            if len(parts) >= 3 and parts[1].strip() and parts[2].strip():
                valid_errors += 1
    return valid_errors


def get_research_scores(transcript, grammar_issues, duration_s):
    """
    ì—°êµ¬ìš© ì •í™•í•œ ìˆ˜ì¹˜ ê³„ì‚° (ë…¼ë¬¸ìš©) - 60-120ì´ˆ ê¸°ì¤€ìœ¼ë¡œ ìˆ˜ì •
    - Accuracy: ì˜¤ë¥˜ìœ¨ ê¸°ë°˜ (10 - (error_rate / 10))
    - Fluency: ë‹¨ì–´ìˆ˜ ê¸°ë°˜ (word_count / 120 * 10) - 1.5ë¶„ ê¸°ì¤€ìœ¼ë¡œ 120ë‹¨ì–´
    
    Args:
        transcript: STT ì „ì‚¬ í…ìŠ¤íŠ¸
        grammar_issues: GPTê°€ ì°¾ì€ ë¬¸ë²• ì´ìŠˆë“¤
        duration_s: ë…¹ìŒ ê¸¸ì´ (ì´ˆ)
        
    Returns:
        dict: ì—°êµ¬ìš© ì ìˆ˜ ë°ì´í„°
    """
    # ê¸°ë³¸ê°’ ì„¤ì •
    if not transcript or not isinstance(transcript, str):
        transcript = ""
    
    if not grammar_issues or not isinstance(grammar_issues, list):
        grammar_issues = []
    
    if not duration_s or not isinstance(duration_s, (int, float)):
        duration_s = 0.0
    
    # ë‹¨ì–´ ìˆ˜ ê³„ì‚° (ê³µë°± ê¸°ì¤€)
    total_words = len(transcript.split()) if transcript.strip() else 0
    
    # ì‹¤ì œ ë¬¸ë²• ì˜¤ë¥˜ ê°œìˆ˜ ê³„ì‚°
    error_count = count_grammar_errors(grammar_issues)
    
    # ì˜¤ë¥˜ìœ¨ ê³„ì‚° (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
    if total_words > 0:
        error_rate = (error_count / total_words) * 100
    else:
        error_rate = 0.0
    
    # Accuracy Score: 10ì—ì„œ ì˜¤ë¥˜ìœ¨ì˜ 1/10ì„ ëº€ ê°’ (ìµœì†Œ 0, ìµœëŒ€ 10)
    accuracy_score = max(0, min(10, 10 - (error_rate / 10)))
    
    # ğŸ”¥ Fluency Score: 120ë‹¨ì–´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ 10ì  ë§Œì  (1.5ë¶„ ê¸°ì¤€ìœ¼ë¡œ ìˆ˜ì •)
    fluency_score = max(0, min(10, (total_words / 120) * 10))
    
    return {
        "accuracy_score": round(accuracy_score, 1),
        "fluency_score": round(fluency_score, 1),
        "error_rate": round(error_rate, 2),
        "word_count": total_words,
        "duration_s": round(duration_s, 1),
        "error_count": error_count
    }


def get_student_feedback(transcript, research_scores, original_feedback):
    """
    í•™ìƒìš© ê²©ë ¤ì  í”¼ë“œë°± ìƒì„± (ì›ë³¸ GPT í”¼ë“œë°± ìœ ì§€)
    - ì›ë³¸ GPT í”¼ë“œë°±ì„ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì—¬ êµìœ¡ì  ê°€ì¹˜ ë³´ì¡´
    - ì—°êµ¬ìš© ì ìˆ˜ëŠ” ë°±ê·¸ë¼ìš´ë“œì—ì„œë§Œ ê³„ì‚°
    
    Args:
        transcript: STT ì „ì‚¬ í…ìŠ¤íŠ¸
        research_scores: ì—°êµ¬ìš© ì ìˆ˜ ë°ì´í„°
        original_feedback: GPTê°€ ìƒì„±í•œ ì›ë³¸ í”¼ë“œë°±
        
    Returns:
        dict: í•™ìƒìš© í”¼ë“œë°± ë°ì´í„° (ì›ë³¸ GPT í”¼ë“œë°± ìœ ì§€)
    """
    # ê¸°ë³¸ê°’ ì²˜ë¦¬
    if not original_feedback or not isinstance(original_feedback, dict):
        original_feedback = get_fallback_feedback()
    
    if not research_scores or not isinstance(research_scores, dict):
        research_scores = {
            "accuracy_score": 5.0,
            "fluency_score": 5.0,
            "error_rate": 20.0,
            "word_count": 60,
            "duration_s": 60.0,
            "error_count": 3
        }
    
    # ğŸ¯ ì›ë³¸ GPT í”¼ë“œë°±ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜ (êµìœ¡ì  ê°€ì¹˜ ìœ ì§€)
    # ì—°êµ¬ìš© ì ìˆ˜ëŠ” ì´ë¯¸ st.session_state.research_scoresì— ì €ì¥ë˜ì–´ ìˆìŒ
    
    # ì›ë³¸ í”¼ë“œë°± ê·¸ëŒ€ë¡œ ì‚¬ìš© (GPTê°€ ìƒì„±í•œ êµìœ¡ì  í”¼ë“œë°± ìœ ì§€)
    student_feedback = original_feedback.copy()
    
    # ì—°êµ¬ìš© ë©”íƒ€ë°ì´í„°ë§Œ ì¶”ê°€ (í•™ìƒì—ê²ŒëŠ” ë³´ì´ì§€ ì•ŠìŒ)
    student_feedback.update({
        "_research_metadata": {
            "accuracy_score": research_scores.get("accuracy_score", 0),
            "fluency_score": research_scores.get("fluency_score", 0),
            "error_rate": research_scores.get("error_rate", 0),
            "word_count": research_scores.get("word_count", 0),
            "duration_s": research_scores.get("duration_s", 0),
            "dual_evaluation_applied": True
        }
    })
    
    return student_feedback


def generate_encouraging_feedback_message(word_count, error_rate, duration_s, score):
    """ê²©ë ¤ì ì¸ í”¼ë“œë°± ë©”ì‹œì§€ ìƒì„± (60-120ì´ˆ ê¸°ì¤€)"""
    messages = []
    
    # ğŸ”¥ ê¸¸ì´ í”¼ë“œë°± (60-120ì´ˆ ê¸°ì¤€ìœ¼ë¡œ ìˆ˜ì •)
    if duration_s >= 90:
        messages.append(f"Excellent! You spoke for {duration_s:.1f} seconds - perfect length!")
    elif duration_s >= 75:
        messages.append(f"Good job speaking for {duration_s:.1f} seconds! Try to reach 90+ seconds next time.")
    else:
        messages.append(f"You spoke for {duration_s:.1f} seconds. Aim for at least 90 seconds to score higher!")
    
    # ì •í™•ì„± í”¼ë“œë°±
    if error_rate <= 5:
        messages.append("Your grammar is very accurate!")
    elif error_rate <= 15:
        messages.append("Good grammar overall with room for improvement.")
    else:
        messages.append("Focus on grammar practice - you're learning!")
    
    # ğŸ”¥ ë‹¨ì–´ ìˆ˜ í”¼ë“œë°± (60-120ì´ˆ ê¸°ì¤€ìœ¼ë¡œ ìˆ˜ì •)
    if word_count >= 120:
        messages.append(f"Great vocabulary use with {word_count} words!")
    elif word_count >= 80:
        messages.append(f"Good speaking volume with {word_count} words.")
    else:
        messages.append(f"Try to add more details - you used {word_count} words.")
    
    return " ".join(messages)


def generate_improvement_areas(research_scores, original_feedback):
    """ê°œì„  ì˜ì—­ ì œì•ˆ ìƒì„± (60-120ì´ˆ ê¸°ì¤€)"""
    areas = []
    
    # ğŸ”¥ Duration ê¸°ë°˜ (60-120ì´ˆ ê¸°ì¤€ìœ¼ë¡œ ìˆ˜ì •)
    if research_scores.get("duration_s", 0) < 90:
        areas.append("Speaking length - aim for 90+ seconds")
    
    # ì˜¤ë¥˜ìœ¨ ê¸°ë°˜
    if research_scores.get("error_rate", 0) > 15:
        areas.append("Grammar accuracy")
    
    # ğŸ”¥ ë‹¨ì–´ ìˆ˜ ê¸°ë°˜ (60-120ì´ˆ ê¸°ì¤€ìœ¼ë¡œ ìˆ˜ì •)
    if research_scores.get("word_count", 0) < 60:
        areas.append("Adding more personal details")
    
    # ì›ë³¸ í”¼ë“œë°±ì—ì„œ ì¶”ê°€ ì˜ì—­
    if original_feedback.get("grammar_issues"):
        areas.append("Particle usage")
    
    if original_feedback.get("content_expansion_suggestions"):
        areas.append("Content expansion")
    
    return areas[:3]  # ìµœëŒ€ 3ê°œ


def generate_encouragement_message(score):
    """ì ìˆ˜ ê¸°ë°˜ ê²©ë ¤ ë©”ì‹œì§€"""
    if score >= 8:
        return "Outstanding work! You're interview-ready! ğŸŒŸ"
    elif score >= 7:
        return "Great progress! You're almost there! ğŸ’ª"
    elif score >= 6:
        return "Good job! Keep practicing and you'll improve! ğŸš€"
    elif score >= 5:
        return "You're learning well! Every practice helps! ğŸ“š"
    else:
        return "Great start! Keep practicing - you can do it! ğŸŒ±"


def generate_duration_feedback(duration_s):
    """ë…¹ìŒ ê¸¸ì´ ê¸°ë°˜ í”¼ë“œë°± (60-120ì´ˆ ê¸°ì¤€)"""
    if duration_s >= 90:
        return f"Perfect! {duration_s:.1f} seconds meets the 60-120 seconds goal!"
    elif duration_s >= 75:
        return f"Good length at {duration_s:.1f} seconds. Try for 90+ next time!"
    elif duration_s >= 60:
        return f"Fair length at {duration_s:.1f} seconds. Aim for 90+ seconds!"
    else:
        return f"Too short at {duration_s:.1f} seconds. Much more needed for good score!"


def generate_accuracy_feedback(error_rate):
    """ì •í™•ì„± ê¸°ë°˜ í”¼ë“œë°±"""
    if error_rate <= 5:
        return "Excellent grammar accuracy!"
    elif error_rate <= 10:
        return "Good accuracy with minor errors."
    elif error_rate <= 20:
        return "Fair accuracy - focus on common mistakes."
    else:
        return "Work on grammar basics - you're improving!"


def generate_fluency_feedback(word_count):
    """ìœ ì°½ì„± ê¸°ë°˜ í”¼ë“œë°± (60-120ì´ˆ ê¸°ì¤€)"""
    if word_count >= 120:
        return f"Excellent fluency with {word_count} words!"
    elif word_count >= 90:
        return f"Good fluency with {word_count} words."
    elif word_count >= 60:
        return f"Fair fluency with {word_count} words - add more details!"
    else:
        return f"Work on speaking more - only {word_count} words used."


# === ê¸°ì¡´ í•¨ìˆ˜ë“¤ (ìˆ˜ì • ì—†ìŒ) ===

def split_korean_sentences(text):
    """
    í•œêµ­ì–´ ë¬¸ì¥ì„ ì ì ˆíˆ ë¶„í• 
    
    Args:
        text: ë¶„í• í•  í…ìŠ¤íŠ¸
        
    Returns:
        list: ë¶„í• ëœ ë¬¸ì¥ë“¤
    """
    # í•œêµ­ì–´ ë¬¸ì¥ êµ¬ë¶„ì: ., !, ?, ìš”/ì–´ìš”/ìŠµë‹ˆë‹¤ ë’¤ì˜ ê³µë°±
    pattern = r'([.!?]|(?:ìš”|ì–´ìš”|ìŠµë‹ˆë‹¤|ì„¸ìš”|í•´ìš”|ì´ì—ìš”|ì˜ˆìš”)\s*)'
    sentences = re.split(pattern, text)
    
    # ë¶„í• ëœ ë¶€ë¶„ì„ ë‹¤ì‹œ ì¡°í•©
    result = []
    for i in range(0, len(sentences)-1, 2):
        if i+1 < len(sentences):
            sentence = sentences[i] + sentences[i+1]
            if sentence.strip():
                result.append(sentence.strip())
    
    # ë§ˆì§€ë§‰ ë¶€ë¶„ì´ ë‚¨ì•„ìˆë‹¤ë©´ ì¶”ê°€
    if len(sentences) % 2 == 1 and sentences[-1].strip():
        result.append(sentences[-1].strip())
    
    return [s for s in result if len(s.strip()) > 3]  # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ ì œì™¸


def preprocess_long_transcript_fallback(transcript, max_chars=GPT_FEEDBACK_MAX_CHARS):
    """
    ë¬¸ì ìˆ˜ ê¸°ë°˜ ê¸´ í…ìŠ¤íŠ¸ ì²˜ë¦¬
    
    Args:
        transcript: ì „ì‚¬ëœ í…ìŠ¤íŠ¸
        max_chars: ìµœëŒ€ ë¬¸ì ìˆ˜
        
    Returns:
        str: ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸
    """
    if len(transcript) <= max_chars:
        return transcript
    
    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸° ì‹œë„
    sentences = split_korean_sentences(transcript)
    
    if not sentences:
        # ë¬¸ì¥ ë¶„í•  ì‹¤íŒ¨ì‹œ ì ë‹¹í•œ ìœ„ì¹˜ì—ì„œ ìë¥´ê¸°
        cutoff = transcript.rfind(' ', 0, max_chars)
        if cutoff == -1:
            cutoff = max_chars
        return transcript[:cutoff]
    
    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìµœëŒ€í•œ í¬í•¨
    result = ""
    for sentence in sentences:
        temp = result + " " + sentence if result else sentence
        if len(temp) <= max_chars:
            result = temp
        else:
            break
    
    return result if result else sentences[0][:max_chars]


def preprocess_long_transcript(transcript):
    """
    ê¸´ ì „ì‚¬ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜ (ë¬¸ì ìˆ˜ ê¸°ë°˜ë§Œ ì‚¬ìš©)
    
    Args:
        transcript: ì „ì‚¬ëœ í…ìŠ¤íŠ¸
        
    Returns:
        str: ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸
    """
    if not transcript or len(transcript.strip()) == 0:
        return transcript
    
    # ê°„ë‹¨í•œ ì •ë¦¬
    cleaned = transcript.strip()
    
    # ë¬¸ì ìˆ˜ ê¸°ë°˜ ì²˜ë¦¬ (tiktoken ì œê±°)
    if len(cleaned) <= GPT_FEEDBACK_MAX_CHARS:
        return cleaned
    else:
        # ê¸´ í…ìŠ¤íŠ¸ëŠ” ë¬¸ì ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸°
        return preprocess_long_transcript_fallback(cleaned)


# === ê°œì„ ëœ ì˜¤ë¥˜ ë¶„ë¥˜ í•¨ìˆ˜ (3ê°œ ì£¼ìš” ìœ í˜• + ê¸°íƒ€) ===
def classify_error_type(issue_text):
    """
    í”¼ë“œë°± í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ 4ê°œ ì˜¤ë¥˜ íƒ€ì… ì¤‘ í•˜ë‚˜ ë°˜í™˜
    - 3ê°œ ì£¼ìš” ìœ í˜•: Particle, Verb Ending, Verb Tense (ëª¨ë‘ ë™ë“±í•˜ê²Œ ì¤‘ìš”)
    - ê¸°íƒ€: Others (ëª¨ë“  ë‹¤ë¥¸ ë¬¸ë²• ì˜¤ë¥˜)
    
    Args:
        issue_text: ë¶„ì„í•  í”¼ë“œë°± í…ìŠ¤íŠ¸
        
    Returns:
        str: ë¶„ë¥˜ëœ ì˜¤ë¥˜ íƒ€ì… (Particle, Verb Ending, Verb Tense, ë˜ëŠ” None)
              Noneì¸ ê²½ìš° í˜¸ì¶œë¶€ì—ì„œ "Others"ë¡œ ë¶„ë¥˜ë¨
    """
    issue_lower = issue_text.lower()
    
    # Originalê³¼ Fix ë¶€ë¶„ ì¶”ì¶œ (ê°œì„ ëœ íŒŒì‹±)
    original_text = ""
    fix_text = ""
    
    # GPT í”¼ë“œë°±ì—ì„œ originalê³¼ fix ì¶”ì¶œ
    if "âŒ" in issue_text and "âœ…" in issue_text:
        try:
            # âŒ ê°€ì¡±ì´ë‘ ë¶€ì‚°ì—¬í–‰ ê°”ë‹¤. âœ… ê°€ì¡±ì´ë‘ ë¶€ì‚°ì—¬í–‰ ê°”ì–´ìš”. í˜•íƒœ
            parts = issue_text.split("âŒ")[1].split("âœ…")
            if len(parts) >= 2:
                original_text = parts[0].strip().strip(".")
                fix_text = parts[1].split("ğŸ’¡")[0].strip().strip(".")
        except:
            pass
    elif "Original:" in issue_text and "â†’" in issue_text:
        try:
            original_text = issue_text.split("Original:")[1].split("â†’")[0].strip().strip("'\"")
            if "Fix:" in issue_text:
                fix_text = issue_text.split("Fix:")[1].split("ğŸ’¡")[0].strip().strip("'\"")
            else:
                fix_text = issue_text.split("â†’")[1].split("ğŸ’¡")[0].strip().strip("'\"")
        except:
            pass
    
    print(f"ğŸ” Debug - Original: '{original_text}' | Fix: '{fix_text}'")  # ë””ë²„ê¹…ìš©
    
    # 1. ì´ˆê¸‰ì ìì£¼ í‹€ë¦¬ëŠ” íŒ¨í„´ ìš°ì„  í™•ì¸
    for pattern_info in COMMON_BEGINNER_ERRORS.values():
        if pattern_info["pattern"] in original_text and pattern_info["correct"] in fix_text:
            print(f"âœ… {pattern_info['type']} (common pattern): {pattern_info['pattern']} â†’ {pattern_info['correct']}")
            return pattern_info["type"]
    
    # 2. Particle í™•ì¸
    for particle in INDIVIDUAL_PARTICLES:
        if f"'{particle}'" in issue_text or f" {particle} " in issue_text:
            print(f"âœ… Particle detected: keyword '{particle}'")
            return "Particle"
        if original_text and fix_text:
            if particle in fix_text and particle not in original_text:
                print(f"âœ… Particle detected: added '{particle}'")
                return "Particle"
    
    if "particle" in issue_lower or "ì¡°ì‚¬" in issue_text:
        print(f"âœ… Particle detected: keyword")
        return "Particle"
    
    # 3. Verb Tense í™•ì¸ (ì‹œê°„ í‘œí˜„ì´ ìˆëŠ” ê²½ìš°)
    for indicator in TIME_INDICATORS + TENSE_MARKERS:
        if indicator in issue_text:
            print(f"âœ… Verb Tense detected: time indicator '{indicator}'")
            return "Verb Tense"
    
    if "tense" in issue_lower or "ì‹œì œ" in issue_text or "past tense" in issue_lower:
        print(f"âœ… Verb Tense detected: keyword")
        return "Verb Tense"
    
    # 4. Verb Ending í™•ì¸
    for ending in VERB_ENDINGS:
        if ending in issue_text:
            print(f"âœ… Verb Ending detected: ending '{ending}'")
            return "Verb Ending"

    # ë°˜ë§ â†’ ì¡´ëŒ“ë§ íŒ¨í„´ í™•ì¸ (ì •í™•í•œ ì–´ë¯¸ í™•ì¸)
    if original_text and fix_text:
        informal_endings = ["ë‹¤", "ã„´ë‹¤", "ëŠ”ë‹¤", "ëƒ", "ë‚˜", "ì§€", "ì•¼"]
        formal_endings = ["ìš”", "ìŠµë‹ˆë‹¤", "ì„¸ìš”", "ì–´ìš”", "ì•„ìš”", "ì´ì—ìš”", "ì˜ˆìš”"]
        
        # ì›ë³¸ì´ ë°˜ë§ë¡œ ëë‚˜ê³ , ìˆ˜ì •ë³¸ì´ ì¡´ëŒ“ë§ë¡œ ëë‚˜ëŠ” ê²½ìš°
        original_has_informal = any(original_text.endswith(ending) for ending in informal_endings)
        fix_has_formal = any(fix_text.endswith(ending) for ending in formal_endings)
        
        if original_has_informal and fix_has_formal:
            print(f"âœ… Verb Ending detected: {original_text} â†’ {fix_text} (informal to formal)")
            return "Verb Ending"

    if "ending" in issue_lower or "verb form" in issue_lower or "ì–´ë¯¸" in issue_text:
        print(f"âœ… Verb Ending detected: keyword")
        return "Verb Ending"
    
    # ğŸ”¥ 3ê°œ ì£¼ìš” ìœ í˜•ì— í•´ë‹¹í•˜ì§€ ì•Šìœ¼ë©´ None ë°˜í™˜ (í˜¸ì¶œë¶€ì—ì„œ "Others"ë¡œ ë¶„ë¥˜ë¨)
    print(f"â“ No specific type detected, will be classified as 'Others'")
    return None


# === ğŸ”¥ ìŠ¤ë§ˆíŠ¸í•œ ì¤‘ë³µ í•„í„°ë§ í•¨ìˆ˜ (vs ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •ë¨) ===
def extract_grammar_corrections(grammar_issues):
    """
    ë¬¸ë²• í”¼ë“œë°±ì—ì„œ ì‹¤ì œ ìˆ˜ì • ë‚´ìš© ì¶”ì¶œ
    
    Args:
        grammar_issues: ë¬¸ë²• ì´ìŠˆ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        list: (original, fix) íŠœí”Œë“¤ì˜ ë¦¬ìŠ¤íŠ¸
    """
    corrections = []
    
    for issue in grammar_issues:
        if isinstance(issue, str) and '|' in issue:
            parts = issue.split('|')
            if len(parts) >= 3:
                original = parts[1].strip().strip("'\"")
                fix = parts[2].strip().strip("'\"")
                if original and fix:
                    corrections.append((original.lower(), fix.lower()))
    
    return corrections


def extract_vs_words_from_vocabulary(vocab_suggestions):
    """
    vs ë°©ì‹ ì–´íœ˜ ì œì•ˆì—ì„œ ë‹¨ì–´ë“¤ ì¶”ì¶œ
    
    Args:
        vocab_suggestions: ì–´íœ˜ ì œì•ˆ ë¦¬ìŠ¤íŠ¸ (vs ë°©ì‹)
        
    Returns:
        list: [(word_a, word_b), ...] í˜•íƒœì˜ ë‹¨ì–´ ìŒë“¤
    """
    vs_pairs = []
    
    for suggestion in vocab_suggestions:
        if "â“ **" in suggestion and " vs " in suggestion:
            try:
                # â“ **ê³µë¶€í•˜ë‹¤ vs ë°°ìš°ë‹¤** ë¶€ë¶„ ì¶”ì¶œ
                lines = suggestion.replace('\\n', '\n').split('\n')
                for line in lines:
                    if line.startswith('â“ **') and ' vs ' in line:
                        title_text = line.replace('â“ **', '').replace('**', '').strip()
                        if ' vs ' in title_text:
                            words = title_text.split(' vs ')
                            if len(words) >= 2:
                                word_a = words[0].strip()
                                word_b = words[1].strip()
                                vs_pairs.append((word_a.lower(), word_b.lower()))
                        break
            except:
                continue
    
    return vs_pairs


def filter_grammar_from_vocabulary(vocab_suggestions, grammar_issues):
    """
    ğŸ”¥ ìŠ¤ë§ˆíŠ¸í•œ ì¤‘ë³µ í•„í„°ë§: ì‹¤ì œ ë¬¸ë²• í”¼ë“œë°±ê³¼ ì¤‘ë³µë˜ëŠ” ì–´íœ˜ íŒë§Œ ì œê±° (vs ë°©ì‹)
    
    Args:
        vocab_suggestions: ì–´íœ˜ ì œì•ˆ ë¦¬ìŠ¤íŠ¸ (vs ë°©ì‹)
        grammar_issues: ë¬¸ë²• ì´ìŠˆ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        list: ì¤‘ë³µì´ ì œê±°ëœ ì–´íœ˜ ì œì•ˆ ë¦¬ìŠ¤íŠ¸
    """
    # ë¬¸ë²• í”¼ë“œë°±ì—ì„œ ì‹¤ì œ ìˆ˜ì •ëœ ë‚´ìš©ë“¤ ì¶”ì¶œ
    grammar_corrections = extract_grammar_corrections(grammar_issues)
    
    # vs ì–´íœ˜ ì œì•ˆì—ì„œ ë‹¨ì–´ ìŒë“¤ ì¶”ì¶œ
    vs_word_pairs = extract_vs_words_from_vocabulary(vocab_suggestions)
    
    filtered = []
    for vocab_tip in vocab_suggestions:
        is_duplicate = False
        
        # ì´ ì–´íœ˜ íŒì˜ ë‹¨ì–´ ìŒ ì°¾ê¸°
        current_vs_pairs = extract_vs_words_from_vocabulary([vocab_tip])
        
        for word_a, word_b in current_vs_pairs:
            # ë¬¸ë²• ìˆ˜ì • ë‚´ìš©ê³¼ ë¹„êµ
            for grammar_old, grammar_new in grammar_corrections:
                # ì–´íœ˜ íŒì˜ ë‹¨ì–´ë“¤ì´ ë¬¸ë²• ìˆ˜ì •ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                if ((word_a in grammar_old or grammar_old in word_a) and 
                    (word_b in grammar_new or grammar_new in word_b)) or \
                   ((word_b in grammar_old or grammar_old in word_b) and 
                    (word_a in grammar_new or grammar_new in word_a)):
                    is_duplicate = True
                    break
            
            if is_duplicate:
                break
        
        # ì¤‘ë³µì´ ì•„ë‹Œ ê²½ìš°ë§Œ í¬í•¨
        if not is_duplicate:
            filtered.append(vocab_tip)
    
    return filtered


def get_default_vocabulary_suggestions():
    """
    ğŸ”¥ vs ë°©ì‹ ê¸°ë³¸ ì–´íœ˜ ì œì•ˆ (ë‹¨ì–´ ë¹„êµ êµìœ¡)
    """
    return [
        "â“ **ê³µë¶€í•˜ë‹¤ vs ë°°ìš°ë‹¤**\\nğŸ’¡ ê³µë¶€í•˜ë‹¤: Academic studying or reviewing material at a desk\\nğŸ’¡ ë°°ìš°ë‹¤: Learning new skills or acquiring new knowledge\\nğŸŸ¢ ì‹œí—˜ì„ ìœ„í•´ ê³µë¶€í•´ìš” (I study for exams) / í•œêµ­ì–´ë¥¼ ë°°ìš°ê³  ìˆì–´ìš” (I'm learning Korean)\\nğŸ“ Use 'ë°°ìš°ë‹¤' for new skills, 'ê³µë¶€í•˜ë‹¤' for reviewing",
        "â“ **ì¢‹ë‹¤ vs ì¢‹ì•„í•˜ë‹¤**\\nğŸ’¡ ì¢‹ë‹¤: Adjective - something is good (state/quality)\\nğŸ’¡ ì¢‹ì•„í•˜ë‹¤: Verb - to like something (preference)\\nğŸŸ¢ ë‚ ì”¨ê°€ ì¢‹ì•„ìš” (The weather is nice) / ìŒì•…ì„ ì¢‹ì•„í•´ìš” (I like music)\\nğŸ“ Use 'ì´/ê°€ ì¢‹ë‹¤' vs 'ì„/ë¥¼ ì¢‹ì•„í•˜ë‹¤'"
    ]


def ensure_required_fields(data, required_fields):
    """í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ëœ ê²½ìš° ê¸°ë³¸ê°’ìœ¼ë¡œ ë³´ì™„"""
    for field, default_value in required_fields.items():
        if field not in data or not data[field]:
            data[field] = default_value
    return data


def generate_prompt(template, **kwargs):
    """í†µí•© í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜"""
    kwargs.update({
        'target_level': FEEDBACK_LEVEL.get("target_level", "TOPIK 2"),
        'allowed_styles': ", ".join(FEEDBACK_LEVEL.get("allowed_speech_styles", ["í•©ë‹ˆë‹¤ì²´", "í•´ìš”ì²´"])),
        'forbidden_styles': ", ".join(FEEDBACK_LEVEL.get("forbidden_speech_styles", ["ë°˜ë§"]))
    })
    return template.format(**kwargs)


# === ğŸ”¥ ê°œì„ ëœ í”¼ë“œë°± í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ë¬¸ì¥ ì—°ê²° íŒ ì¶”ê°€) ===
IMPROVED_FEEDBACK_PROMPT_TEMPLATE = """Analyze this Korean speaking response from a beginner student.

Student answered "{question}": {transcript}

**IMPORTANT GUIDELINES:**
1. Be encouraging and positive - these are beginners learning Korean
2. Keep grammar explanations simple and beginner-friendly
3. Always praise what they did well first
4. Target level: {target_level}
5. Allowed speech styles: {allowed_styles}
6. Forbidden speech styles: {forbidden_styles}

**âš ï¸âš ï¸ CRITICAL STYLE MATCHING REQUIREMENT: ADHERE TO STUDENT'S ORIGINAL SPEECH STYLE PER SENTENCE âš ï¸âš ï¸**
- **ABSOLUTELY DO NOT change all sentences into one style.** You MUST preserve the student's speech style for EACH sentence individually.
- If a sentence uses í•´ìš”(í•´ìš”, ì´ì—ìš”, ê°€ìš”, ì™€ìš”, ë´ìš”, etc.), write that sentence in í•´ìš”-style.
- If a sentence uses í•©ë‹ˆë‹¤(í•©ë‹ˆë‹¤, ì…ë‹ˆë‹¤, ê°‘ë‹ˆë‹¤, ì˜µë‹ˆë‹¤, etc.), write that sentence in í•©ë‹ˆë‹¤-style.
- If the student mixes styles within their response, you MUST reflect that mix in the `suggested_model_sentence`.
- **STRICTLY PROHIBITED:** Do NOT use ë°˜ë§ or plain dictionary-style endings (e.g., "â€‘ë‹¤"). ONLY use speech styles that are appropriate for an interview: either í•©ë‹ˆë‹¤-style or í•´ìš”-style, following the student's usage.

**ğŸ”¥ ANALYSIS REQUIREMENTS:** 

1. **Grammar Issues (3-6ê°œ, ë‹¤ì–‘í•œ ìœ í˜• ìš°ì„ )**
   - **ìš°ì„ ìˆœìœ„ ì ìš©**: ì˜ì‚¬ì†Œí†µì— ê°€ì¥ í° ì˜í–¥ì„ ì£¼ëŠ” ì˜¤ë¥˜ë¶€í„° ì„ íƒ
   - **ìœ í˜• ë‹¤ì–‘í™” í•„ìˆ˜**: ì¡°ì‚¬ ì˜¤ë¥˜ê°€ ë§ì•„ë„ ìµœëŒ€ 1-2ê°œë§Œ ì„ íƒí•˜ê³ , ë°˜ë“œì‹œ ë‹¤ë¥¸ ìœ í˜• í¬í•¨
   - **í¬í•¨í•  ìœ í˜•ë“¤**:
     * Particle (ì¡°ì‚¬): ê°€ì¥ ëª…í™•í•œ 1-2ê°œë§Œ (ì„/ë¥¼, ì€/ëŠ”, ì´/ê°€, ì— ë“±)
     * Verb Tense (ë™ì‚¬ ì‹œì œ): ê³¼ê±°/í˜„ì¬/ë¯¸ë˜ í˜¼ìš© ì˜¤ë¥˜
     * Verb Ending (ë™ì‚¬ ì–´ë¯¸): ë°˜ë§/ì¡´ëŒ“ë§, ë¶ˆê·œì¹™ í™œìš©, ì–´ë¯¸ ì„ íƒ
     * Word Order (ì–´ìˆœ): ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ì–´ìˆœ
     * Connectives (ì—°ê²°ì–´): ë¶€ì ì ˆí•œ ì—°ê²°í‘œí˜„, ê·¸ë¦¬ê³  ë‚¨ìš©
     * Others: ê¸°íƒ€ ë¬¸ë²• ì˜¤ë¥˜
   
   - **ì„ íƒ ê¸°ì¤€**: 
     1. ì˜ì‚¬ì†Œí†µì— ê°€ì¥ í° ì˜í–¥ì„ ì£¼ëŠ” ì˜¤ë¥˜
     2. ì´ˆê¸‰ìê°€ ìì£¼ í‹€ë¦¬ëŠ” íŒ¨í„´
     3. ì‰½ê²Œ ê³ ì¹  ìˆ˜ ìˆëŠ” ì˜¤ë¥˜
     
   - **MUST include "Original:" and "â†’ Fix:" format.**
   - **CRITICAL: DO NOT classify unnatural word choice as a grammar issue if the grammar itself is correct.**
   - **Target: Find 3-6 issues with TYPE DIVERSITY if they exist.**

2. **Vocabulary (2-3ê°œ, í•™ìƒ ë‹µë³€ ê¸°ë°˜ ì‹¤ìš©ì  ê°œì„ )**
   - **í•™ìƒì´ ì‹¤ì œë¡œ ì‚¬ìš©í•œ í‘œí˜„ì˜ ê°œì„ ì— ì´ˆì **
   - **í¬í•¨í•  ë‚´ìš©**:
     * ë¶€ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ â†’ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ (ì˜ˆ: "ë§ì´ ê°”ì–´ìš”" â†’ "ì—¬ëŸ¬ ê³³ì— ê°”ì–´ìš”")
     * ë°˜ë³µëœ ë‹¨ì–´ â†’ ë‹¤ì–‘í•œ í‘œí˜„ (ì˜ˆ: "ê·¸ë¦¬ê³ " ë‚¨ìš© â†’ ë‹¤ì–‘í•œ ì—°ê²°ì–´)
     * ë” ì •í™•í•œ ì–´íœ˜ ì„ íƒ (ë§¥ë½ì— ë§ëŠ” ë‹¨ì–´)
     * vs í˜•ì‹ ìœ ì§€í•˜ë˜ ì‹¤ìš©ì  ê°œì„ 
   
   - **Format: "â“ **Word A vs Word B**\\nğŸ’¡ Word A: [explanation of when to use A]\\nğŸ’¡ Word B: [explanation of when to use B]\\nğŸŸ¢ [examples showing both words in context]\\nğŸ“ [key difference and usage rule]"**
   - **Focus on student's actual expressions that could be more natural**
   - **Target: Provide 2-3 practical improvements when possible.**

3. **Content Expansion (2ê°œ, êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì )**
   - **í•™ìƒì´ ì–¸ê¸‰í•œ ì£¼ì œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í™•ì¥**
   - **ì˜ˆì‹œ**: í•™ìƒì´ "ë°”ë‹¤ ê°”ì–´ìš”"ë¼ê³  í–ˆìœ¼ë©´ â†’ "ë°”ë‹¤ì—ì„œ ìˆ˜ì˜ë„ í•˜ê³  ì¡°ê°œê»ë°ê¸°ë„ ì£¼ì› ì–´ìš”" ê°™ì€ êµ¬ì²´ì  í™•ì¥
   - Give two concrete, personal topics they can add based on what they mentioned.
   - Each idea should help them speak at least 30 more seconds.
   - Use examples they can directly copy.
   - **CRITICAL: Topic names must be in ENGLISH, Korean sentences in Korean.**
   
4. **One Advanced Pattern (í•™ìƒ ë‹µë³€ ê¸°ë°˜)**
   - **í•™ìƒì´ ì‚¬ìš©í•œ íŒ¨í„´ì„ í™•ì¥í•˜ëŠ” ë°©í–¥**
   - **ì˜ˆì‹œ**: í•™ìƒì´ "~ê³  ì‹¶ë‹¤" ë§ì´ ì‚¬ìš© â†’ "~ê³  ì‹¶ì–´ì„œ" ì´ìœ  í‘œí˜„ ê°€ë¥´ì¹˜ê¸°
   - Provide one useful pattern for the placement interview.
   - Must be appropriate for their level (TOPIK 1â€“2).
   - Connect to what the student actually said.

5. **ğŸ”¥ Sentence Connection Tip (í•™ìƒ ë‹µë³€ ê¸°ë°˜ ë¬¸ì¥ ì—°ê²°)**
   - **í•™ìƒì´ ì‹¤ì œë¡œ ì‚¬ìš©í•œ ì§§ì€ ë¬¸ì¥ë“¤ì„ ì°¾ì•„ì„œ ì—°ê²° ë°©ë²• ì œì‹œ**
   - **ì—°ê²°ì–´ í™œìš©**: ê·¸ë¦¬ê³ , ê·¸ë˜ì„œ, -ê³ , -ì•„ì„œ/ì–´ì„œ
   - **Before/After í˜•ì‹**ìœ¼ë¡œ ëª…í™•í•œ ê°œì„  ì˜ˆì‹œ ì œê³µ
   - **í•™ìƒì˜ ì‹¤ì œ ë°œí™”ì—ì„œ 2-3ê°œ ì§§ì€ ë¬¸ì¥ì„ ì„ íƒí•˜ì—¬ í•˜ë‚˜ì˜ ê¸´ ë¬¸ì¥ìœ¼ë¡œ ì—°ê²°**
   - **Format**: "ğŸ¯ **Tip for Longer Sentences**\\nâŒ [student's actual short sentences] \\nâœ… [combined longer sentence using connectives]\\nğŸ’¡ Use connectives like ê·¸ë¦¬ê³ , ê·¸ë˜ì„œ, -ê³ , -ì•„ì„œ/ì–´ì„œ to sound more natural"

**GRAMMAR ERROR TYPES**
- **Particle**: Wrong particle (ì€/ëŠ”, ì´/ê°€, ì„/ë¥¼, etc.)
- **Verb Ending**: Wrong verb ending or politeness ending (ì˜ˆìš”/ì´ì—ìš”, ì•„ìš”/ì–´ìš”, etc.)
- **Verb Tense**: Incorrect verb tense usage (past/present/future)
- **Word Order**: Unnatural word order
- **Connectives**: Inappropriate connecting expressions
- **Others**: For grammar mistakes that do not fit the above categories

**ğŸ”¥ Performance Summary (êµ¬ì²´ì  ë§ì¶¤í˜• í”¼ë“œë°±)**
- **êµ¬ì²´ì  ì¹­ì°¬**: í•™ìƒì´ ì‹¤ì œë¡œ ì˜í•œ ë¶€ë¶„ ì–¸ê¸‰ (ì˜ˆ: "Excellent! You covered both topics completely and explained WHY you want to work in Korea")
- **í•µì‹¬ ê°œì„ ì **: 2-3ê°œë¡œ ì§‘ì¤‘
- **ê°œì„  ì˜ˆë¬¸**: í•™ìƒ ë‹µë³€ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ êµ¬ì²´ì  ì˜ˆë¬¸ ì œì‹œ
- **ê¸¸ì´ í”¼ë“œë°±**: 90ì´ˆ ëª©í‘œ ì–¸ê¸‰

**Required JSON Structure:**
{{
    "suggested_model_sentence": "Natural, complete Korean sentence showing perfect answer",
    "suggested_model_sentence_english": "English translation",
    "grammar_issues": [
        "â—ï¸ [Type]\\nâ€¢ Original: '[exactly what they said]' â†’ Fix: '[corrected version]'\\nğŸ§  Simple explanation",
        "â—ï¸ [Type]\\nâ€¢ Original: '[exactly what they said]' â†’ Fix: '[corrected version]'\\nğŸ§  Simple explanation",
        "â—ï¸ [Type]\\nâ€¢ Original: '[exactly what they said]' â†’ Fix: '[corrected version]'\\nğŸ§  Simple explanation"
    ],
    "vocabulary_suggestions": [
        "â“ **Word A vs Word B**\\nğŸ’¡ Word A: [explanation of when to use A]\\nğŸ’¡ Word B: [explanation of when to use B]\\nğŸŸ¢ [examples showing both in context]\\nğŸ“ [key difference]",
        "â“ **Word A vs Word B**\\nğŸ’¡ Word A: [explanation of when to use A]\\nğŸ’¡ Word B: [explanation of when to use B]\\nğŸŸ¢ [examples showing both in context]\\nğŸ“ [key difference]"
    ],
    "content_expansion_suggestions": [
        "ğŸ’¬ Topic: [English topic name]\\nğŸ“ Example: '[Korean sentence they can use]'\\n   '[English translation]'",
        "ğŸ’¬ Topic: [English topic name]\\nğŸ“ Example: '[Korean sentence they can use]'\\n   '[English translation]'"
    ],
    "grammar_expression_tip": "ğŸš€ Try this: '[pattern]' = '[meaning]'\\nğŸ“ Example: '[Korean example]'\\nğŸ’¡ When to use: [simple explanation]",
    "sentence_connection_tip": "ğŸ¯ **Tip for Longer Sentences**\\nâŒ [student's actual short sentences from their response]\\nâœ… [combined longer sentence using connectives]\\nğŸ’¡ Use connectives like ê·¸ë¦¬ê³ , ê·¸ë˜ì„œ, -ê³ , -ì•„ì„œ/ì–´ì„œ to sound more natural",
    "interview_readiness_score": [1-10],
    "interview_readiness_reason": "Encouraging explanation of score with specific praise and improvements",
    "detailed_feedback": "ğŸŒŸ What You Did Well\\n- [specific praise point 1 with example from their answer]\\n- [specific praise point 2] ğŸ‘\\n\\nğŸ¯ Things to Improve\\n- [specific grammar issue with concrete example: 'Instead of X, try Y']\\n- [specific suggestion with clear example]\\n- [specific content suggestion with example]\\n\\nğŸ“ Try This Next Time\\n1. [actionable tip 1]\\n2. [actionable tip 2]\\n3. [actionable tip 3]"
}}

**Scoring Guide:**
- Score 8 to 10: Spoke 60s+, rich personal content, only minor errors
- Score 6 to 7: Spoke 60s+, good content, some errors but understandable
- Score 4 to 5: Spoke 60s+, basic content, several errors
- Score 1 to 3: Spoke under 60s, limited content, major communication issues"""


# === ë©”ì¸ í”¼ë“œë°± í•¨ìˆ˜ë“¤ (ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ ì ìš©) ===
def get_gpt_feedback(transcript, attempt_number=1, duration=0):
    """
    STT ê¸°ë°˜ ë£¨ë¸Œë¦­ì„ ì ìš©í•œ GPT í”¼ë“œë°± ìƒì„± (ì´ì¤‘ í‰ê°€ ì‹œìŠ¤í…œ ì ìš© + ê°œì„ ëœ í”„ë¡¬í”„íŠ¸)
    
    Args:
        transcript: ì „ì‚¬ëœ í…ìŠ¤íŠ¸
        attempt_number: ì‹œë„ ë²ˆí˜¸
        duration: ìŒì„± ê¸¸ì´ (ì´ˆ)
        
    Returns:
        dict: í•™ìƒìš© í”¼ë“œë°± (ì—°êµ¬ìš© ì ìˆ˜ëŠ” ë³„ë„ ì €ì¥)
    """
    if not OPENAI_API_KEY:
        st.error("Critical Error: OpenAI API key is required for feedback!")
        return {}
    
    # ê¸´ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ë¬¸ì ìˆ˜ ê¸°ë°˜)
    processed_transcript = preprocess_long_transcript(transcript)
    
    # ì „ì²˜ë¦¬ ê²°ê³¼ ë¡œê¹…
    if len(transcript) != len(processed_transcript):
        st.info(f"ğŸ“ Text processed: {len(transcript)} â†’ {len(processed_transcript)} characters for better AI analysis")
    
    # ğŸ”¥ ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‚¬ìš©
    enhanced_prompt_template = IMPROVED_FEEDBACK_PROMPT_TEMPLATE + f"""

**STUDENT SPEAKING DURATION:** {duration:.1f} seconds

**IMPORTANT TONE GUIDANCE - SPEAK DIRECTLY TO THE STUDENT:**
- Always use "You" instead of "The student" 
- Write feedback as if you're a warm Korean teacher talking directly to the student
- Be encouraging and personal: "Great job! You spoke for..." instead of "The student spoke for..."
- Use friendly, supportive language throughout all feedback sections

**REMEMBER: Write ALL feedback sections using "You" and speak directly to the student with warmth and encouragement!**

Use the actual duration ({duration:.1f}s) when generating your feedback and scoring."""

    prompt = generate_prompt(enhanced_prompt_template, question=EXPERIMENT_QUESTION, transcript=processed_transcript)
    debug_info = {
        'attempts': 0, 
        'errors': []
    }
    client = openai.OpenAI(api_key=OPENAI_API_KEY)
    
    # 2ë²ˆ ì‹œë„ (íƒ€ì„ì•„ì›ƒ 30ì´ˆë¡œ ì—°ì¥)
    for attempt in range(2):
        debug_info['attempts'] = attempt + 1
        
        try:
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": GPT_SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                timeout=30  # 20ì´ˆ â†’ 30ì´ˆë¡œ ì—°ì¥
            )
            
            raw_content = response.choices[0].message.content.strip()
            debug_info['errors'] = []  # ì„±ê³µì‹œ ì—ëŸ¬ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
            
            original_feedback = parse_gpt_response(raw_content)
            
            if original_feedback and original_feedback.get('suggested_model_sentence'):
                # ğŸ¯ ì´ì¤‘ í‰ê°€ ì‹œìŠ¤í…œ ì ìš©
                
                # 1. ì—°êµ¬ìš© ì ìˆ˜ ê³„ì‚°
                research_scores = get_research_scores(
                    transcript, 
                    original_feedback.get('grammar_issues', []), 
                    duration
                )
                
                # 2. í•™ìƒìš© í”¼ë“œë°± ìƒì„±
                student_feedback = get_student_feedback(
                    transcript, 
                    research_scores, 
                    original_feedback
                )
                
                # 3. ì„¸ì…˜ì— ì—°êµ¬ìš© ì ìˆ˜ ì €ì¥
                st.session_state.research_scores = research_scores
                
                # 4. ë””ë²„ê·¸ ì •ë³´ ì €ì¥
                st.session_state.gpt_debug_info = debug_info
                
                st.success("âœ… AI feedback ready!")
                return student_feedback
            else:
                raise ValueError("Missing required fields")
                
        except Exception as e:
            error_msg = f"Attempt {attempt + 1} failed: {str(e)}"
            debug_info['errors'].append(error_msg)
            
            if attempt < 1:
                st.warning(f"âš ï¸ AI feedback error, retrying...")
                time.sleep(0.5)
    
    # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ - fallback í”¼ë“œë°± ì‚¬ìš©
    st.error("âŒ AI feedback failed after 2 attempts")
    st.info("Using basic feedback to continue experiment")
    
    debug_info['errors'].append("All attempts failed - using fallback")
    st.session_state.gpt_debug_info = debug_info
    
    # Fallbackì—ì„œë„ ì´ì¤‘ í‰ê°€ ì‹œìŠ¤í…œ ì ìš©
    fallback_feedback = get_fallback_feedback()
    
    # Fallbackìš© ì—°êµ¬ ì ìˆ˜ ê³„ì‚°
    research_scores = get_research_scores(transcript, [], duration)
    student_feedback = get_student_feedback(transcript, research_scores, fallback_feedback)
    
    # ì„¸ì…˜ì— ì €ì¥
    st.session_state.research_scores = research_scores
    
    return student_feedback


def parse_gpt_response(raw_content):
    """GPT ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±"""
    try:
        result = json.loads(raw_content)
        return validate_and_fix_feedback(result)
    except json.JSONDecodeError:
        try:
            if "```json" in raw_content:
                start = raw_content.find("```json") + 7
                end = raw_content.find("```", start)
                clean_content = raw_content[start:end].strip()
                result = json.loads(clean_content)
                return validate_and_fix_feedback(result)
        except:
            pass
    
    return None


def validate_and_fix_feedback(feedback):
    """í”¼ë“œë°± êµ¬ì¡°ë¥¼ ê²€ì¦í•˜ê³  ëˆ„ë½ëœ í•„ìˆ˜ í•„ë“œë¥¼ ì¶”ê°€"""
    
    # ğŸ”¥ í•„ìˆ˜ í•„ë“œ ê¸°ë³¸ê°’ (vs ë°©ì‹ ì–´íœ˜íŒ + 2ì¸ì¹­ í†¤ + detailed_feedback + sentence_connection_tip)
    required_fields = {
        "suggested_model_sentence": "ì—¬ë¦„ ë°©í•™ì—ëŠ” ê°€ì¡±í•˜ê³  ì—¬í–‰ì„ ê°”ì–´ìš”. ë°”ë‹¤ì—ì„œ ìˆ˜ì˜ë„ í•˜ê³  ë§›ìˆëŠ” ìŒì‹ë„ ë§ì´ ë¨¹ì—ˆì–´ìš”. í•œêµ­ì—ì„œëŠ” í•œêµ­ì–´ ìˆ˜ì—…ì„ ë“¤ì„ ê±°ì˜ˆìš”. í•œêµ­ ë¬¸í™”ë¥¼ ë” ë°°ìš°ê³  ì‹¶ì–´ì„œ í•œêµ­ ì¹œêµ¬ë“¤ë„ ì‚¬ê·€ê³  ì‹¶ì–´ìš”.",
        "suggested_model_sentence_english": "During summer vacation, I went on a trip with my family. I swam in the sea and ate a lot of delicious food. In Korea, I will take Korean language classes. I want to learn more about Korean culture, so I want to make Korean friends too.",
        "content_expansion_suggestions": [
            "ğŸ’¬ Topic: Summer vacation details\\nğŸ“ Example: 'ì¹œêµ¬ë“¤í•˜ê³  ìº í•‘ë„ ê°”ì–´ìš”. ë°¤ì— ë³„ë„ ë³´ê³  ë°”ë² íë„ í–ˆì–´ìš”.'\\n   'I went camping with friends too. We looked at stars at night and had a barbecue.'",
            "ğŸ’¬ Topic: Specific plans in Korea\\nğŸ“ Example: 'í•œêµ­ ì „í†µ ìŒì‹ì„ ë°°ìš°ê³  ì‹¶ì–´ìš”. ê¹€ì¹˜ ë§Œë“œëŠ” ë°©ë²•ë„ ë°°ìš¸ ê±°ì˜ˆìš”.'\\n   'I want to learn Korean traditional food. I will also learn how to make kimchi.'"
        ],
        "vocabulary_suggestions": get_default_vocabulary_suggestions(),  # ğŸ”¥ vs ë°©ì‹ ì–´íœ˜íŒ
        "fluency_comment": "Keep practicing to speak more naturally!",
        "interview_readiness_score": 6,
        "sentence_connection_tip": "ğŸ¯ **Tip for Longer Sentences**\\nâŒ ë°”ë‹¤ ê°”ì–´ìš”. ìˆ˜ì˜í–ˆì–´ìš”.\\nâœ… ë°”ë‹¤ì— ê°€ì„œ ìˆ˜ì˜í–ˆì–´ìš”.\\nğŸ’¡ Use connectives like ê·¸ë¦¬ê³ , ê·¸ë˜ì„œ, -ê³ , -ì•„ì„œ/ì–´ì„œ to sound more natural",  # ğŸ”¥ ìƒˆë¡œ ì¶”ê°€
    "detailed_feedback": "ğŸŒŸ What You Did Well\\n- You answered both topics really well! I could clearly understand your summer vacation activities and your plans for Korea ğŸ˜Š\\n- Your motivation was so clear when you said 'í•œêµ­ ë¬¸í™”ë¥¼ ì¢‹ì•„í•´ì„œ' - that connection was perfect! ğŸ‘\\n- I loved how you mentioned specific activities like going to the beach. That made your answer much more interesting!\\n\\nğŸ¯ Key Improvements\\n- I noticed some particles were missing. For example, you said 'ì¹œêµ¬ ë§Œë‚¬ì–´ìš”' but it should be 'ì¹œêµ¬ë¥¼ ë§Œë‚¬ì–´ìš”' to sound more natural\\n- Try to keep your tense consistent - when talking about past vacation, stick with past tense endings like 'ê°”ì–´ìš”, í–ˆì–´ìš”'\\n- Your answer was a bit short (about 45 seconds). Try to add one more detail for each topic to reach 90+ seconds\\n\\nğŸ“ Try This Next Time\\n1. Before speaking, quickly think: 'Am I using ì„/ë¥¼ correctly?'\\n2. Add one specific example when explaining reasons: 'I like Korean food, especially kimchi and bulgogi'\\n3. Use connecting words like 'ê·¸ë¦¬ê³ ' or 'ê·¸ë˜ì„œ' to make longer, smoother sentences",
        "encouragement_message": "Every practice makes you better! You're doing great learning Korean!"
    }
    
    feedback = ensure_required_fields(feedback, required_fields)
    
    # ğŸ”¥ Grammar issues ê²€ì¦ ë° ê°œì„  (ìµœëŒ€ 6ê°œ, ëª¨ë“  ì˜¤ë¥˜ í‘œì‹œ + ìœ í˜• ë¶„ë¥˜ ìœ ì§€)
    if 'grammar_issues' in feedback and feedback['grammar_issues']:
        valid_issues = []
        for i, issue in enumerate(feedback['grammar_issues'][:6]):  # ìµœëŒ€ 6ê°œ
            if isinstance(issue, str) and len(issue) > 10:
                # ğŸ¯ ì˜¤ë¥˜ íƒ€ì… ë¶„ë¥˜ (3ê°œ ì£¼ìš” ìœ í˜• + ê¸°íƒ€)
                error_type = classify_error_type(issue)
                if not error_type:  # 3ê°œ ìœ í˜•ì— í•´ë‹¹í•˜ì§€ ì•Šìœ¼ë©´
                    error_type = "Others"  # "Others" ìœ í˜•ìœ¼ë¡œ ë¶„ë¥˜
                
                # ğŸ”¥ ëª¨ë“  ìœ íš¨í•œ ë¬¸ë²• ì˜¤ë¥˜ë¥¼ í¬í•¨ (í•„í„°ë§ ì œê±°)
                standardized_issue = standardize_grammar_issue(issue, error_type)
                valid_issues.append(standardized_issue)
        
        if valid_issues:
            feedback['grammar_issues'] = valid_issues
        else:
            feedback['grammar_issues'] = get_default_grammar_issues()
    else:
        feedback['grammar_issues'] = get_default_grammar_issues()
    
    # ğŸ”¥ Vocabulary suggestions ì¬êµ¬ì„± (vs ë°©ì‹ + ìŠ¤ë§ˆíŠ¸ ì¤‘ë³µ í•„í„°ë§)
    if 'vocabulary_suggestions' in feedback and feedback['vocabulary_suggestions']:
        # ğŸ¯ ìŠ¤ë§ˆíŠ¸í•œ ì¤‘ë³µ í•„í„°ë§: ì‹¤ì œ ë¬¸ë²• í”¼ë“œë°±ê³¼ ì¤‘ë³µë˜ëŠ” ë‚´ìš©ë§Œ ì œê±°
        filtered_vocab = filter_grammar_from_vocabulary(
            feedback['vocabulary_suggestions'], 
            feedback.get('grammar_issues', [])
        )
        
        if filtered_vocab:
            # GPTê°€ ìƒì„±í•œ vs ë°©ì‹ ì–´íœ˜ ì œì•ˆì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
            feedback['vocabulary_suggestions'] = filtered_vocab[:2]  # ìµœëŒ€ 2ê°œ
        else:
            # ëª¨ë“  ì–´íœ˜ ì œì•ˆì´ ë¬¸ë²•ê³¼ ì¤‘ë³µë˜ì–´ í•„í„°ë§ëœ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
            feedback['vocabulary_suggestions'] = get_default_vocabulary_suggestions()
    else:
        # GPTê°€ ì–´íœ˜ ì œì•ˆì„ ìƒì„±í•˜ì§€ ì•Šì•˜ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        feedback['vocabulary_suggestions'] = get_default_vocabulary_suggestions()
    
    # ì ìˆ˜ ê²€ì¦
    score = feedback.get("interview_readiness_score", 6)
    if not isinstance(score, (int, float)) or score < 1 or score > 10:
        feedback["interview_readiness_score"] = 6
    
    return feedback


def standardize_grammar_issue(issue_text, error_type):
    """ë¬¸ë²• ì´ìŠˆë¥¼ ê°„ë‹¨í•œ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    
    # Originalê³¼ Fix ì¶”ì¶œ
    original_text = ""
    fix_text = ""
    explanation = ""
    
    if "Original:" in issue_text and "â†’" in issue_text:
        try:
            original_text = issue_text.split("Original:")[1].split("â†’")[0].strip().strip("'\"")
            if "Fix:" in issue_text:
                fix_text = issue_text.split("Fix:")[1].split("ğŸ§ ")[0].strip().strip("'\"")
            else:
                fix_text = issue_text.split("â†’")[1].split("ğŸ§ ")[0].strip().strip("'\"")
            
            if "ğŸ§ " in issue_text:
                explanation = issue_text.split("ğŸ§ ")[1].strip()
                # "Simple explanation:" ì œê±°
                explanation = re.sub(r'^(?:ğŸ’¡\s*)?Simple explanation:\s*', '', explanation)
        except:
            pass
    
    # ê°„ë‹¨í•œ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±
    if original_text and fix_text:
        if not explanation:
            explanation = get_default_explanation(error_type)
        
        return f"{error_type}|{original_text}|{fix_text}|{explanation}"
    else:
        # í˜•ì‹ì´ ëª…í™•í•˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ ì²˜ë¦¬
        return f"{error_type}||Basic grammar point|Review this grammar carefully"


def get_default_explanation(error_type):
    """ì˜¤ë¥˜ íƒ€ì…ë³„ ê¸°ë³¸ ì„¤ëª… (4ê°œ ìœ í˜• ì§€ì›)"""
    explanations = {
        "Particle": "Use the appropriate particle to mark the grammatical role",
        "Verb Ending": "Use the correct verb ending form",
        "Verb Tense": "Use the appropriate tense marker",
        "Others": "Review this grammar point carefully"  # ğŸ”¥ "Others" ìœ í˜• ì¶”ê°€
    }
    return explanations.get(error_type, "Review this grammar point")


def get_default_grammar_issues():
    """ê¸°ë³¸ ë¬¸ë²• ì´ìŠˆë“¤ (3ê°œ ì£¼ìš” ìœ í˜•)"""
    return [
        "Particle|ì €ëŠ” ê²½ì œ ì „ê³µì´ì—ìš”|ì €ëŠ” ê²½ì œë¥¼ ì „ê³µí•´ìš”|Use 'ë¥¼' to indicate the object and change 'ì „ê³µì´ì—ìš”' to 'ì „ê³µí•´ìš”'",
        "Verb Ending|ì¢‹ì•„ìš”|ì¢‹ì•„í•´ìš”|Use 'ì¢‹ì•„í•´ìš”' when expressing that you like doing activities",
        "Verb Tense|ì–´ì œ ê°€ìš”|ì–´ì œ ê°”ì–´ìš”|Use past tense with time indicators like 'ì–´ì œ'"
    ]


def get_fallback_feedback():
    """API ì‹¤íŒ¨ì‹œ ì‚¬ìš©í•  ê¸°ë³¸ í”¼ë“œë°± (60-120ì´ˆ ê¸°ì¤€, vs ë°©ì‹ ì–´íœ˜ ì œì•ˆ í¬í•¨, 2ì¸ì¹­ í†¤, detailed_feedback í¬í•¨, sentence_connection_tip ì¶”ê°€)"""
    return {
        "suggested_model_sentence": "ì—¬ë¦„ ë°©í•™ì—ëŠ” ê°€ì¡±í•˜ê³  ì—¬í–‰ì„ ê°”ì–´ìš”. ë°”ë‹¤ì—ì„œ ìˆ˜ì˜ë„ í•˜ê³  ë§›ìˆëŠ” ìŒì‹ë„ ë§ì´ ë¨¹ì—ˆì–´ìš”. í•œêµ­ì—ì„œëŠ” í•œêµ­ì–´ ìˆ˜ì—…ì„ ë“¤ì„ ê±°ì˜ˆìš”. í•œêµ­ ë¬¸í™”ë¥¼ ë” ë°°ìš°ê³  ì‹¶ì–´ì„œ í•œêµ­ ì¹œêµ¬ë“¤ë„ ì‚¬ê·€ê³  ì‹¶ì–´ìš”.",
        "suggested_model_sentence_english": "During summer vacation, I went on a trip with my family. I swam in the sea and ate a lot of delicious food. In Korea, I will take Korean language classes. I want to learn more about Korean culture, so I want to make Korean friends too.",
        "grammar_issues": get_default_grammar_issues(),
        "vocabulary_suggestions": get_default_vocabulary_suggestions(),  # ğŸ”¥ vs ë°©ì‹ ì–´íœ˜íŒ í¬í•¨
        "content_expansion_suggestions": [
            "ğŸ’¬ Topic: Summer vacation details\\nğŸ“ Example: 'ì¹œêµ¬ë“¤í•˜ê³  ìº í•‘ë„ ê°”ì–´ìš”. ë°¤ì— ë³„ë„ ë³´ê³  ë°”ë² íë„ í–ˆì–´ìš”.'\\n   'I went camping with friends too. We looked at stars at night and had a barbecue.'",
            "ğŸ’¬ Topic: Specific plans in Korea\\nğŸ“ Example: 'í•œêµ­ ì „í†µ ìŒì‹ì„ ë°°ìš°ê³  ì‹¶ì–´ìš”. ê¹€ì¹˜ ë§Œë“œëŠ” ë°©ë²•ë„ ë°°ìš¸ ê±°ì˜ˆìš”.'\\n   'I want to learn Korean traditional food. I will also learn how to make kimchi.'"
        ],
        "grammar_expression_tip": "ğŸš€ Try: 'ì €ëŠ” Xë¥¼ ì¢‹ì•„í•´ìš”' = 'I like X'\\nğŸ“ Example: 'ì €ëŠ” í•œêµ­ ìŒì‹ì„ ì¢‹ì•„í•´ìš”'\\nğŸ’¡ Use to express preferences",
        "sentence_connection_tip": "ğŸ¯ **Tip for Longer Sentences**\\nâŒ ë°”ë‹¤ ê°”ì–´ìš”. ìˆ˜ì˜í–ˆì–´ìš”.\\nâœ… ë°”ë‹¤ì— ê°€ì„œ ìˆ˜ì˜í–ˆì–´ìš”.\\nğŸ’¡ Use connectives like ê·¸ë¦¬ê³ , ê·¸ë˜ì„œ, -ê³ , -ì•„ì„œ/ì–´ì„œ to sound more natural",  # ğŸ”¥ ìƒˆë¡œ ì¶”ê°€
        "fluency_comment": "Keep practicing! Try to speak for at least 60+ seconds to build fluency.",
        "interview_readiness_score": 5,
        "detailed_feedback": "Good effort attempting both topics! Here are some tips to improve: â€¢ Try to speak for at least 60+ seconds to meet interview expectations â€¢ Add specific details about your experiences - what exactly did you do? â€¢ Practice connecting your ideas with phrases like 'ê·¸ë¦¬ê³ ' (and) and 'ê·¸ë˜ì„œ' (so/therefore) to sound more natural",
        "encouragement_message": "Every practice session helps! Keep going! í™”ì´íŒ…!"
    }


def get_improvement_assessment(first_transcript, second_transcript, original_feedback):
    """STT ê¸°ë°˜ ë£¨ë¸Œë¦­ì„ ì‚¬ìš©í•œ ê°œì„ ë„ í‰ê°€ (2ì¸ì¹­ í†¤)"""
    if not OPENAI_API_KEY:
        return get_fallback_improvement_assessment()
    
    # ğŸ”¥ ê°œì„ ë„ í‰ê°€ í”„ë¡¬í”„íŠ¸ì—ë„ 2ì¸ì¹­ í†¤ ì§€ì¹¨ ì¶”ê°€
    enhanced_improvement_template = IMPROVEMENT_PROMPT_TEMPLATE.replace(
        "**Task:** Evaluate improvement between attempts. Be encouraging and specific!",
        """**Task:** Evaluate improvement between attempts. Be encouraging and specific!

**IMPORTANT TONE GUIDANCE - SPEAK DIRECTLY TO THE STUDENT:**
- Always use "You" instead of "The student" 
- Write feedback as if you're a warm Korean teacher talking directly to the student
- Be encouraging and personal: "Great improvement! You spoke much longer..." instead of "The student improved..."
- Use friendly, supportive language throughout all assessment sections"""
    )
    
    prompt = generate_prompt(
        enhanced_improvement_template,
        question=EXPERIMENT_QUESTION,
        first_transcript=first_transcript,
        second_transcript=second_transcript,
        original_feedback=json.dumps(original_feedback, ensure_ascii=False)
    )
    
    try:
        client = openai.OpenAI(api_key=OPENAI_API_KEY)
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are a Korean teacher evaluating progress. Respond only with valid JSON. Always speak directly to the student using 'You' instead of 'The student'."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            timeout=15
        )
        
        raw_content = response.choices[0].message.content.strip()
        result = parse_gpt_response(raw_content)
        
        if result:
            return validate_and_fix_improvement(result)
        else:
            raise ValueError("Failed to parse response")
            
    except Exception as e:
        print(f"Improvement assessment failed: {e}")
        return get_fallback_improvement_assessment()


def validate_and_fix_improvement(improvement):
    """ê°œì„ ë„ í‰ê°€ë¥¼ ê²€ì¦í•˜ê³  ëˆ„ë½ëœ í•„ìˆ˜ í•„ë“œë¥¼ ì¶”ê°€ (2ì¸ì¹­ í†¤)"""
    required_fields = {
        "first_attempt_score": 5,
        "second_attempt_score": 5,
        "score_difference": 0,
        "improvement_score": 5,
        "improvement_reason": "Continue practicing for better fluency and accuracy",
        "specific_improvements": ["Attempted Korean speaking practice"],
        "remaining_issues": ["Focus on speaking longer (60+ seconds) with more details and address both topics"],
        "feedback_application": "unknown",
        "overall_assessment": "Keep practicing! Focus on speaking for 60+ seconds with personal details and clear reasons for both topics.",
        "encouragement_message": "Every practice session makes you better! Keep going!"
    }
    
    improvement = ensure_required_fields(improvement, required_fields)
    
    # ì ìˆ˜ë“¤ ê²€ì¦ (1-10 ë²”ìœ„)
    score_fields = ["first_attempt_score", "second_attempt_score", "improvement_score"]
    for field in score_fields:
        score = improvement.get(field, 5)
        if not isinstance(score, (int, float)) or score < 1 or score > 10:
            improvement[field] = 5
    
    # score_difference ê³„ì‚°
    try:
        improvement["score_difference"] = improvement["second_attempt_score"] - improvement["first_attempt_score"]
    except:
        improvement["score_difference"] = 0
    
    # ë¦¬ìŠ¤íŠ¸ í•„ë“œë“¤ ê²€ì¦
    list_fields = ["specific_improvements", "remaining_issues"]
    for field in list_fields:
        if not isinstance(improvement.get(field), list) or not improvement[field]:
            improvement[field] = ["Attempted Korean speaking practice"] if field == "specific_improvements" else ["Continue practicing for better fluency"]
    
    # feedback_application ê²€ì¦
    valid_applications = ["excellent", "good", "partial", "poor", "unclear"]
    if improvement.get("feedback_application") not in valid_applications:
        improvement["feedback_application"] = "unclear"
    
    return improvement


def get_fallback_improvement_assessment():
    """ê°œì„ ë„ í‰ê°€ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’ (2ì¸ì¹­ í†¤)"""
    return {
        "first_attempt_score": 5,
        "second_attempt_score": 5,
        "score_difference": 0,
        "improvement_score": 5,
        "improvement_reason": "Technical error - manual review needed",
        "specific_improvements": ["You attempted Korean speaking practice"],
        "remaining_issues": ["Practice speaking for at least 60-120 seconds"],
        "feedback_application": "unknown",
        "overall_assessment": "Keep practicing - focus on at least 60-120 seconds with personal details",
        "encouragement_message": "Every practice session makes you better! Keep going!"
    }


def get_score_category_info(score):
    """ì ìˆ˜ì— ë”°ë¥¸ ì¹´í…Œê³ ë¦¬ ì •ë³´ ë°˜í™˜"""
    for category, info in STT_RUBRIC.items():
        if info["min_score"] <= score <= info["max_score"]:
            return info
    return STT_RUBRIC["fair"]


def display_score_with_category(score, label="Score"):
    """ì ìˆ˜ë¥¼ ì¹´í…Œê³ ë¦¬ì™€ í•¨ê»˜ í‘œì‹œ"""
    if isinstance(score, (int, float)):
        category_info = get_score_category_info(score)
        st.markdown(
            f"<h2 style='color: {category_info['color']}; text-align: center;'>{score}/10</h2>", 
            unsafe_allow_html=True
        )
        st.markdown(
            f"<p style='color: {category_info['color']}; text-align: center; font-weight: bold;'>{category_info['label']}</p>", 
            unsafe_allow_html=True
        )
    else:
        st.write(f"**{label}:** {score}")


def display_score_with_encouragement(score, duration=0):
    """ì ìˆ˜ë¥¼ ê²©ë ¤ ë©”ì‹œì§€ì™€ í•¨ê»˜ í‘œì‹œ (60-120ì´ˆ ê¸°ì¤€)"""
    category_info = get_score_category_info(score)
    
    # ì ìˆ˜ í‘œì‹œ
    st.markdown(
        f"<h2 style='color: {category_info['color']}; text-align: center; margin: 20px 0;'>{score}/10</h2>", 
        unsafe_allow_html=True
    )
    
    # ğŸ”¥ ê²©ë ¤ ë©”ì‹œì§€ (TOPIK ê¸°ì¤€ìœ¼ë¡œ ìˆ˜ì •, 60-120ì´ˆ ëª©í‘œ)
    if score >= 8:
        st.balloons()
        message = "ğŸŒŸ Outstanding! Excellent task completion with rich content!"
        if duration >= 90:
            message += " Perfect length too!"
    elif score >= 7:
        message = "ğŸ¯ Great job! Good task completion and content!"
        if duration < 60:
            message += " Try to speak for at least 60 seconds next time."
    elif score >= 6:
        message = "ğŸ’ª Good work! You're improving steadily!"
        if duration < 60:
            message += " Aim for 60+ seconds."
    elif score >= 5:
        message = "ğŸš€ Keep going! You're learning!"
        if duration < 60:
            message += " Focus on reaching 60 seconds."
    else:
        message = "ğŸŒ± Everyone starts somewhere! Keep practicing!"
        message += " Work towards 60+ seconds with both topics covered."
    
    # ë©”ì‹œì§€ í‘œì‹œ
    st.markdown(
        f"""
        <div style='
            background-color: {category_info['color']}20;
            border: 2px solid {category_info['color']};
            border-radius: 10px;
            padding: 15px;
            text-align: center;
            margin: 10px 0;
        '>
            <p style='
                color: {category_info['color']};
                font-weight: bold;
                font-size: 16px;
                margin: 0;
            '>
                {message}
            </p>
        </div>
        """,
        unsafe_allow_html=True
    )