"""
feedback.py
GPTë¥¼ ì´ìš©í•œ í•œêµ­ì–´ í•™ìŠµ í”¼ë“œë°± ìƒì„± (tiktoken ì œê±° - ë¬¸ì ìˆ˜ ê¸°ë°˜ ì²˜ë¦¬)
"""

import openai
import json
import time
import re  # ì¶”ê°€: Simple explanation ë ˆì´ë¸” ì œê±°ìš©
import streamlit as st
from config import (
    OPENAI_API_KEY, 
    EXPERIMENT_QUESTION, 
    GPT_SYSTEM_PROMPT, 
    STT_RUBRIC,
    FEEDBACK_PROMPT_TEMPLATE,
    IMPROVEMENT_PROMPT_TEMPLATE,
    FALLBACK_FEEDBACK_DATA,
    FALLBACK_IMPROVEMENT_DATA,
    GRAMMAR_ERROR_TYPES,
    FEEDBACK_LEVEL,
    GPT_FEEDBACK_MAX_TOKENS,
    GPT_FEEDBACK_MAX_CHARS
)


# === ê°„ì†Œí™”ëœ ì˜¤ë¥˜ ë¶„ë¥˜ ìƒìˆ˜ ===
INDIVIDUAL_PARTICLES = ["ì„", "ë¥¼", "ì€", "ëŠ”", "ì´", "ê°€", "ì—ì„œ", "ì—ê²Œ", "ì—", "ì™€", "ê³¼", "ì˜", "ë¡œ", "ìœ¼ë¡œ"]
TIME_INDICATORS = ["ì–´ì œ", "ë‚´ì¼", "ì§€ê¸ˆ", "ì˜¤ëŠ˜", "ë‚´ë…„", "ì‘ë…„", "ë‹¤ìŒ ì£¼", "ì§€ë‚œì£¼", "ë°©ê¸ˆ", "ë‚˜ì¤‘ì—"]
VERB_ENDINGS = ["ì˜ˆìš”", "ì´ì—ìš”", "ì•„ìš”", "ì–´ìš”", "ìŠµë‹ˆë‹¤", "ì„¸ìš”", "ã…‚ë‹ˆë‹¤"]
TENSE_MARKERS = ["í–ˆì–´ìš”", "í•  ê±°ì˜ˆìš”", "í•˜ê³  ìˆì–´ìš”", "í•œ ì ì´", "í–ˆì—ˆì–´ìš”", "í• ê²Œìš”"]

# ì´ˆê¸‰ í•™ìŠµì ìì£¼ í‹€ë¦¬ëŠ” íŒ¨í„´
COMMON_BEGINNER_ERRORS = {
    "ì¢‹ì•„ìš”_ì¢‹ì•„í•´ìš”": {"pattern": "ì¢‹ì•„ìš”", "correct": "ì¢‹ì•„í•´ìš”", "type": "Verb Ending"},
    "ì…ë‹ˆë‹¤_ì´ì—ìš”": {"pattern": "ì…ë‹ˆë‹¤", "correct": "ì´ì—ìš”", "type": "Verb Ending"},
    "ì „ê³µì´ì—ìš”_ì „ê³µí•´ìš”": {"pattern": "ì „ê³µì´ì—ìš”", "correct": "ì „ê³µí•´ìš”", "type": "Verb Ending"}
}


# === ê¸´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ (ë¬¸ì ìˆ˜ ê¸°ë°˜ë§Œ) ===
def split_korean_sentences(text):
    """
    í•œêµ­ì–´ ë¬¸ì¥ì„ ì ì ˆíˆ ë¶„í• 
    
    Args:
        text: ë¶„í• í•  í…ìŠ¤íŠ¸
        
    Returns:
        list: ë¶„í• ëœ ë¬¸ì¥ë“¤
    """
    # í•œêµ­ì–´ ë¬¸ì¥ êµ¬ë¶„ì: ., !, ?, ìš”/ì–´ìš”/ìŠµë‹ˆë‹¤ ë’¤ì˜ ê³µë°±
    pattern = r'([.!?]|(?:ìš”|ì–´ìš”|ìŠµë‹ˆë‹¤|ì„¸ìš”|í•´ìš”|ì´ì—ìš”|ì˜ˆìš”)\s*)'
    sentences = re.split(pattern, text)
    
    # ë¶„í• ëœ ë¶€ë¶„ì„ ë‹¤ì‹œ ì¡°í•©
    result = []
    for i in range(0, len(sentences)-1, 2):
        if i+1 < len(sentences):
            sentence = sentences[i] + sentences[i+1]
            if sentence.strip():
                result.append(sentence.strip())
    
    # ë§ˆì§€ë§‰ ë¶€ë¶„ì´ ë‚¨ì•„ìˆë‹¤ë©´ ì¶”ê°€
    if len(sentences) % 2 == 1 and sentences[-1].strip():
        result.append(sentences[-1].strip())
    
    return [s for s in result if len(s.strip()) > 3]  # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ ì œì™¸


def preprocess_long_transcript_fallback(transcript, max_chars=GPT_FEEDBACK_MAX_CHARS):
    """
    ë¬¸ì ìˆ˜ ê¸°ë°˜ ê¸´ í…ìŠ¤íŠ¸ ì²˜ë¦¬
    
    Args:
        transcript: ì „ì‚¬ëœ í…ìŠ¤íŠ¸
        max_chars: ìµœëŒ€ ë¬¸ì ìˆ˜
        
    Returns:
        str: ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸
    """
    if len(transcript) <= max_chars:
        return transcript
    
    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸° ì‹œë„
    sentences = split_korean_sentences(transcript)
    
    if not sentences:
        # ë¬¸ì¥ ë¶„í•  ì‹¤íŒ¨ì‹œ ì ë‹¹í•œ ìœ„ì¹˜ì—ì„œ ìë¥´ê¸°
        cutoff = transcript.rfind(' ', 0, max_chars)
        if cutoff == -1:
            cutoff = max_chars
        return transcript[:cutoff]
    
    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìµœëŒ€í•œ í¬í•¨
    result = ""
    for sentence in sentences:
        temp = result + " " + sentence if result else sentence
        if len(temp) <= max_chars:
            result = temp
        else:
            break
    
    return result if result else sentences[0][:max_chars]


def preprocess_long_transcript(transcript):
    """
    ê¸´ ì „ì‚¬ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜ (ë¬¸ì ìˆ˜ ê¸°ë°˜ë§Œ ì‚¬ìš©)
    
    Args:
        transcript: ì „ì‚¬ëœ í…ìŠ¤íŠ¸
        
    Returns:
        str: ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸
    """
    if not transcript or len(transcript.strip()) == 0:
        return transcript
    
    # ê°„ë‹¨í•œ ì •ë¦¬
    cleaned = transcript.strip()
    
    # ë¬¸ì ìˆ˜ ê¸°ë°˜ ì²˜ë¦¬ (tiktoken ì œê±°)
    if len(cleaned) <= GPT_FEEDBACK_MAX_CHARS:
        return cleaned
    else:
        # ê¸´ í…ìŠ¤íŠ¸ëŠ” ë¬¸ì ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸°
        return preprocess_long_transcript_fallback(cleaned)


# === ê°„ì†Œí™”ëœ ì˜¤ë¥˜ ë¶„ë¥˜ í•¨ìˆ˜ (3ê°œ ìœ í˜•ë§Œ) ===
def classify_error_type(issue_text):
    """
    í”¼ë“œë°± í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ 3ê°œ ì˜¤ë¥˜ íƒ€ì… ì¤‘ í•˜ë‚˜ ë°˜í™˜
    
    Args:
        issue_text: ë¶„ì„í•  í”¼ë“œë°± í…ìŠ¤íŠ¸
        
    Returns:
        str: ë¶„ë¥˜ëœ ì˜¤ë¥˜ íƒ€ì… (Particle, Verb Ending, Verb Tense) ë˜ëŠ” None
    """
    issue_lower = issue_text.lower()
    
    # Originalê³¼ Fix ë¶€ë¶„ ì¶”ì¶œ
    original_text = ""
    fix_text = ""
    if "Original:" in issue_text and "â†’" in issue_text:
        try:
            original_text = issue_text.split("Original:")[1].split("â†’")[0].strip().strip("'\"")
            if "Fix:" in issue_text:
                fix_text = issue_text.split("Fix:")[1].strip().strip("'\"")
            else:
                fix_text = issue_text.split("â†’")[1].strip().strip("'\"")
        except:
            pass
    
    # 1. ì´ˆê¸‰ì ìì£¼ í‹€ë¦¬ëŠ” íŒ¨í„´ ìš°ì„  í™•ì¸
    for pattern_info in COMMON_BEGINNER_ERRORS.values():
        if pattern_info["pattern"] in original_text and pattern_info["correct"] in fix_text:
            return pattern_info["type"]
    
    # 2. Particle í™•ì¸
    for particle in INDIVIDUAL_PARTICLES:
        if f"'{particle}'" in issue_text or f" {particle} " in issue_text:
            return "Particle"
        if particle in fix_text and particle not in original_text:
            return "Particle"
    
    if "particle" in issue_lower or "ì¡°ì‚¬" in issue_text:
        return "Particle"
    
    # 3. Verb Tense í™•ì¸ (ì‹œê°„ í‘œí˜„ì´ ìˆëŠ” ê²½ìš°)
    for indicator in TIME_INDICATORS + TENSE_MARKERS:
        if indicator in issue_text:
            return "Verb Tense"
    
    if "tense" in issue_lower or "ì‹œì œ" in issue_text:
        return "Verb Tense"
    
    # 4. Verb Ending í™•ì¸
    for ending in VERB_ENDINGS:
        if ending in issue_text:
            return "Verb Ending"
    
    if "ending" in issue_lower or "verb form" in issue_lower or "ì–´ë¯¸" in issue_text:
        return "Verb Ending"
    
    # 5. 3ê°œ ìœ í˜•ì— í•´ë‹¹í•˜ì§€ ì•Šìœ¼ë©´ None ë°˜í™˜
    return None


# === ì–´íœ˜ í•„í„°ë§ í•¨ìˆ˜ ===
def filter_grammar_from_vocabulary(vocab_suggestions):
    """
    vocabularyì—ì„œ ë¬¸ë²• ê´€ë ¨ í•­ëª© ì œê±°
    
    Args:
        vocab_suggestions: ì–´íœ˜ ì œì•ˆ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        list: ë¬¸ë²• ê´€ë ¨ í•­ëª©ì´ ì œê±°ëœ ìˆœìˆ˜ ì–´íœ˜ ì œì•ˆ ë¦¬ìŠ¤íŠ¸
    """
    # í•„í„°ë§í•  ë¬¸ë²• í‚¤ì›Œë“œë“¤
    grammar_keywords = [
        # ì¡°ì‚¬
        "ì„", "ë¥¼", "ì€", "ëŠ”", "ì´", "ê°€", "ì—ì„œ", "ì—ê²Œ", "ì—", "ì™€", "ê³¼", "ì˜", "ë¡œ", "ìœ¼ë¡œ",
        # ì–´ë¯¸
        "ì˜ˆìš”", "ì´ì—ìš”", "ì•„ìš”", "ì–´ìš”", "ìŠµë‹ˆë‹¤", "ì„¸ìš”", "ã…‚ë‹ˆë‹¤",
        # ì‹œì œ
        "í–ˆì–´ìš”", "í• ê²Œìš”", "í•  ê±°ì˜ˆìš”", "í•˜ê³  ìˆì–´ìš”", "ê°”ì–´ìš”", "ì™”ì–´ìš”",
        # ë¬¸ë²• ê´€ë ¨ ë‹¨ì–´ë“¤
        "particle", "ending", "tense", "ì¡°ì‚¬", "ì–´ë¯¸", "ì‹œì œ", "grammar"
    ]
    
    filtered = []
    for tip in vocab_suggestions:
        # ë¬¸ë²• í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì œì™¸
        tip_lower = tip.lower()
        is_grammar = any(keyword in tip_lower for keyword in grammar_keywords)
        
        if not is_grammar:
            filtered.append(tip)
    
    return filtered[:2]  # ìµœëŒ€ 2ê°œë§Œ


def get_pure_vocabulary_suggestions():
    """ìˆœìˆ˜ ì–´íœ˜ ì„ íƒ ê¸°ë³¸ ì˜ˆì‹œë“¤ (vs ë°©ì‹ìœ¼ë¡œ ë³€ê²½)"""
    return [
        "â“ **ê³µë¶€í•˜ë‹¤ vs ë°°ìš°ë‹¤**\\nğŸ’¡ ê³µë¶€í•˜ë‹¤: Academic studying or reviewing material at a desk\\nğŸ’¡ ë°°ìš°ë‹¤: Learning new skills or acquiring new knowledge\\nğŸŸ¢ ì‹œí—˜ì„ ìœ„í•´ ê³µë¶€í•´ìš” (I study for exams) / í•œêµ­ì–´ë¥¼ ë°°ìš°ê³  ìˆì–´ìš” (I'm learning Korean)\\nğŸ“ Use 'ë°°ìš°ë‹¤' for new skills, 'ê³µë¶€í•˜ë‹¤' for reviewing",
        "â“ **ì¢‹ë‹¤ vs ì¢‹ì•„í•˜ë‹¤**\\nğŸ’¡ ì¢‹ë‹¤: Adjective - something is good (state/quality)\\nğŸ’¡ ì¢‹ì•„í•˜ë‹¤: Verb - to like something (preference)\\nğŸŸ¢ ë‚ ì”¨ê°€ ì¢‹ì•„ìš” (The weather is nice) / ìŒì•…ì„ ì¢‹ì•„í•´ìš” (I like music)\\nğŸ“ Use 'ì´/ê°€ ì¢‹ë‹¤' vs 'ì„/ë¥¼ ì¢‹ì•„í•˜ë‹¤'",
        "â“ **ì—¬í–‰í•˜ë‹¤ vs ~ì— ì—¬í–‰ ê°€ë‹¤**\\nğŸ’¡ ì—¬í–‰í•˜ë‹¤: General traveling activity\\nğŸ’¡ ~ì— ì—¬í–‰ ê°€ë‹¤: Going to a specific destination\\nğŸŸ¢ ì—¬ë¦„ì— ì—¬í–‰í•´ìš” (I travel in summer) / ì œì£¼ë„ì— ì—¬í–‰ ê°”ì–´ìš” (I went on a trip to Jeju)\\nğŸ“ Use 'ì¥ì†Œì— ì—¬í–‰ ê°€ë‹¤' when destination is important"
    ]


def ensure_required_fields(data, required_fields):
    """í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ëœ ê²½ìš° ê¸°ë³¸ê°’ìœ¼ë¡œ ë³´ì™„"""
    for field, default_value in required_fields.items():
        if field not in data or not data[field]:
            data[field] = default_value
    return data


def generate_prompt(template, **kwargs):
    """í†µí•© í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜"""
    kwargs.update({
        'target_level': FEEDBACK_LEVEL.get("target_level", "TOPIK 2"),
        'allowed_styles': ", ".join(FEEDBACK_LEVEL.get("allowed_speech_styles", ["í•©ë‹ˆë‹¤ì²´", "í•´ìš”ì²´"])),
        'forbidden_styles': ", ".join(FEEDBACK_LEVEL.get("forbidden_speech_styles", ["ë°˜ë§"]))
    })
    return template.format(**kwargs)


# === ë©”ì¸ í”¼ë“œë°± í•¨ìˆ˜ë“¤ ===
def get_gpt_feedback(transcript, attempt_number=1, duration=0):
    """
    STT ê¸°ë°˜ ë£¨ë¸Œë¦­ì„ ì ìš©í•œ GPT í”¼ë“œë°± ìƒì„± (ë¬¸ì ìˆ˜ ê¸°ë°˜ í…ìŠ¤íŠ¸ ì²˜ë¦¬)
    
    Args:
        transcript: ì „ì‚¬ëœ í…ìŠ¤íŠ¸
        attempt_number: ì‹œë„ ë²ˆí˜¸
        duration: ìŒì„± ê¸¸ì´ (ì´ˆ)
    """
    if not OPENAI_API_KEY:
        st.error("Critical Error: OpenAI API key is required for feedback!")
        return {}
    
    # ê¸´ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ë¬¸ì ìˆ˜ ê¸°ë°˜)
    processed_transcript = preprocess_long_transcript(transcript)
    
    # ì „ì²˜ë¦¬ ê²°ê³¼ ë¡œê¹…
    if len(transcript) != len(processed_transcript):
        st.info(f"ğŸ“ Text processed: {len(transcript)} â†’ {len(processed_transcript)} characters for better AI analysis")
    
    # duration ì •ë³´ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
    enhanced_prompt_template = FEEDBACK_PROMPT_TEMPLATE + f"""

**STUDENT SPEAKING DURATION:** {duration:.1f} seconds

**DURATION-BASED SCORING:**
- If 60+ seconds: Excellent length (meets 1-minute goal!)
- If 45-60 seconds: Good length, encourage reaching 60+ seconds
- If 30-45 seconds: Fair length, needs to reach at least 60 seconds
- If under 30 seconds: Too short, must improve significantly

Use the actual duration ({duration:.1f}s) when generating your feedback and scoring."""

    prompt = generate_prompt(enhanced_prompt_template, question=EXPERIMENT_QUESTION, transcript=processed_transcript)
    debug_info = {
        'attempts': 0, 
        'model_used': None, 
        'errors': [], 
        'raw_response': None,
        'original_length': len(transcript),
        'processed_length': len(processed_transcript),
        'duration_provided': duration,
        'processing_method': 'character_based'  # tiktoken ì œê±° í‘œì‹œ
    }
    client = openai.OpenAI(api_key=OPENAI_API_KEY)
    
    # 2ë²ˆ ì‹œë„ (íƒ€ì„ì•„ì›ƒ 30ì´ˆë¡œ ì—°ì¥)
    for attempt in range(2):
        debug_info['attempts'] = attempt + 1
        
        try:
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": GPT_SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                timeout=30  # 20ì´ˆ â†’ 30ì´ˆë¡œ ì—°ì¥
            )
            
            raw_content = response.choices[0].message.content.strip()
            debug_info['raw_response'] = raw_content[:500] + "..." if len(raw_content) > 500 else raw_content
            debug_info['model_used'] = "gpt-4o"
            
            feedback_json = parse_gpt_response(raw_content)
            
            if feedback_json and feedback_json.get('suggested_model_sentence'):
                st.session_state.gpt_debug_info = debug_info
                st.success("âœ… AI feedback ready!")
                return feedback_json
            else:
                raise ValueError("Missing required fields")
                
        except Exception as e:
            error_msg = f"Attempt {attempt + 1} failed: {str(e)}"
            debug_info['errors'].append(error_msg)
            
            if attempt < 1:
                st.warning(f"âš ï¸ AI feedback error, retrying...")
                time.sleep(0.5)
    
    # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ - fallback í”¼ë“œë°± ì‚¬ìš©
    st.error("âŒ AI feedback failed after 2 attempts")
    st.info("Using basic feedback to continue experiment")
    
    debug_info['errors'].append("All attempts failed - using fallback")
    st.session_state.gpt_debug_info = debug_info
    
    return get_fallback_feedback()


def parse_gpt_response(raw_content):
    """GPT ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±"""
    try:
        result = json.loads(raw_content)
        return validate_and_fix_feedback(result)
    except json.JSONDecodeError:
        try:
            if "```json" in raw_content:
                start = raw_content.find("```json") + 7
                end = raw_content.find("```", start)
                clean_content = raw_content[start:end].strip()
                result = json.loads(clean_content)
                return validate_and_fix_feedback(result)
        except:
            pass
    
    return None


def validate_and_fix_feedback(feedback):
    """í”¼ë“œë°± êµ¬ì¡°ë¥¼ ê²€ì¦í•˜ê³  ëˆ„ë½ëœ í•„ìˆ˜ í•„ë“œë¥¼ ì¶”ê°€"""
    
    # í•„ìˆ˜ í•„ë“œ ê¸°ë³¸ê°’
    required_fields = {
        "suggested_model_sentence": "ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” [ì´ë¦„]ì´ì—ìš”. í•œêµ­í•™ì„ ì „ê³µí•´ìš”. ì·¨ë¯¸ëŠ” ìŒì•… ë“£ê¸°ì™€ ì˜í™” ë³´ê¸°ì˜ˆìš”.",
        "suggested_model_sentence_english": "Hello. I'm [name]. I major in Korean Studies. My hobbies are listening to music and watching movies.",
        "content_expansion_suggestions": [
            "ğŸ’¬ Topic: Favorite Korean food\\nğŸ“ Example: 'ì œê°€ ê°€ì¥ ì¢‹ì•„í•˜ëŠ” í•œêµ­ ìŒì‹ì€ ë¶ˆê³ ê¸°ì˜ˆìš”. ë¶ˆê³ ê¸°ëŠ” ë‹¬ì½¤í•˜ê³  ë§›ìˆì–´ìš”.'\\n   'My favorite Korean food is bulgogi. It is sweet and delicious.'",
            "ğŸ’¬ Topic: Why you study Korean\\nğŸ“ Example: 'í•œêµ­ ë¬¸í™”ê°€ ì¬ë¯¸ìˆì–´ì„œ í•œêµ­ì–´ë¥¼ ê³µë¶€í•´ìš”.'\\n   'I study Korean because Korean culture is interesting.'"
        ],
        "fluency_comment": "Keep practicing to speak more naturally!",
        "interview_readiness_score": 6,
        "interview_readiness_reason": "You're making good progress! Focus on speaking longer (60+ seconds) with more personal details.",
        "encouragement_message": "Every practice makes you better! You're doing great learning Korean!"
    }
    
    feedback = ensure_required_fields(feedback, required_fields)
    
    # Grammar issues ê²€ì¦ ë° ê°œì„  (ìµœëŒ€ 6ê°œ, 3ê°œ ìœ í˜•ë§Œ)
    if 'grammar_issues' in feedback and feedback['grammar_issues']:
        valid_issues = []
        for i, issue in enumerate(feedback['grammar_issues'][:6]):  # ìµœëŒ€ 6ê°œ
            if isinstance(issue, str) and len(issue) > 10:
                # ì˜¤ë¥˜ íƒ€ì… ë¶„ë¥˜ (3ê°œ ìœ í˜•ë§Œ)
                error_type = classify_error_type(issue)
                if error_type:  # 3ê°œ ìœ í˜• ì¤‘ í•˜ë‚˜ì¸ ê²½ìš°ë§Œ
                    standardized_issue = standardize_grammar_issue(issue, error_type)
                    valid_issues.append(standardized_issue)
        
        if valid_issues:
            feedback['grammar_issues'] = valid_issues
        else:
            feedback['grammar_issues'] = get_default_grammar_issues()
    else:
        feedback['grammar_issues'] = get_default_grammar_issues()
    
    # â”€â”€â”€ Vocabulary suggestions ì¬êµ¬ì„± (ìµœëŒ€ 2ê°œ) + ë¬¸ë²• ê²¹ì¹¨ í•„í„°ë§ â”€â”€â”€
    if 'vocabulary_suggestions' in feedback and feedback['vocabulary_suggestions']:
        # ë¨¼ì € ë¬¸ë²• ê´€ë ¨ í•­ëª© í•„í„°ë§
        filtered_vocab = filter_grammar_from_vocabulary(feedback['vocabulary_suggestions'])
        
        if len(filtered_vocab) >= 2:
            # ì¶©ë¶„í•œ ìˆœìˆ˜ ì–´íœ˜ ì œì•ˆì´ ìˆìœ¼ë©´ ì‚¬ìš©
            vocab_to_process = filtered_vocab[:2]
        else:
            # í•„í„°ë§ í›„ ë¶€ì¡±í•˜ë©´ ê¸°ë³¸ ì–´íœ˜ ì œì•ˆìœ¼ë¡œ ë³´ì™„
            pure_suggestions = get_pure_vocabulary_suggestions()
            vocab_to_process = (filtered_vocab + pure_suggestions)[:2]
    else:
        # ì–´íœ˜ ì œì•ˆì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        vocab_to_process = get_pure_vocabulary_suggestions()[:2]

    # â†’ vs ë°©ì‹ í¬ë§·ìœ¼ë¡œ ì¬êµ¬ì„±
    formatted_vocab = []
    for tip in vocab_to_process:
        # ì´ë¯¸ vs í¬ë§·ì¸ì§€ í™•ì¸
        if "â“ **" in tip and " vs " in tip:
            formatted_vocab.append(tip)
            continue
        
        # ê¸°ì¡´ âŒâœ… í¬ë§·ì¸ ê²½ìš° vs í¬ë§·ìœ¼ë¡œ ë³€í™˜ (ê¸°ë³¸ê°’ ì‚¬ìš©)
        # GPTê°€ ìƒˆë¡œìš´ í˜•ì‹ì„ í•™ìŠµí•  ë•Œê¹Œì§€ëŠ” ê¸°ë³¸ vs ì˜ˆì‹œ ì‚¬ìš©
        if len(formatted_vocab) < 2:
            pure_suggestions = get_pure_vocabulary_suggestions()
            formatted_vocab.extend(pure_suggestions[:2-len(formatted_vocab)])
            break

    feedback['vocabulary_suggestions'] = formatted_vocab[:2]
    
    # ì ìˆ˜ ê²€ì¦
    score = feedback.get("interview_readiness_score", 6)
    if not isinstance(score, (int, float)) or score < 1 or score > 10:
        feedback["interview_readiness_score"] = 6
    
    return feedback


def standardize_grammar_issue(issue_text, error_type):
    """ë¬¸ë²• ì´ìŠˆë¥¼ ê°„ë‹¨í•œ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    
    # Originalê³¼ Fix ì¶”ì¶œ
    original_text = ""
    fix_text = ""
    explanation = ""
    
    if "Original:" in issue_text and "â†’" in issue_text:
        try:
            original_text = issue_text.split("Original:")[1].split("â†’")[0].strip().strip("'\"")
            if "Fix:" in issue_text:
                fix_text = issue_text.split("Fix:")[1].split("ğŸ§ ")[0].strip().strip("'\"")
            else:
                fix_text = issue_text.split("â†’")[1].split("ğŸ§ ")[0].strip().strip("'\"")
            
            if "ğŸ§ " in issue_text:
                explanation = issue_text.split("ğŸ§ ")[1].strip()
                # "Simple explanation:" ì œê±°
                explanation = re.sub(r'^(?:ğŸ’¡\s*)?Simple explanation:\s*', '', explanation)
        except:
            pass
    
    # ê°„ë‹¨í•œ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±
    if original_text and fix_text:
        if not explanation:
            explanation = get_default_explanation(error_type)
        
        return f"{error_type}|{original_text}|{fix_text}|{explanation}"
    else:
        # í˜•ì‹ì´ ëª…í™•í•˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ ì²˜ë¦¬
        return f"{error_type}||Basic grammar point|Review this grammar carefully"


def get_default_explanation(error_type):
    """ì˜¤ë¥˜ íƒ€ì…ë³„ ê¸°ë³¸ ì„¤ëª…"""
    explanations = {
        "Particle": "Use the appropriate particle to mark the grammatical role",
        "Verb Ending": "Use the correct verb ending form",
        "Verb Tense": "Use the appropriate tense marker"
    }
    return explanations.get(error_type, "Review this grammar point")


def get_default_grammar_issues():
    """ê¸°ë³¸ ë¬¸ë²• ì´ìŠˆë“¤ (3ê°œ ìœ í˜•ë§Œ)"""
    return [
        "Particle|ì €ëŠ” ê²½ì œ ì „ê³µì´ì—ìš”|ì €ëŠ” ê²½ì œë¥¼ ì „ê³µí•´ìš”|Use 'ë¥¼' to indicate the object and change 'ì „ê³µì´ì—ìš”' to 'ì „ê³µí•´ìš”'",
        "Verb Ending|ì¢‹ì•„ìš”|ì¢‹ì•„í•´ìš”|Use 'ì¢‹ì•„í•´ìš”' when expressing that you like doing activities",
        "Verb Tense|ì–´ì œ ê°€ìš”|ì–´ì œ ê°”ì–´ìš”|Use past tense with time indicators like 'ì–´ì œ'"
    ]


def get_fallback_feedback():
    """API ì‹¤íŒ¨ì‹œ ì‚¬ìš©í•  ê¸°ë³¸ í”¼ë“œë°± (1ë¶„ ê¸°ì¤€, vs ë°©ì‹)"""
    return {
        "suggested_model_sentence": "ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” [ì´ë¦„]ì´ì—ìš”. [ì „ê³µ]ì„ ê³µë¶€í•´ìš”. ì·¨ë¯¸ëŠ” [ì·¨ë¯¸]ì˜ˆìš”. í•œêµ­ì–´ë¥¼ ê³µë¶€í•˜ëŠ” ê²ƒì´ ì¬ë¯¸ìˆì–´ìš”.",
        "suggested_model_sentence_english": "Hello. I'm [name]. I study [major]. My hobby is [hobby]. Studying Korean is interesting.",
        "grammar_issues": get_default_grammar_issues(),
        "vocabulary_suggestions": [
            "â“ **ê³µë¶€í•˜ë‹¤ vs ë°°ìš°ë‹¤**\\nğŸ’¡ ê³µë¶€í•˜ë‹¤: Academic studying or reviewing material at a desk\\nğŸ’¡ ë°°ìš°ë‹¤: Learning new skills or acquiring new knowledge\\nğŸŸ¢ ì‹œí—˜ì„ ìœ„í•´ ê³µë¶€í•´ìš” (I study for exams) / í•œêµ­ì–´ë¥¼ ë°°ìš°ê³  ìˆì–´ìš” (I'm learning Korean)\\nğŸ“ Use 'ë°°ìš°ë‹¤' for new skills, 'ê³µë¶€í•˜ë‹¤' for reviewing",
            "â“ **ì¢‹ë‹¤ vs ì¢‹ì•„í•˜ë‹¤**\\nğŸ’¡ ì¢‹ë‹¤: Adjective - something is good (state/quality)\\nğŸ’¡ ì¢‹ì•„í•˜ë‹¤: Verb - to like something (preference)\\nğŸŸ¢ ë‚ ì”¨ê°€ ì¢‹ì•„ìš” (The weather is nice) / ìŒì•…ì„ ì¢‹ì•„í•´ìš” (I like music)\\nğŸ“ Use 'ì´/ê°€ ì¢‹ë‹¤' vs 'ì„/ë¥¼ ì¢‹ì•„í•˜ë‹¤'"
        ],
        "content_expansion_suggestions": [
            "ğŸ’¬ Topic: Favorite Korean food\\nğŸ“ Example: 'ì œê°€ ê°€ì¥ ì¢‹ì•„í•˜ëŠ” í•œêµ­ ìŒì‹ì€ ë¶ˆê³ ê¸°ì˜ˆìš”. ë¶ˆê³ ê¸°ëŠ” ë‹¬ì½¤í•˜ê³  ë§›ìˆì–´ìš”.'\\n   'My favorite Korean food is bulgogi. It is sweet and delicious.'",
            "ğŸ’¬ Topic: Why you study Korean\\nğŸ“ Example: 'í•œêµ­ ë¬¸í™”ê°€ ì¬ë¯¸ìˆì–´ì„œ í•œêµ­ì–´ë¥¼ ê³µë¶€í•´ìš”.'\\n   'I study Korean because Korean culture is interesting.'"
        ],
        "grammar_expression_tip": "ğŸš€ Try: 'ì €ëŠ” Xë¥¼ ì¢‹ì•„í•´ìš”' = 'I like X'\\nğŸ“ Example: 'ì €ëŠ” í•œêµ­ ìŒì‹ì„ ì¢‹ì•„í•´ìš”'\\nğŸ’¡ Use to express preferences",
        "fluency_comment": "Keep practicing! Try to speak for at least 1 minute (60+ seconds) to build fluency.",
        "interview_readiness_score": 5,
        "interview_readiness_reason": "You're making progress! Focus on speaking for at least 1 minute (60+ seconds) with more personal details.",
        "encouragement_message": "Every practice session helps! Keep going! í™”ì´íŒ…!"
    }


def get_improvement_assessment(first_transcript, second_transcript, original_feedback):
    """STT ê¸°ë°˜ ë£¨ë¸Œë¦­ì„ ì‚¬ìš©í•œ ê°œì„ ë„ í‰ê°€"""
    if not OPENAI_API_KEY:
        return get_fallback_improvement_assessment()
    
    prompt = generate_prompt(
        IMPROVEMENT_PROMPT_TEMPLATE,
        question=EXPERIMENT_QUESTION,
        first_transcript=first_transcript,
        second_transcript=second_transcript,
        original_feedback=json.dumps(original_feedback, ensure_ascii=False)
    )
    
    try:
        client = openai.OpenAI(api_key=OPENAI_API_KEY)
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are a Korean teacher evaluating progress. Respond only with valid JSON."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            timeout=15
        )
        
        raw_content = response.choices[0].message.content.strip()
        result = parse_gpt_response(raw_content)
        
        if result:
            return validate_and_fix_improvement(result)
        else:
            raise ValueError("Failed to parse response")
            
    except Exception as e:
        print(f"Improvement assessment failed: {e}")
        return get_fallback_improvement_assessment()


def validate_and_fix_improvement(improvement):
    """ê°œì„ ë„ í‰ê°€ë¥¼ ê²€ì¦í•˜ê³  ëˆ„ë½ëœ í•„ìˆ˜ í•„ë“œë¥¼ ì¶”ê°€"""
    required_fields = {
        "first_attempt_score": 5,
        "second_attempt_score": 5,
        "score_difference": 0,
        "improvement_score": 5,
        "improvement_reason": "Continue practicing for better fluency and accuracy",
        "specific_improvements": ["Attempted Korean speaking practice"],
        "remaining_issues": ["Focus on speaking longer (60+ seconds) with more details"],
        "feedback_application": "unclear",
        "overall_assessment": "Keep practicing! Focus on speaking for 60+ seconds with personal details.",
        "encouragement_message": "Every practice session makes you better! Keep going!"
    }
    
    improvement = ensure_required_fields(improvement, required_fields)
    
    # ì ìˆ˜ë“¤ ê²€ì¦ (1-10 ë²”ìœ„)
    score_fields = ["first_attempt_score", "second_attempt_score", "improvement_score"]
    for field in score_fields:
        score = improvement.get(field, 5)
        if not isinstance(score, (int, float)) or score < 1 or score > 10:
            improvement[field] = 5
    
    # score_difference ê³„ì‚°
    try:
        improvement["score_difference"] = improvement["second_attempt_score"] - improvement["first_attempt_score"]
    except:
        improvement["score_difference"] = 0
    
    # ë¦¬ìŠ¤íŠ¸ í•„ë“œë“¤ ê²€ì¦
    list_fields = ["specific_improvements", "remaining_issues"]
    for field in list_fields:
        if not isinstance(improvement.get(field), list) or not improvement[field]:
            improvement[field] = ["Attempted Korean speaking practice"] if field == "specific_improvements" else ["Continue practicing for better fluency"]
    
    # feedback_application ê²€ì¦
    valid_applications = ["excellent", "good", "partial", "poor", "unclear"]
    if improvement.get("feedback_application") not in valid_applications:
        improvement["feedback_application"] = "unclear"
    
    return improvement


def get_fallback_improvement_assessment():
    """ê°œì„ ë„ í‰ê°€ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’"""
    return FALLBACK_IMPROVEMENT_DATA.copy()


def get_score_category_info(score):
    """ì ìˆ˜ì— ë”°ë¥¸ ì¹´í…Œê³ ë¦¬ ì •ë³´ ë°˜í™˜"""
    for category, info in STT_RUBRIC.items():
        if info["min_score"] <= score <= info["max_score"]:
            return info
    return STT_RUBRIC["fair"]


def display_score_with_category(score, label="Score"):
    """ì ìˆ˜ë¥¼ ì¹´í…Œê³ ë¦¬ì™€ í•¨ê»˜ í‘œì‹œ"""
    if isinstance(score, (int, float)):
        category_info = get_score_category_info(score)
        st.markdown(
            f"<h2 style='color: {category_info['color']}; text-align: center;'>{score}/10</h2>", 
            unsafe_allow_html=True
        )
        st.markdown(
            f"<p style='color: {category_info['color']}; text-align: center; font-weight: bold;'>{category_info['label']}</p>", 
            unsafe_allow_html=True
        )
    else:
        st.write(f"**{label}:** {score}")


def display_score_with_encouragement(score, duration=0):
    """ì ìˆ˜ë¥¼ ê²©ë ¤ ë©”ì‹œì§€ì™€ í•¨ê»˜ í‘œì‹œ"""
    category_info = get_score_category_info(score)
    
    # ì ìˆ˜ í‘œì‹œ
    st.markdown(
        f"<h2 style='color: {category_info['color']}; text-align: center; margin: 20px 0;'>{score}/10</h2>", 
        unsafe_allow_html=True
    )
    
    # ê²©ë ¤ ë©”ì‹œì§€
    if score >= 8:
        st.balloons()
        message = "ğŸŒŸ Outstanding! You're interview-ready!"
        if duration >= 60:
            message += " Perfect length too!"
    elif score >= 7:
        message = "ğŸ¯ Great job! Almost perfect!"
        if duration < 60:
            message += " Try to speak a bit longer (60+ seconds)."
    elif score >= 6:
        message = "ğŸ’ª Good work! You're improving!"
        if duration < 60:
            message += " Aim for 60+ seconds."
    elif score >= 5:
        message = "ğŸš€ Keep going! You're learning!"
        message += " Focus on reaching 60 seconds."
    else:
        message = "ğŸŒ± Everyone starts somewhere! Keep practicing!"
        message += " Work towards speaking for 60 seconds."
    
    # ë©”ì‹œì§€ í‘œì‹œ
    st.markdown(
        f"""
        <div style='
            background-color: {category_info['color']}20;
            border: 2px solid {category_info['color']};
            border-radius: 10px;
            padding: 15px;
            text-align: center;
            margin: 10px 0;
        '>
            <p style='
                color: {category_info['color']};
                font-weight: bold;
                font-size: 16px;
                margin: 0;
            '>
                {message}
            </p>
        </div>
        """,
        unsafe_allow_html=True
    )