"""
data_io.py
ì‹¤í—˜ ë°ì´í„° ì €ì¥, ë°±ì—…, ì—…ë¡œë“œ ë° ë¡œê·¸ ê´€ë¦¬ ëª¨ë“ˆ (ì—°êµ¬ìš© TOPIK ë¶„ì„ ì‹œíŠ¸ ì¶”ê°€)
"""

import os
import csv
import json
import zipfile
import pandas as pd
from datetime import datetime, timedelta
import streamlit as st
from config import (
    FOLDERS, 
    DATA_RETENTION_DAYS, 
    EXPERIMENT_QUESTION,
    GCS_ENABLED,
    GCS_BUCKET_NAME,
    GCS_SERVICE_ACCOUNT,
    GCS_SIMPLE_STRUCTURE,
    LOG_FORMAT,
    CURRENT_SESSION,
    SESSION_LABELS
)
from research_scoring import (
    get_research_analysis_data,
    generate_grading_summary_row
)


def save_session_data():
    """
    ì„¸ì…˜ ë°ì´í„°ë¥¼ CSV + ì—°êµ¬ìš© Excelë¡œ ì €ì¥ (ìê¸°íš¨ëŠ¥ê° + TOPIK ë¶„ì„ í¬í•¨)
    
    Returns:
        tuple: (csv_filename, excel_filename, audio_folder, saved_files, zip_filename, timestamp)
    """
    try:
        # ì¤‘ë³µ ì €ì¥ ë°©ì§€
        if hasattr(st.session_state, 'data_saved') and st.session_state.data_saved:
            if hasattr(st.session_state, 'saved_files'):
                st.info("â„¹ï¸ Data already saved, using existing files.")
                existing_timestamp = getattr(st.session_state, 'saved_timestamp', datetime.now().strftime("%Y%m%d_%H%M%S"))
                return st.session_state.saved_files + (existing_timestamp,)
        
        # í•„ìš”í•œ í´ë” ìƒì„±
        for folder in FOLDERS.values():
            os.makedirs(folder, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        session_data = build_session_data(timestamp)
        csv_filename = save_to_csv(session_data, timestamp)
        
        # ğŸ†• ì—°êµ¬ìš© Excel íŒŒì¼ ìƒì„±
        excel_filename = save_research_excel(timestamp)
        
        audio_folder, saved_files = save_audio_files(timestamp)
        zip_filename = create_comprehensive_backup_zip(st.session_state.session_id, timestamp)
        
        return csv_filename, excel_filename, audio_folder, saved_files, zip_filename, timestamp
    
    except Exception as e:
        st.error(f"âŒ Error saving session data: {str(e)}")
        return None, None, None, [], None, None


def save_research_excel(timestamp):
    """
    ì—°êµ¬ìš© TOPIK ë¶„ì„ Excel íŒŒì¼ ìƒì„±
    
    Args:
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        
    Returns:
        str: Excel íŒŒì¼ ê²½ë¡œ
    """
    try:
        session_num = getattr(st.session_state, 'session_number', CURRENT_SESSION)
        excel_filename = os.path.join(
            FOLDERS["data"], 
            f"research_analysis_session{session_num}_{st.session_state.session_id}_{timestamp}.xlsx"
        )
        
        # Excel ì‘ì„±ê¸° ìƒì„±
        with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:
            
            # === ì‹œíŠ¸ 1: ì±„ì ììš© ìš”ì•½ í…Œì´ë¸” ===
            grading_summary = create_grading_summary_sheet()
            if grading_summary:
                grading_df = pd.DataFrame([grading_summary])
                grading_df.to_excel(writer, sheet_name='ì±„ì ììš©_ìš”ì•½', index=False)
            
            # === ì‹œíŠ¸ 2: 1ì°¨ ì‹œë„ ìƒì„¸ ë¶„ì„ ===
            if st.session_state.transcription_1:
                research_data_1 = generate_research_data_for_attempt(1)
                if research_data_1:
                    analysis_df_1 = create_detailed_analysis_sheet(research_data_1, 1)
                    analysis_df_1.to_excel(writer, sheet_name='1ì°¨_ìƒì„¸ë¶„ì„', index=False)
            
            # === ì‹œíŠ¸ 3: 2ì°¨ ì‹œë„ ìƒì„¸ ë¶„ì„ ===
            if st.session_state.transcription_2:
                research_data_2 = generate_research_data_for_attempt(2)
                if research_data_2:
                    analysis_df_2 = create_detailed_analysis_sheet(research_data_2, 2)
                    analysis_df_2.to_excel(writer, sheet_name='2ì°¨_ìƒì„¸ë¶„ì„', index=False)
            
            # === ì‹œíŠ¸ 4: TOPIK ì ìˆ˜ ë¹„êµ ===
            if st.session_state.transcription_1 and st.session_state.transcription_2:
                comparison_df = create_score_comparison_sheet()
                comparison_df.to_excel(writer, sheet_name='ì ìˆ˜_ë¹„êµ', index=False)
            
            # === ì‹œíŠ¸ 5: ì›ë³¸ ë°ì´í„° ===
            original_session_data = build_session_data(timestamp)
            original_df = pd.DataFrame([original_session_data])
            original_df.to_excel(writer, sheet_name='ì›ë³¸_ì„¸ì…˜ë°ì´í„°', index=False)
        
        print(f"âœ… Research Excel created: {excel_filename}")
        return excel_filename
        
    except Exception as e:
        st.error(f"âŒ Error creating research Excel: {str(e)}")
        return None


def create_grading_summary_sheet():
    """
    ì±„ì ììš© ìš”ì•½ ì‹œíŠ¸ ë°ì´í„° ìƒì„±
    
    Returns:
        dict: ì±„ì ììš© ìš”ì•½ ë°ì´í„°
    """
    try:
        # 1ì°¨, 2ì°¨ ì—°êµ¬ ë°ì´í„° ìƒì„±
        research_data_1 = generate_research_data_for_attempt(1) if st.session_state.transcription_1 else None
        research_data_2 = generate_research_data_for_attempt(2) if st.session_state.transcription_2 else None
        
        if research_data_1:
            # ì±„ì ììš© ìš”ì•½ í–‰ ìƒì„±
            summary_row = generate_grading_summary_row(research_data_1, research_data_2)
            
            # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
            summary_row.update({
                "experiment_question": EXPERIMENT_QUESTION,
                "learning_duration": getattr(st.session_state, 'learning_duration', ''),
                "speaking_confidence": getattr(st.session_state, 'speaking_confidence', ''),
                "self_efficacy_average": calculate_self_efficacy_average(),
                "consent_given": getattr(st.session_state, 'consent_given', False),
                "data_quality_notes": generate_data_quality_notes()
            })
            
            return summary_row
        
        return None
        
    except Exception as e:
        print(f"Error creating grading summary: {e}")
        return None


def create_detailed_analysis_sheet(research_data, attempt_number):
    """
    ìƒì„¸ ë¶„ì„ ì‹œíŠ¸ ë°ì´í„° ìƒì„±
    
    Args:
        research_data: ì—°êµ¬ ë¶„ì„ ë°ì´í„°
        attempt_number: ì‹œë„ ë²ˆí˜¸
        
    Returns:
        DataFrame: ìƒì„¸ ë¶„ì„ ë°ì´í„°í”„ë ˆì„
    """
    try:
        # ë¶„ì„ ë°ì´í„°ë¥¼ í”Œë«í•˜ê²Œ ë³€í™˜
        flattened_data = flatten_research_data(research_data, attempt_number)
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„± (ì„¸ë¡œ í˜•íƒœë¡œ í‚¤-ê°’ ìŒ)
        analysis_rows = []
        for category, data in flattened_data.items():
            if isinstance(data, dict):
                for key, value in data.items():
                    analysis_rows.append({
                        "ì¹´í…Œê³ ë¦¬": category,
                        "í•­ëª©": key,
                        "ê°’": str(value),
                        "ì„¤ëª…": get_item_description(category, key)
                    })
            else:
                analysis_rows.append({
                    "ì¹´í…Œê³ ë¦¬": category,
                    "í•­ëª©": category,
                    "ê°’": str(data),
                    "ì„¤ëª…": get_item_description(category, category)
                })
        
        return pd.DataFrame(analysis_rows)
        
    except Exception as e:
        print(f"Error creating detailed analysis sheet: {e}")
        return pd.DataFrame()


def create_score_comparison_sheet():
    """
    ì ìˆ˜ ë¹„êµ ì‹œíŠ¸ ìƒì„±
    
    Returns:
        DataFrame: ì ìˆ˜ ë¹„êµ ë°ì´í„°í”„ë ˆì„
    """
    try:
        research_data_1 = generate_research_data_for_attempt(1)
        research_data_2 = generate_research_data_for_attempt(2)
        
        if not research_data_1 or not research_data_2:
            return pd.DataFrame()
        
        # ì ìˆ˜ ë¹„êµ ë°ì´í„°
        comparison_data = []
        
        # TOPIK 3ì˜ì—­ ì ìˆ˜ ë¹„êµ
        scores_1 = research_data_1['summary_indicators']
        scores_2 = research_data_2['summary_indicators']
        
        topik_areas = [
            ("ë‚´ìš© ë° ê³¼ì œ ìˆ˜í–‰", "content_task_performance_score"),
            ("ì–¸ì–´ ì‚¬ìš©", "language_use_score"),
            ("ë°œí™” ì „ë‹¬ë ¥", "speech_delivery_score"),
            ("ì „ì²´ í‰ê· ", "overall_auto_score")
        ]
        
        for area_name, score_key in topik_areas:
            score_1 = scores_1.get(score_key, 0)
            score_2 = scores_2.get(score_key, 0)
            improvement = score_2 - score_1
            
            comparison_data.append({
                "TOPIK_ì˜ì—­": area_name,
                "1ì°¨_ìë™ì ìˆ˜": score_1,
                "2ì°¨_ìë™ì ìˆ˜": score_2,
                "ê°œì„ ë„": improvement,
                "ê°œì„ ìœ¨": f"{(improvement/score_1*100):.1f}%" if score_1 > 0 else "N/A",
                "1ì°¨_ìˆ˜ë™ì ìˆ˜_ì±„ì ì1": "",
                "1ì°¨_ìˆ˜ë™ì ìˆ˜_ì±„ì ì2": "",
                "2ì°¨_ìˆ˜ë™ì ìˆ˜_ì±„ì ì1": "",
                "2ì°¨_ìˆ˜ë™ì ìˆ˜_ì±„ì ì2": "",
                "ìˆ˜ë™ì ìˆ˜_ê°œì„ ë„": ""
            })
        
        # ì„¸ë¶€ ì§€í‘œ ë¹„êµ
        detailed_comparison = []
        
        # ê¸°ë³¸ ì§€í‘œë“¤
        basic_metrics = [
            ("ë…¹ìŒ ê¸¸ì´", "duration_seconds", "ì´ˆ"),
            ("ë‹¨ì–´ ìˆ˜", lambda d: d['task_performance']['content_richness']['total_words'], "ê°œ"),
            ("ë¬¸ì¥ ìˆ˜", lambda d: d['task_performance']['content_richness']['sentences_count'], "ê°œ"),
            ("ë¬¸ë²• ì˜¤ë¥˜", lambda d: d['language_use']['grammar_accuracy']['total_grammar_errors'], "ê°œ"),
            ("ì˜¤ë¥˜ìœ¨", lambda d: d['language_use']['grammar_accuracy']['error_rate'], "%"),
            ("ì–´íœ˜ ë‹¤ì–‘ì„±", lambda d: d['language_use']['vocabulary_usage']['vocabulary_diversity'], "ë¹„ìœ¨"),
            ("ë¶„ë‹¹ ë‹¨ì–´ìˆ˜", lambda d: d['speech_delivery_indicators']['fluency_indicators']['words_per_minute'], "wpm")
        ]
        
        for metric_name, metric_key, unit in basic_metrics:
            if callable(metric_key):
                value_1 = metric_key(research_data_1)
                value_2 = metric_key(research_data_2)
            else:
                value_1 = research_data_1.get(metric_key, 0)
                value_2 = research_data_2.get(metric_key, 0)
            
            change = value_2 - value_1
            
            detailed_comparison.append({
                "ì„¸ë¶€_ì§€í‘œ": metric_name,
                "1ì°¨_ê°’": value_1,
                "2ì°¨_ê°’": value_2,
                "ë³€í™”ëŸ‰": change,
                "ë‹¨ìœ„": unit,
                "í‰ê°€": evaluate_change(metric_name, change)
            })
        
        # ë‘ ë°ì´í„°í”„ë ˆì„ í•©ì¹˜ê¸°
        comparison_df = pd.DataFrame(comparison_data)
        detailed_df = pd.DataFrame(detailed_comparison)
        
        # ë¹ˆ í–‰ìœ¼ë¡œ êµ¬ë¶„
        separator = pd.DataFrame([{"TOPIK_ì˜ì—­": "=== ì„¸ë¶€ ì§€í‘œ ë¹„êµ ==="}])
        
        # ì»¬ëŸ¼ ë§ì¶”ê¸°
        max_cols = max(len(comparison_df.columns), len(detailed_df.columns))
        for df in [comparison_df, separator, detailed_df]:
            while len(df.columns) < max_cols:
                df[f"ë¹ˆì»¬ëŸ¼_{len(df.columns)}"] = ""
        
        return pd.concat([comparison_df, separator, detailed_df], ignore_index=True)
        
    except Exception as e:
        print(f"Error creating score comparison sheet: {e}")
        return pd.DataFrame()


def generate_research_data_for_attempt(attempt_number):
    """
    íŠ¹ì • ì‹œë„ì— ëŒ€í•œ ì—°êµ¬ ë°ì´í„° ìƒì„±
    
    Args:
        attempt_number: ì‹œë„ ë²ˆí˜¸ (1 or 2)
        
    Returns:
        dict: ì—°êµ¬ ë¶„ì„ ë°ì´í„°
    """
    try:
        if attempt_number == 1:
            transcript = st.session_state.transcription_1
            duration = getattr(st.session_state, 'audio_duration_1', 0)
        elif attempt_number == 2:
            transcript = st.session_state.transcription_2
            duration = getattr(st.session_state, 'audio_duration_2', 0)
        else:
            return None
        
        if not transcript:
            return None
        
        # GPT í”¼ë“œë°± ë°ì´í„°
        feedback_data = st.session_state.feedback if attempt_number == 1 else {}
        grammar_issues = feedback_data.get('grammar_issues', [])
        
        # ì—°êµ¬ ë¶„ì„ ë°ì´í„° ìƒì„±
        research_data = get_research_analysis_data(
            transcript=transcript,
            grammar_issues=grammar_issues,
            duration_s=duration,
            feedback_data=feedback_data,
            attempt_number=attempt_number
        )
        
        return research_data
        
    except Exception as e:
        print(f"Error generating research data for attempt {attempt_number}: {e}")
        return None


def flatten_research_data(research_data, attempt_number):
    """
    ì—°êµ¬ ë°ì´í„°ë¥¼ í”Œë«í•œ êµ¬ì¡°ë¡œ ë³€í™˜
    
    Args:
        research_data: ì—°êµ¬ ë¶„ì„ ë°ì´í„°
        attempt_number: ì‹œë„ ë²ˆí˜¸
        
    Returns:
        dict: í”Œë«í•œ êµ¬ì¡°ì˜ ë°ì´í„°
    """
    flattened = {
        f"ê¸°ë³¸ì •ë³´_ì‹œë„{attempt_number}": {
            "ì„¸ì…˜ID": research_data.get("session_id", ""),
            "ì‹œë„ë²ˆí˜¸": research_data.get("attempt", ""),
            "ë¶„ì„ì‹œê°„": research_data.get("timestamp", ""),
            "ë…¹ìŒê¸¸ì´": f"{research_data.get('duration_seconds', 0)}ì´ˆ"
        },
        
        "ê³¼ì œìˆ˜í–‰_ë¶„ì„": {
            "ì—¬ë¦„ë°©í•™_ì–¸ê¸‰": research_data["task_performance"]["topics_mentioned"]["summer_vacation"],
            "í•œêµ­ê³„íš_ì–¸ê¸‰": research_data["task_performance"]["topics_mentioned"]["korea_plans"],
            "ì–‘ì£¼ì œ_ì™„ë£Œ": research_data["task_performance"]["topics_mentioned"]["both_topics_covered"],
            "ì´ìœ ì œì‹œ_ì™„ì„±ë„": research_data["task_performance"]["reasoning_provided"]["reasoning_completeness"],
            "ì´ë‹¨ì–´ìˆ˜": research_data["task_performance"]["content_richness"]["total_words"],
            "ê³ ìœ ë‹¨ì–´ìˆ˜": research_data["task_performance"]["content_richness"]["unique_words"],
            "ë¬¸ì¥ìˆ˜": research_data["task_performance"]["content_richness"]["sentences_count"],
            "ì„¸ë¶€ì‚¬í•­_ê°œìˆ˜": research_data["task_performance"]["content_richness"]["detail_count"],
            "ë‹´í™”êµ¬ì„±_ì ìˆ˜": research_data["task_performance"]["discourse_organization"]["organization_score"]
        },
        
        "ì–¸ì–´ì‚¬ìš©_ë¶„ì„": {
            "ë¬¸ë²•ì˜¤ë¥˜_ì´ê°œìˆ˜": research_data["language_use"]["grammar_accuracy"]["total_grammar_errors"],
            "ì˜¤ë¥˜ìœ¨": f"{research_data['language_use']['grammar_accuracy']['error_rate']}%",
            "ì •í™•ì„±_ì ìˆ˜": research_data["language_use"]["grammar_accuracy"]["accuracy_score"],
            "ì–´íœ˜ë‹¤ì–‘ì„±": research_data["language_use"]["vocabulary_usage"]["vocabulary_diversity"],
            "ì¡´ëŒ“ë§_ìˆ˜ì¤€": research_data["language_use"]["language_appropriateness"]["speech_level"],
            "ì¡´ëŒ“ë§_ì¼ê´€ì„±": research_data["language_use"]["language_appropriateness"]["consistency"]
        },
        
        "ë°œí™”ì „ë‹¬ë ¥_ë¶„ì„": {
            "ë¶„ë‹¹ë‹¨ì–´ìˆ˜": research_data["speech_delivery_indicators"]["fluency_indicators"]["words_per_minute"],
            "ë§ì„¤ì„í‘œì§€": ", ".join(research_data["speech_delivery_indicators"]["fluency_indicators"]["hesitation_markers"]),
            "ë°˜ë³µíšŸìˆ˜": research_data["speech_delivery_indicators"]["fluency_indicators"]["repetition_count"],
            "í‰ê· ë¬¸ì¥ê¸¸ì´": research_data["speech_delivery_indicators"]["speech_patterns"]["average_sentence_length"],
            "ë¯¸ì™„ì„±ë¬¸ì¥ìˆ˜": research_data["speech_delivery_indicators"]["speech_patterns"]["incomplete_sentences"]
        },
        
        "TOPIK_ìë™ì ìˆ˜": {
            "ë‚´ìš©ë°ê³¼ì œìˆ˜í–‰": research_data["summary_indicators"]["content_task_performance_score"],
            "ì–¸ì–´ì‚¬ìš©": research_data["summary_indicators"]["language_use_score"],
            "ë°œí™”ì „ë‹¬ë ¥": research_data["summary_indicators"]["speech_delivery_score"],
            "ì „ì²´í‰ê· ": research_data["summary_indicators"]["overall_auto_score"]
        },
        
        "ì„¸ë¶€ì ìˆ˜": research_data["summary_indicators"]["detailed_scores"],
        
        "ì±„ì ì°¸ê³ ì‚¬í•­": {
            "ì£¼ìš”íŠ¹ì§•": "; ".join(research_data["summary_indicators"]["grading_notes"]),
            "ì£¼ì˜ì‚¬í•­": "; ".join(research_data["summary_indicators"]["attention_points"]),
            "ë°œí™”ë¶„ì„": research_data["summary_indicators"]["speech_delivery_breakdown"]["delivery_explanation"]
        }
    }
    
    return flattened


def get_item_description(category, key):
    """
    í•­ëª©ë³„ ì„¤ëª… ë°˜í™˜
    
    Args:
        category: ì¹´í…Œê³ ë¦¬
        key: í‚¤
        
    Returns:
        str: ì„¤ëª…
    """
    descriptions = {
        "ê³¼ì œìˆ˜í–‰_ë¶„ì„": {
            "ì—¬ë¦„ë°©í•™_ì–¸ê¸‰": "ì—¬ë¦„ë°©í•™ ê´€ë ¨ ë‚´ìš© ì–¸ê¸‰ ì—¬ë¶€",
            "í•œêµ­ê³„íš_ì–¸ê¸‰": "í•œêµ­ì—ì„œì˜ ê³„íš ê´€ë ¨ ë‚´ìš© ì–¸ê¸‰ ì—¬ë¶€",
            "ì–‘ì£¼ì œ_ì™„ë£Œ": "ë‘ ì£¼ì œ ëª¨ë‘ ë‹¤ë£¸ ì—¬ë¶€",
            "ì´ìœ ì œì‹œ_ì™„ì„±ë„": "ê° ì£¼ì œì— ëŒ€í•œ ì´ìœ  ì„¤ëª… ì™„ì„±ë„ (both/partial/none)",
            "ì„¸ë¶€ì‚¬í•­_ê°œìˆ˜": "êµ¬ì²´ì ì¸ ì„¸ë¶€ì‚¬í•­ì˜ ê°œìˆ˜",
            "ë‹´í™”êµ¬ì„±_ì ìˆ˜": "ë‹´í™” ì¡°ì§ì„± ì ìˆ˜ (1-5ì )"
        },
        "ì–¸ì–´ì‚¬ìš©_ë¶„ì„": {
            "ì˜¤ë¥˜ìœ¨": "ì´ ë‹¨ì–´ ìˆ˜ ëŒ€ë¹„ ë¬¸ë²• ì˜¤ë¥˜ ë¹„ìœ¨",
            "ì–´íœ˜ë‹¤ì–‘ì„±": "ê³ ìœ  ë‹¨ì–´ ìˆ˜ / ì´ ë‹¨ì–´ ìˆ˜",
            "ì¡´ëŒ“ë§_ìˆ˜ì¤€": "ì£¼ë¡œ ì‚¬ìš©í•œ ì¡´ëŒ“ë§ ìˆ˜ì¤€"
        },
        "ë°œí™”ì „ë‹¬ë ¥_ë¶„ì„": {
            "ë¶„ë‹¹ë‹¨ì–´ìˆ˜": "ë§í•˜ê¸° ì†ë„ ì§€í‘œ (60-80ì´ ì ì ˆ)",
            "ë§ì„¤ì„í‘œì§€": "ìŒ, ì–´, ê·¸ ë“±ì˜ ë§ì„¤ì„ í‘œí˜„",
            "í‰ê· ë¬¸ì¥ê¸¸ì´": "ë¬¸ì¥ë‹¹ í‰ê·  ë‹¨ì–´ ìˆ˜"
        },
        "TOPIK_ìë™ì ìˆ˜": {
            "ë‚´ìš©ë°ê³¼ì œìˆ˜í–‰": "ê³¼ì œ ì™„ì„±ë„ + ë‚´ìš© í’ë¶€í•¨ + ë‹´í™” êµ¬ì„± (1-5ì )",
            "ì–¸ì–´ì‚¬ìš©": "ë¬¸ë²• ì •í™•ì„± + ì–´íœ˜ ë‹¤ì–‘ì„± (1-5ì )",
            "ë°œí™”ì „ë‹¬ë ¥": "ì†ë„ + ìœ ì°½ì„± + ì¼ê´€ì„± ê°„ì ‘ ì§€í‘œ (1-5ì )"
        }
    }
    
    return descriptions.get(category, {}).get(key, "")


def evaluate_change(metric_name, change):
    """
    ë³€í™”ëŸ‰ í‰ê°€
    
    Args:
        metric_name: ì§€í‘œëª…
        change: ë³€í™”ëŸ‰
        
    Returns:
        str: í‰ê°€ ê²°ê³¼
    """
    if metric_name in ["ë…¹ìŒ ê¸¸ì´", "ë‹¨ì–´ ìˆ˜", "ë¬¸ì¥ ìˆ˜", "ì–´íœ˜ ë‹¤ì–‘ì„±", "ë¶„ë‹¹ ë‹¨ì–´ìˆ˜"]:
        # ì¦ê°€ê°€ ì¢‹ì€ ì§€í‘œë“¤
        if change > 0:
            return "ê°œì„ "
        elif change == 0:
            return "ë™ì¼"
        else:
            return "ê°ì†Œ"
    elif metric_name in ["ë¬¸ë²• ì˜¤ë¥˜", "ì˜¤ë¥˜ìœ¨"]:
        # ê°ì†Œê°€ ì¢‹ì€ ì§€í‘œë“¤
        if change < 0:
            return "ê°œì„ "
        elif change == 0:
            return "ë™ì¼"
        else:
            return "ì¦ê°€"
    else:
        return "ë³€í™”"


def calculate_self_efficacy_average():
    """
    ìê¸°íš¨ëŠ¥ê° í‰ê·  ê³„ì‚°
    
    Returns:
        float: ìê¸°íš¨ëŠ¥ê° í‰ê·  (1-5ì )
    """
    efficacy_scores = []
    for i in range(1, 7):
        score = getattr(st.session_state, f'self_efficacy_{i}', 0)
        if score and isinstance(score, (int, float)) and 1 <= score <= 5:
            efficacy_scores.append(score)
    
    return round(sum(efficacy_scores) / len(efficacy_scores), 2) if efficacy_scores else 0


def generate_data_quality_notes():
    """
    ë°ì´í„° í’ˆì§ˆ ì°¸ê³ ì‚¬í•­ ìƒì„±
    
    Returns:
        str: í’ˆì§ˆ ì°¸ê³ ì‚¬í•­
    """
    notes = []
    
    # ë…¹ìŒ ê¸¸ì´ ì²´í¬
    duration_1 = getattr(st.session_state, 'audio_duration_1', 0)
    duration_2 = getattr(st.session_state, 'audio_duration_2', 0)
    
    if duration_1 >= 90:
        notes.append("1ì°¨ë…¹ìŒ ìš°ìˆ˜ê¸¸ì´")
    elif duration_1 >= 60:
        notes.append("1ì°¨ë…¹ìŒ ì ì •ê¸¸ì´")
    else:
        notes.append("1ì°¨ë…¹ìŒ ì§§ìŒ")
    
    if duration_2 >= 90:
        notes.append("2ì°¨ë…¹ìŒ ìš°ìˆ˜ê¸¸ì´")
    elif duration_2 >= 60:
        notes.append("2ì°¨ë…¹ìŒ ì ì •ê¸¸ì´")
    else:
        notes.append("2ì°¨ë…¹ìŒ ì§§ìŒ")
    
    # ìê¸°íš¨ëŠ¥ê° ì²´í¬
    efficacy_avg = calculate_self_efficacy_average()
    if efficacy_avg > 0:
        notes.append(f"ìê¸°íš¨ëŠ¥ê° {efficacy_avg}/5.0")
    
    # ë™ì˜ì„œ ì²´í¬
    if getattr(st.session_state, 'consent_given', False):
        notes.append("ë™ì˜ì™„ë£Œ")
    
    return "; ".join(notes)


# === ê¸°ì¡´ í•¨ìˆ˜ë“¤ (ìˆ˜ì • ì—†ìŒ) ===

def build_session_data(timestamp):
    """
    ì„¸ì…˜ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ êµ¬ì„± (ìê¸°íš¨ëŠ¥ê° í•„ë“œ ì¶”ê°€)
    
    Args:
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        
    Returns:
        dict: ì™„ì„±ëœ ì„¸ì…˜ ë°ì´í„°
    """
    research_scores = getattr(st.session_state, 'research_scores', {})
    
    # ê¸°ë³¸ê°’ ì„¤ì •
    default_research_scores = {
        'accuracy_score': 0.0,
        'fluency_score': 0.0,
        'error_rate': 0.0,
        'word_count': 0,
        'duration_s': 0.0,
        'error_count': 0
    }
    
    for key, default_value in default_research_scores.items():
        if key not in research_scores:
            research_scores[key] = default_value

    session_data = {
        'session_id': st.session_state.session_id,
        'session_number': getattr(st.session_state, 'session_number', CURRENT_SESSION),
        'session_label': getattr(st.session_state, 'session_label', SESSION_LABELS.get(CURRENT_SESSION, "Session 1")),
        'original_nickname': getattr(st.session_state, 'original_nickname', ''),
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        
        # ë°°ê²½ ì •ë³´
        'learning_duration': getattr(st.session_state, 'learning_duration', ''),
        'speaking_confidence': getattr(st.session_state, 'speaking_confidence', ''),
        
        # ìê¸°íš¨ëŠ¥ê° ì ìˆ˜ 6ê°œ ì¶”ê°€
        'self_efficacy_1': getattr(st.session_state, 'self_efficacy_1', ''),
        'self_efficacy_2': getattr(st.session_state, 'self_efficacy_2', ''),
        'self_efficacy_3': getattr(st.session_state, 'self_efficacy_3', ''),
        'self_efficacy_4': getattr(st.session_state, 'self_efficacy_4', ''),
        'self_efficacy_5': getattr(st.session_state, 'self_efficacy_5', ''),
        'self_efficacy_6': getattr(st.session_state, 'self_efficacy_6', ''),
        
        # ê°•í™”ëœ ë™ì˜ ì¶”ì  (HTML íŒŒì¼ë¡œ ìˆ˜ì •)
        'consent_given': getattr(st.session_state, 'consent_given', False),
        'consent_timestamp': getattr(st.session_state, 'consent_timestamp', ''),
        'consent_participation': getattr(st.session_state, 'consent_participation', False),
        'consent_audio_ai': getattr(st.session_state, 'consent_audio_ai', False),
        'consent_data_storage': getattr(st.session_state, 'consent_data_storage', False),
        'consent_privacy_rights': getattr(st.session_state, 'consent_privacy_rights', False),
        'consent_final_confirmation': getattr(st.session_state, 'consent_final_confirmation', False),
        'consent_zoom_interview': getattr(st.session_state, 'consent_zoom_interview', False),
        'gdpr_compliant': getattr(st.session_state, 'gdpr_compliant', False),
        'consent_file_generated': getattr(st.session_state, 'consent_file', '') != '',
        'consent_file_filename': getattr(st.session_state, 'consent_file', ''),
        'consent_file_type': 'html',
        
        # ì‹¤í—˜ ë°ì´í„°
        'question': EXPERIMENT_QUESTION,
        'transcription_1': st.session_state.transcription_1,
        'transcription_2': st.session_state.transcription_2,
        'gpt_feedback_json': json.dumps(st.session_state.feedback, ensure_ascii=False),
        
        # ì—°êµ¬ìš© ì ìˆ˜ í•„ë“œ
        'research_accuracy_score': research_scores.get('accuracy_score', 0.0),
        'research_fluency_score': research_scores.get('fluency_score', 0.0),
        'research_error_rate': research_scores.get('error_rate', 0.0),
        'research_word_count': research_scores.get('word_count', 0),
        'research_duration_s': research_scores.get('duration_s', 0.0),
        'research_error_count': research_scores.get('error_count', 0),
        'research_scores_json': json.dumps(research_scores, ensure_ascii=False),
        
        # ë°ì´í„° í’ˆì§ˆ ë¶„ì„ í•„ë“œ
        'audio_duration_1': getattr(st.session_state, 'audio_duration_1', 0.0),
        'audio_duration_2': getattr(st.session_state, 'audio_duration_2', 0.0),
        'audio_quality_check_1': get_audio_quality_label(getattr(st.session_state, 'audio_duration_1', 0)),
        'audio_quality_check_2': get_audio_quality_label(getattr(st.session_state, 'audio_duration_2', 0)),
        
        # ê°œì„ ë„ í‰ê°€ ë°ì´í„°
        'improvement_score': getattr(st.session_state, 'improvement_assessment', {}).get('improvement_score', 0),
        'improvement_reason': getattr(st.session_state, 'improvement_assessment', {}).get('improvement_reason', ''),
        'first_attempt_score': getattr(st.session_state, 'improvement_assessment', {}).get('first_attempt_score', 0),
        'second_attempt_score': getattr(st.session_state, 'improvement_assessment', {}).get('second_attempt_score', 0),
        'score_difference': getattr(st.session_state, 'improvement_assessment', {}).get('score_difference', 0),
        'feedback_application': getattr(st.session_state, 'improvement_assessment', {}).get('feedback_application', ''),
        'specific_improvements': json.dumps(getattr(st.session_state, 'improvement_assessment', {}).get('specific_improvements', []), ensure_ascii=False),
        'remaining_issues': json.dumps(getattr(st.session_state, 'improvement_assessment', {}).get('remaining_issues', []), ensure_ascii=False),
        'overall_assessment': getattr(st.session_state, 'improvement_assessment', {}).get('overall_assessment', ''),
        'improvement_assessment_json': json.dumps(getattr(st.session_state, 'improvement_assessment', {}), ensure_ascii=False),
        
        # í•™ìƒìš© í”¼ë“œë°± í•„ë“œë“¤
        'suggested_model_sentence': st.session_state.feedback.get('suggested_model_sentence', ''),
        'suggested_model_sentence_english': st.session_state.feedback.get('suggested_model_sentence_english', ''),
        'fluency_comment': st.session_state.feedback.get('fluency_comment', ''),
        'interview_readiness_score': st.session_state.feedback.get('interview_readiness_score', ''),
        'interview_readiness_reason': st.session_state.feedback.get('interview_readiness_reason', ''),
        'grammar_expression_tip': st.session_state.feedback.get('grammar_expression_tip', ''),
        
        # STT ë£¨ë¸Œë¦­ ê¸°ë°˜ í”¼ë“œë°± ë¶„ì„
        'grammar_issues_count': len(st.session_state.feedback.get('grammar_issues', [])),
        'vocabulary_suggestions_count': len(st.session_state.feedback.get('vocabulary_suggestions', [])),
        'content_expansion_suggestions_count': len(st.session_state.feedback.get('content_expansion_suggestions', [])),
        'content_expansion_suggestions_json': json.dumps(st.session_state.feedback.get('content_expansion_suggestions', []), ensure_ascii=False),
        'grammar_issues_json': json.dumps(st.session_state.feedback.get('grammar_issues', []), ensure_ascii=False),
        'vocabulary_suggestions_json': json.dumps(st.session_state.feedback.get('vocabulary_suggestions', []), ensure_ascii=False),
        'highlight_targets_json': json.dumps(st.session_state.feedback.get('highlight_targets', {}), ensure_ascii=False),
        
        # ë””ë²„ê·¸ ì •ë³´
        'gpt_model_used': st.session_state.gpt_debug_info.get('model_used', ''),
        'gpt_attempts': st.session_state.gpt_debug_info.get('attempts', 0),
        'dual_evaluation_used': st.session_state.gpt_debug_info.get('dual_evaluation', False),
        
        # ğŸ†• TOPIK ìë™ ì ìˆ˜ ì¶”ê°€
        'topik_content_task_auto_1': get_topik_score(1, 'content_task_performance_score'),
        'topik_language_use_auto_1': get_topik_score(1, 'language_use_score'),
        'topik_speech_delivery_auto_1': get_topik_score(1, 'speech_delivery_score'),
        'topik_overall_auto_1': get_topik_score(1, 'overall_auto_score'),
        'topik_content_task_auto_2': get_topik_score(2, 'content_task_performance_score'),
        'topik_language_use_auto_2': get_topik_score(2, 'language_use_score'),
        'topik_speech_delivery_auto_2': get_topik_score(2, 'speech_delivery_score'),
        'topik_overall_auto_2': get_topik_score(2, 'overall_auto_score'),
        
        # ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´
        'audio_folder': f"{FOLDERS['audio_recordings']}/{getattr(st.session_state, 'session_number', CURRENT_SESSION)}_{st.session_state.session_id}_{timestamp}",
        
        # ë°ì´í„° ê´€ë¦¬ ì •ë³´
        'data_retention_until': (datetime.now() + timedelta(days=DATA_RETENTION_DAYS)).strftime('%Y-%m-%d'),
        'deletion_requested': False,
        'last_updated': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        
        # ì €ì¥ íƒ€ì´ë° ì •ë³´
        'saved_at_step': 'second_recording_complete',
        'save_trigger': 'auto_after_second_recording'
    }
    
    return session_data


def get_topik_score(attempt_number, score_type):
    """
    íŠ¹ì • ì‹œë„ì˜ TOPIK ì ìˆ˜ ë°˜í™˜
    
    Args:
        attempt_number: ì‹œë„ ë²ˆí˜¸ (1 or 2)
        score_type: ì ìˆ˜ íƒ€ì…
        
    Returns:
        float: TOPIK ì ìˆ˜
    """
    try:
        research_data = generate_research_data_for_attempt(attempt_number)
        if research_data:
            return research_data['summary_indicators'].get(score_type, 0)
        return 0
    except:
        return 0


def get_audio_quality_label(duration):
    """
    ìŒì„± ê¸¸ì´ì— ë”°ë¥¸ í’ˆì§ˆ ë¼ë²¨ ë°˜í™˜ (1-2ë¶„ ëª©í‘œ ê¸°ì¤€)
    
    Args:
        duration: ìŒì„± ê¸¸ì´ (ì´ˆ)
        
    Returns:
        str: í’ˆì§ˆ ë¼ë²¨
    """
    if duration >= 90:  # 1.5ë¶„ (ì¤‘ê°„ê°’)
        return 'excellent'
    elif duration >= 75:  # 1ë¶„ 15ì´ˆ
        return 'good'
    elif duration >= 60:  # 1ë¶„
        return 'fair'
    else:
        return 'very_short'


def save_to_csv(session_data, timestamp):
    """
    ì„¸ì…˜ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥
    
    Args:
        session_data: ì„¸ì…˜ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        
    Returns:
        str: CSV íŒŒì¼ ê²½ë¡œ
    """
    session_num = getattr(st.session_state, 'session_number', CURRENT_SESSION)
    csv_filename = os.path.join(
        FOLDERS["data"], 
        f"korean_session{session_num}_{st.session_state.session_id}_{timestamp}.csv"
    )
    
    with open(csv_filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=session_data.keys())
        writer.writeheader()
        writer.writerow(session_data)
    
    return csv_filename


def save_audio_files(timestamp):
    """
    ìŒì„± íŒŒì¼ë“¤ì„ ì €ì¥
    
    Args:
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        
    Returns:
        tuple: (folder_path, saved_files_list)
    """
    try:
        session_num = getattr(st.session_state, 'session_number', CURRENT_SESSION)
        folder_name = os.path.join(
            FOLDERS["audio_recordings"], 
            f"session{session_num}_{st.session_state.session_id}_{timestamp}"
        )
        os.makedirs(folder_name, exist_ok=True)
        
        saved_files = []
        
        # ì²« ë²ˆì§¸ ë…¹ìŒ
        if hasattr(st.session_state, 'first_audio') and st.session_state.first_audio:
            file_path = os.path.join(folder_name, "first_audio.wav")
            with open(file_path, "wb") as f:
                f.write(st.session_state.first_audio["bytes"])
            saved_files.append("first_audio.wav")
        
        # ë‘ ë²ˆì§¸ ë…¹ìŒ
        if hasattr(st.session_state, 'second_audio') and st.session_state.second_audio:
            file_path = os.path.join(folder_name, "second_audio.wav")
            with open(file_path, "wb") as f:
                f.write(st.session_state.second_audio["bytes"])
            saved_files.append("second_audio.wav")
        
        # ëª¨ë¸ ìŒì„± (ì¼ë°˜ ì†ë„)
        if st.session_state.model_audio.get("normal"):
            file_path = os.path.join(folder_name, "model_normal.mp3")
            with open(file_path, "wb") as f:
                f.write(st.session_state.model_audio["normal"])
            saved_files.append("model_normal.mp3")
        
        # ëª¨ë¸ ìŒì„± (ëŠë¦° ì†ë„)
        if st.session_state.model_audio.get("slow"):
            file_path = os.path.join(folder_name, "model_slow.mp3")
            with open(file_path, "wb") as f:
                f.write(st.session_state.model_audio["slow"])
            saved_files.append("model_slow.mp3")
        
        return folder_name, saved_files
    
    except Exception as e:
        st.error(f"âŒ Error saving audio files: {str(e)}")
        return None, []


def create_participant_info_file(session_id, timestamp):
    """
    ì°¸ì—¬ì ì •ë³´ íŒŒì¼ ìƒì„± (ìê¸°íš¨ëŠ¥ê° + TOPIK ì ìˆ˜ í¬í•¨)
    
    Args:
        session_id: ì„¸ì…˜ ID
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        
    Returns:
        str: ìƒì„±ëœ íŒŒì¼ ê²½ë¡œ
    """
    try:
        info_filename = os.path.join(FOLDERS["data"], f"{session_id}_participant_info.txt")
        
        original_nickname = getattr(st.session_state, 'original_nickname', 'Unknown')
        session_label = getattr(st.session_state, 'session_label', SESSION_LABELS.get(CURRENT_SESSION, "Session 1"))
        learning_duration = getattr(st.session_state, 'learning_duration', 'Not specified')
        speaking_confidence = getattr(st.session_state, 'speaking_confidence', 'Not specified')
        
        # ìê¸°íš¨ëŠ¥ê° ì ìˆ˜ ìˆ˜ì§‘ (6ê°œ)
        efficacy_scores = []
        for i in range(1, 7):
            score = getattr(st.session_state, f'self_efficacy_{i}', 'N/A')
            efficacy_scores.append(f"Item {i}: {score}/5")
        
        efficacy_avg = calculate_self_efficacy_average()
        
        # TOPIK ìë™ ì ìˆ˜ ì •ë³´
        topik_scores_1 = []
        topik_scores_2 = []
        
        for attempt in [1, 2]:
            research_data = generate_research_data_for_attempt(attempt)
            if research_data:
                scores = research_data['summary_indicators']
                score_text = f"ë‚´ìš©ë°ê³¼ì œìˆ˜í–‰: {scores.get('content_task_performance_score', 'N/A')}/5, ì–¸ì–´ì‚¬ìš©: {scores.get('language_use_score', 'N/A')}/5, ë°œí™”ì „ë‹¬ë ¥: {scores.get('speech_delivery_score', 'N/A')}/5, ì „ì²´: {scores.get('overall_auto_score', 'N/A')}/5"
                if attempt == 1:
                    topik_scores_1.append(score_text)
                else:
                    topik_scores_2.append(score_text)
        
        research_scores = getattr(st.session_state, 'research_scores', {})
        accuracy_score = research_scores.get('accuracy_score', 'N/A')
        fluency_score = research_scores.get('fluency_score', 'N/A')
        error_rate = research_scores.get('error_rate', 'N/A')
        word_count = research_scores.get('word_count', 'N/A')
        
        info_content = f"""=== PARTICIPANT INFORMATION ===
Anonymous ID: {session_id}
Original Nickname: {original_nickname}
Session: {session_label} (Session {CURRENT_SESSION})
Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Save Trigger: Auto-save after second recording completion

=== BACKGROUND INFORMATION ===
Learning Duration: {learning_duration}
Speaking Confidence: {speaking_confidence}

=== SELF-EFFICACY SCORES (1-5 scale) ===
{chr(10).join(efficacy_scores)}
Average Self-Efficacy: {efficacy_avg}/5.0

=== EXPERIMENT DETAILS ===
Question: {EXPERIMENT_QUESTION}
First Recording Duration: {getattr(st.session_state, 'audio_duration_1', 0):.1f} seconds
Second Recording Duration: {getattr(st.session_state, 'audio_duration_2', 0):.1f} seconds
Student UI Score: {st.session_state.feedback.get('interview_readiness_score', 'N/A')}/10

=== TOPIK-BASED AUTO SCORES (NEW) ===
1ì°¨ ì‹œë„: {topik_scores_1[0] if topik_scores_1 else 'N/A'}
2ì°¨ ì‹œë„: {topik_scores_2[0] if topik_scores_2 else 'N/A'}

=== RESEARCH SCORES (LEGACY) ===
Accuracy Score: {accuracy_score}/10 (Error rate: {error_rate}%)
Fluency Score: {fluency_score}/10 (Word count: {word_count})
Dual Evaluation System: {getattr(st.session_state, 'gpt_debug_info', {}).get('dual_evaluation', False)}

=== CONSENT INFORMATION ===
Consent Given: {getattr(st.session_state, 'consent_given', False)}
Consent Timestamp: {getattr(st.session_state, 'consent_timestamp', 'N/A')}
GDPR Compliant: {getattr(st.session_state, 'gdpr_compliant', False)}
Zoom Interview Consent: {getattr(st.session_state, 'consent_zoom_interview', False)}
Consent File Type: HTML (Korean language support)

=== DATA MANAGEMENT ===
Data Retention Until: {(datetime.now() + timedelta(days=DATA_RETENTION_DAYS)).strftime('%Y-%m-%d')}
Storage Method: GCS ZIP Archive + Research Excel (Auto-save after 2nd recording)
Last Updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

=== FOR RESEARCHER ===
This file contains the link between the anonymous ID and the original nickname.
Data was automatically saved after second recording completion.
NEW: TOPIK-based 3-area scoring system implemented for research analysis.
Research Excel file includes detailed analysis sheets for manual grading.
Self-efficacy scores (1-5 scale) collected before experiment.
Consent form is stored as HTML file for Korean language compatibility.
Contact: pen0226@gmail.com for any data requests or questions.
"""
        
        with open(info_filename, 'w', encoding='utf-8') as f:
            f.write(info_content)
        
        return info_filename
    
    except Exception as e:
        return None


def create_comprehensive_backup_zip(session_id, timestamp):
    """
    ëª¨ë“  ì„¸ì…˜ ë°ì´í„°ë¥¼ í¬í•¨í•œ ì™„ì „í•œ ë°±ì—… ZIP ìƒì„± (ì—°êµ¬ìš© Excel í¬í•¨)
    
    Args:
        session_id: ì„¸ì…˜ ID
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        
    Returns:
        str: ZIP íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None
    """
    try:
        session_num = getattr(st.session_state, 'session_number', CURRENT_SESSION)
        zip_filename = os.path.join(
            FOLDERS["data"], 
            f"{session_id}_{timestamp}.zip"
        )
        
        with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:
            
            # ì°¸ì—¬ì ì •ë³´ íŒŒì¼ ìƒì„± ë° ì¶”ê°€
            participant_info_file = create_participant_info_file(session_id, timestamp)
            if participant_info_file and os.path.exists(participant_info_file):
                zipf.write(participant_info_file, "participant_info.txt")
            
            # CSV íŒŒì¼ ì¶”ê°€
            csv_file = os.path.join(FOLDERS["data"], f"korean_session{session_num}_{session_id}_{timestamp}.csv")
            if os.path.exists(csv_file):
                zipf.write(csv_file, f"session_data_{timestamp}.csv")
            
            # ğŸ†• ì—°êµ¬ìš© Excel íŒŒì¼ ì¶”ê°€
            excel_file = os.path.join(FOLDERS["data"], f"research_analysis_session{session_num}_{session_id}_{timestamp}.xlsx")
            if os.path.exists(excel_file):
                zipf.write(excel_file, f"research_analysis_{timestamp}.xlsx")
                print(f"âœ… Research Excel included: research_analysis_{timestamp}.xlsx")
            
            # HTML ë™ì˜ì„œ íŒŒì¼ ì¶”ê°€
            consent_html = os.path.join(FOLDERS["data"], f"{session_id}_consent.html")
            if os.path.exists(consent_html):
                zipf.write(consent_html, f"consent_form_{session_id}.html")
                print(f"âœ… Consent HTML file included: {session_id}_consent.html")
            else:
                print(f"âš ï¸ Consent HTML file not found: {session_id}_consent.html")
            
            # í˜¹ì‹œë‚˜ PDF íŒŒì¼ë„ ìˆë‹¤ë©´ í•¨ê»˜ í¬í•¨ (í•˜ìœ„ í˜¸í™˜ì„±)
            consent_pdf = os.path.join(FOLDERS["data"], f"{session_id}_consent.pdf")
            if os.path.exists(consent_pdf):
                zipf.write(consent_pdf, f"consent_form_{session_id}.pdf")
                print(f"âœ… Consent PDF file also included: {session_id}_consent.pdf")
            
            # ìŒì„± íŒŒì¼ë“¤ ì¶”ê°€
            audio_folder = os.path.join(FOLDERS["audio_recordings"], f"session{session_num}_{session_id}_{timestamp}")
            if os.path.exists(audio_folder):
                for file in os.listdir(audio_folder):
                    file_path = os.path.join(audio_folder, file)
                    zipf.write(file_path, f"audio/{file}")
            
            # ZIP ë‚´ìš© ìš”ì•½ íŒŒì¼ ì¶”ê°€
            research_scores = getattr(st.session_state, 'research_scores', {})
            efficacy_avg = calculate_self_efficacy_average()
            
            readme_content = f"""=== ZIP CONTENTS SUMMARY ===
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Participant: {session_id} (Session {session_num})
Save Trigger: Auto-save after second recording completion

Files included:
- participant_info.txt: Participant details + Research scores + Self-efficacy scores + TOPIK auto scores
- session_data_{timestamp}.csv: Complete session data with dual evaluation + TOPIK scores + self-efficacy data
- research_analysis_{timestamp}.xlsx: â­ NEW: Comprehensive research analysis with TOPIK-based scoring
- consent_form_{session_id}.html: Signed consent form (HTML format for Korean support)
- audio/: All recorded audio files (student + model pronunciations)

ğŸ†• RESEARCH EXCEL SHEETS:
1. ì±„ì ììš©_ìš”ì•½: Grading summary with auto/manual score columns (_auto, _rater1, _rater2)
2. 1ì°¨_ìƒì„¸ë¶„ì„: Detailed analysis of first attempt (task performance, language use, speech delivery)
3. 2ì°¨_ìƒì„¸ë¶„ì„: Detailed analysis of second attempt
4. ì ìˆ˜_ë¹„êµ: Score comparison between attempts with improvement metrics  
5. ì›ë³¸_ì„¸ì…˜ë°ì´í„°: Original session data for reference

ğŸ¯ TOPIK-BASED AUTO SCORING (1-5 points each):
- ë‚´ìš© ë° ê³¼ì œ ìˆ˜í–‰: Task completion + content richness + discourse organization
- ì–¸ì–´ ì‚¬ìš©: Grammar accuracy + vocabulary diversity + appropriateness
- ë°œí™” ì „ë‹¬ë ¥: Speaking pace + fluency indicators + consistency (indirect measures)

SELF-EFFICACY DATA:
- 6 items measured on 1-5 scale
- Average self-efficacy score: {efficacy_avg}/5.0
- Individual scores stored in CSV under self_efficacy_1 through self_efficacy_6

CONSENT FORM FORMAT:
- HTML format for perfect Korean language support
- Can be saved as PDF using browser print function (Ctrl+P)
- Avoids character encoding issues that occurred with direct PDF generation

DUAL EVALUATION SYSTEM:
- Student UI Score: Educational feedback (GPT-generated with TOPIK criteria)
- Research Auto Scores: TOPIK-based objective metrics for academic analysis
- Manual Grading Support: Excel templates for human raters with reference data

RESEARCH WORKFLOW:
1. Use research_analysis.xlsx for systematic manual grading
2. Auto scores provide baseline reference for human raters
3. Compare auto vs manual scores for reliability studies
4. All raw data preserved for transparency

IMPORTANT: Data was automatically saved after second recording completion.
This ensures no data loss even if survey is not completed.

Contact researcher: pen0226@gmail.com
"""
            
            readme_path = os.path.join(FOLDERS["data"], f"{session_id}_readme.txt")
            with open(readme_path, 'w', encoding='utf-8') as f:
                f.write(readme_content)
            zipf.write(readme_path, "README.txt")
        
        # ì„ì‹œ íŒŒì¼ë“¤ ì •ë¦¬
        temp_files = [participant_info_file, readme_path]
        for temp_file in temp_files:
            if temp_file and os.path.exists(temp_file):
                try:
                    os.remove(temp_file)
                except:
                    pass
        
        print(f"âœ… Comprehensive backup ZIP created with research Excel: {zip_filename}")
        return zip_filename
        
    except Exception as e:
        st.error(f"âŒ Error creating comprehensive backup ZIP: {e}")
        return None


# === GCS ê´€ë ¨ í•¨ìˆ˜ë“¤ (ìˆ˜ì • ì—†ìŒ) ===

def get_gcs_client():
    """
    GCS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    
    Returns:
        tuple: (client, bucket, status_message)
    """
    try:
        from google.cloud import storage
        import json
        
        if not GCS_ENABLED:
            return None, None, "GCS upload is disabled in configuration"
        
        if not GCS_SERVICE_ACCOUNT:
            return None, None, "GCS service account not configured"
        
        try:
            if isinstance(GCS_SERVICE_ACCOUNT, dict):
                credentials_dict = dict(GCS_SERVICE_ACCOUNT)
                print(f"Using TOML format service account (Project: {credentials_dict.get('project_id', 'Unknown')})")
            elif isinstance(GCS_SERVICE_ACCOUNT, str):
                credentials_dict = json.loads(GCS_SERVICE_ACCOUNT)
                print(f"Using JSON format service account (Project: {credentials_dict.get('project_id', 'Unknown')})")
            else:
                return None, None, f"Unexpected service account type: {type(GCS_SERVICE_ACCOUNT)}"
                
        except json.JSONDecodeError:
            return None, None, "Invalid JSON format in service account"
        except Exception as parse_error:
            return None, None, f"Service account parsing error: {str(parse_error)}"
        
        client = storage.Client.from_service_account_info(credentials_dict)
        bucket = client.bucket(GCS_BUCKET_NAME)
        
        return client, bucket, "Success"
        
    except ImportError as e:
        return None, None, f"Missing required libraries: {str(e)}. Run: pip install google-cloud-storage"
    except Exception as e:
        return None, None, f"GCS client initialization failed: {str(e)}"


def upload_to_gcs(local_path, blob_name):
    """
    GCSì— íŒŒì¼ ì—…ë¡œë“œ
    
    Args:
        local_path: ì—…ë¡œë“œí•  ë¡œì»¬ íŒŒì¼ ê²½ë¡œ
        blob_name: GCSì—ì„œ ì‚¬ìš©í•  íŒŒì¼ëª…
        
    Returns:
        tuple: (blob_url, status_message)
    """
    try:
        client, bucket, status = get_gcs_client()
        if not client:
            return None, f"GCS client error: {status}"
        
        if not os.path.exists(local_path):
            return None, f"File not found: {local_path}"
        
        blob = bucket.blob(blob_name)
        blob.upload_from_filename(local_path)
        
        blob_url = f"gs://{GCS_BUCKET_NAME}/{blob_name}"
        print(f"ZIP uploaded: {blob_name}")
        
        return blob_url, f"Successfully uploaded: {blob_name}"
        
    except Exception as e:
        return None, f"Upload failed: {str(e)}"


def auto_backup_to_gcs(csv_filename, excel_filename, zip_filename, session_id, timestamp):
    """
    ZIP íŒŒì¼ë§Œ GCSì— ìë™ ë°±ì—… + nickname_mapping.csv ë°±ì—…
    
    Args:
        csv_filename: CSV íŒŒì¼ ê²½ë¡œ
        excel_filename: Excel íŒŒì¼ ê²½ë¡œ (ì—°êµ¬ìš©)
        zip_filename: ZIP íŒŒì¼ ê²½ë¡œ
        session_id: ì„¸ì…˜ ID
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        
    Returns:
        tuple: (uploaded_files, errors)
    """
    uploaded_files = []
    errors = []
    
    if not GCS_ENABLED:
        errors.append("GCS upload is disabled in configuration")
        return uploaded_files, errors
    
    session_num = getattr(st.session_state, 'session_number', CURRENT_SESSION)
    session_folder = GCS_SIMPLE_STRUCTURE.get(session_num, GCS_SIMPLE_STRUCTURE[1])
    
    # ZIP íŒŒì¼ ì—…ë¡œë“œ (ì—°êµ¬ìš© Excel í¬í•¨)
    if zip_filename and os.path.exists(zip_filename):
        try:
            blob_name = f"{session_folder}{session_id}_{timestamp}.zip"
            blob_url, result_msg = upload_to_gcs(zip_filename, blob_name)
            
            if blob_url:
                uploaded_files.append(blob_name)
                print(f"âœ… ZIP with HTML consent + self-efficacy + research Excel uploaded: {blob_name}")
            else:
                errors.append(f"ZIP upload failed: {result_msg}")
                
        except Exception as e:
            errors.append(f"ZIP upload error: {str(e)}")
    else:
        errors.append("ZIP file not found for upload")
    
    # nickname_mapping.csv ë°±ì—…
    mapping_file = os.path.join(FOLDERS["data"], 'nickname_mapping.csv')
    if os.path.exists(mapping_file):
        try:
            mapping_blob_name = "nickname_mapping.csv"
            blob_url, result_msg = upload_to_gcs(mapping_file, mapping_blob_name)
            
            if blob_url:
                uploaded_files.append(mapping_blob_name)
            else:
                errors.append(f"Mapping file upload failed: {result_msg}")
                
        except Exception as e:
            errors.append(f"Mapping file upload error: {str(e)}")
    
    return uploaded_files, errors


def test_gcs_connection():
    """
    GCS ì—°ê²° ìƒíƒœ í…ŒìŠ¤íŠ¸
    
    Returns:
        tuple: (success, message)
    """
    try:
        client, bucket, status = get_gcs_client()
        if not client:
            return False, f"GCS connection failed: {status}"
        
        if bucket.exists():
            project_id = "Unknown"
            if isinstance(GCS_SERVICE_ACCOUNT, dict):
                project_id = GCS_SERVICE_ACCOUNT.get('project_id', 'Unknown')
                format_type = "TOML format"
            else:
                import json
                try:
                    service_info = json.loads(GCS_SERVICE_ACCOUNT)
                    project_id = service_info.get('project_id', 'Unknown')
                    format_type = "JSON format"
                except:
                    format_type = "Unknown format"
            
            return True, f"Connected successfully to bucket: {GCS_BUCKET_NAME} (Project: {project_id} - {format_type})"
        else:
            return False, f"Bucket not found: {GCS_BUCKET_NAME}"
        
    except Exception as e:
        return False, f"Connection test failed: {str(e)}"


def log_upload_status(session_id, timestamp, uploaded_files, errors, email_sent=False):
    """
    GCS ì—…ë¡œë“œ ê²°ê³¼ë¥¼ ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡ (ì—°êµ¬ìš© Excel ì •ë³´ í¬í•¨)
    
    Args:
        session_id: ì„¸ì…˜ ID
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        uploaded_files: ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡
        errors: ì˜¤ë¥˜ ëª©ë¡
        email_sent: ì´ë©”ì¼ ì „ì†¡ ì—¬ë¶€
        
    Returns:
        bool: ë¡œê·¸ ê¸°ë¡ ì„±ê³µ ì—¬ë¶€
    """
    try:
        os.makedirs(FOLDERS["logs"], exist_ok=True)
        
        log_date = datetime.now().strftime('%Y%m%d')
        log_filename = os.path.join(
            FOLDERS["logs"], 
            f"upload_log_{log_date}.txt"
        )
        
        session_num = getattr(st.session_state, 'session_number', CURRENT_SESSION)
        session_label = getattr(st.session_state, 'session_label', SESSION_LABELS.get(CURRENT_SESSION, "Session 1"))
        original_nickname = getattr(st.session_state, 'original_nickname', 'Unknown')
        
        research_scores = getattr(st.session_state, 'research_scores', {})
        accuracy_score = research_scores.get('accuracy_score', 'N/A')
        fluency_score = research_scores.get('fluency_score', 'N/A')
        dual_eval_used = getattr(st.session_state, 'gpt_debug_info', {}).get('dual_evaluation', False)
        
        # ìê¸°íš¨ëŠ¥ê° í‰ê·  ê³„ì‚° (6ê°œ)
        efficacy_avg = calculate_self_efficacy_average()
        
        # TOPIK ì ìˆ˜ ì •ë³´
        topik_1 = get_topik_score(1, 'overall_auto_score')
        topik_2 = get_topik_score(2, 'overall_auto_score')
        
        upload_status = "SUCCESS" if uploaded_files and not errors else "PARTIAL" if uploaded_files else "FAILED"
        
        log_entry = f"""
[{datetime.now().strftime(LOG_FORMAT['timestamp_format'])}] SESSION: {session_label} - {session_id}_{timestamp}
Nickname: {original_nickname}
Status: {upload_status}
Save Trigger: Auto-save after second recording completion
Dual Evaluation: {dual_eval_used} (Research scores: Accuracy={accuracy_score}, Fluency={fluency_score})
Self-Efficacy: Average {efficacy_avg}/5.0 (6 items collected)
        TOPIK Auto Scores: 1ì°¨={topik_1}/5, 2ì°¨={topik_2}/5 (NEW: 3-area scoring system)
GCS Enabled: {GCS_ENABLED} (Service Account method - ZIP with research Excel)
Bucket: {GCS_BUCKET_NAME}
Files uploaded: {len(uploaded_files)} ({', '.join(uploaded_files) if uploaded_files else 'None'})
Errors: {len(errors)} ({'; '.join(errors) if errors else 'None'})
Email notification: {'Sent' if email_sent else 'Not sent/Failed'}
Data Safety: Secured before survey step
Research Excel: TOPIK-based analysis with grading support included
Research Data: TOPIK 3-area auto scores + self-efficacy calculated and stored
Consent Format: HTML (Korean language support) - Fixed backup inclusion
{'='*80}
"""
        
        with open(log_filename, 'a', encoding='utf-8') as log_file:
            log_file.write(log_entry)
        
        return True
    except Exception:
        return False


def display_download_buttons(csv_filename, excel_filename, zip_filename):
    """
    ì—°êµ¬ììš© ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ë“¤ í‘œì‹œ (ì—°êµ¬ìš© Excel í¬í•¨)
    
    Args:
        csv_filename: CSV íŒŒì¼ ê²½ë¡œ
        excel_filename: Excel íŒŒì¼ ê²½ë¡œ (ì—°êµ¬ìš©)
        zip_filename: ZIP íŒŒì¼ ê²½ë¡œ
    """
    if GCS_ENABLED:
        st.info("ğŸ“¤ ZIP file (including research Excel + HTML consent + self-efficacy data) should be automatically uploaded to Google Cloud Storage. Use these downloads as backup only.")
    else:
        st.warning("âš ï¸ GCS upload is disabled. Use these download buttons to save your data.")
    
    col1, col2, col3 = st.columns(3)
    
    session_num = getattr(st.session_state, 'session_number', CURRENT_SESSION)
    timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    with col1:
        # ZIP ì™„ì „ ë°±ì—… ë‹¤ìš´ë¡œë“œ
        if zip_filename and os.path.exists(zip_filename):
            try:
                with open(zip_filename, 'rb') as f:
                    zip_data = f.read()
                st.download_button(
                    label="ğŸ“¦ Complete Backup ZIP (w/ Research Excel)",
                    data=zip_data,
                    file_name=f"{st.session_state.session_id}_{timestamp_str}.zip",
                    mime='application/zip',
                    use_container_width=True
                )
            except:
                st.info("ZIP unavailable")
        else:
            st.info("ZIP unavailable")
    
    with col2:
        # ğŸ†• ì—°êµ¬ìš© Excel ë‹¤ìš´ë¡œë“œ
        if excel_filename and os.path.exists(excel_filename):
            try:
                with open(excel_filename, 'rb') as f:
                    excel_data = f.read()
                st.download_button(
                    label="ğŸ“Š Research Analysis Excel",
                    data=excel_data,
                    file_name=f"research_analysis_{st.session_state.session_id}_{timestamp_str}.xlsx",
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                    use_container_width=True
                )
            except:
                st.info("Research Excel unavailable")
        else:
            st.info("Research Excel unavailable")
    
    with col3:
        # CSV ë‹¤ìš´ë¡œë“œ
        if csv_filename and os.path.exists(csv_filename):
            try:
                with open(csv_filename, 'r', encoding='utf-8') as f:
                    csv_data = f.read()
                st.download_button(
                    label="ğŸ“„ CSV Data (Open in Excel)",
                    data=csv_data,
                    file_name=f"session{session_num}_{st.session_state.session_id}_{timestamp_str}.csv",
                    mime='text/csv',
                    use_container_width=True
                )
            except:
                st.error("CSV download failed")
        else:
            st.info("CSV unavailable")
    
    st.caption("â„¹ï¸ ğŸ†• Research Excel includes TOPIK-based analysis with manual grading templates. ZIP contains all files. HTML consent + self-efficacy data included.")


def display_session_details():
    """
    ì—°êµ¬ììš© ì„¸ì…˜ ìƒì„¸ ì •ë³´ í‘œì‹œ (TOPIK ì ìˆ˜ í¬í•¨)
    """
    st.markdown("**ğŸ“‹ Session Details:**")
    display_name = getattr(st.session_state, 'original_nickname', st.session_state.session_id)
    session_label = getattr(st.session_state, 'session_label', SESSION_LABELS.get(CURRENT_SESSION, "Session 1"))
    st.write(f"**Participant:** {display_name} (ID: {st.session_state.session_id})")
    st.write(f"**Session:** {session_label}")
    st.write(f"**Question:** {EXPERIMENT_QUESTION}")
    st.write(f"**Completed:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    st.write(f"**Data Saved:** After second recording completion")
    
    # ë°°ê²½ ì •ë³´ í‘œì‹œ
    learning_duration = getattr(st.session_state, 'learning_duration', '')
    speaking_confidence = getattr(st.session_state, 'speaking_confidence', '')
    if learning_duration:
        st.write(f"**Learning Duration:** {learning_duration}")
    if speaking_confidence:
        st.write(f"**Speaking Confidence:** {speaking_confidence}")
    
    # ìê¸°íš¨ëŠ¥ê° ì ìˆ˜ í‘œì‹œ (6ê°œ)
    efficacy_avg = calculate_self_efficacy_average()
    if efficacy_avg > 0:
        st.write(f"**Self-Efficacy:** {efficacy_avg}/5.0 (6 items)")
        with st.expander("ğŸ¯ Self-Efficacy Details", expanded=False):
            for i in range(1, 7):
                score = getattr(st.session_state, f'self_efficacy_{i}', 0)
                if score:
                    st.write(f"Item {i}: {score}/5")
    
    # ğŸ†• TOPIK ìë™ ì ìˆ˜ ì •ë³´ í‘œì‹œ
    st.markdown("**ğŸ¯ TOPIK-Based Auto Scores (NEW):**")
    topik_data_1 = generate_research_data_for_attempt(1)
    topik_data_2 = generate_research_data_for_attempt(2)
    
    if topik_data_1:
        scores_1 = topik_data_1['summary_indicators']
        st.write(f"1ì°¨ ì‹œë„: ë‚´ìš©ë°ê³¼ì œìˆ˜í–‰ {scores_1.get('content_task_performance_score', 'N/A')}/5, ì–¸ì–´ì‚¬ìš© {scores_1.get('language_use_score', 'N/A')}/5, ë°œí™”ì „ë‹¬ë ¥ {scores_1.get('speech_delivery_score', 'N/A')}/5")
    
    if topik_data_2:
        scores_2 = topik_data_2['summary_indicators']
        st.write(f"2ì°¨ ì‹œë„: ë‚´ìš©ë°ê³¼ì œìˆ˜í–‰ {scores_2.get('content_task_performance_score', 'N/A')}/5, ì–¸ì–´ì‚¬ìš© {scores_2.get('language_use_score', 'N/A')}/5, ë°œí™”ì „ë‹¬ë ¥ {scores_2.get('speech_delivery_score', 'N/A')}/5")
    
    if not topik_data_1 and not topik_data_2:
        st.write("âŒ TOPIK auto scores not calculated")
    
    # ê¸°ì¡´ ì—°êµ¬ìš© ì ìˆ˜ ì •ë³´ í‘œì‹œ
    research_scores = getattr(st.session_state, 'research_scores', {})
    if research_scores:
        st.markdown("**ğŸ”¬ Legacy Research Scores:**")
        accuracy = research_scores.get('accuracy_score', 'N/A')
        fluency = research_scores.get('fluency_score', 'N/A')
        error_rate = research_scores.get('error_rate', 'N/A')
        word_count = research_scores.get('word_count', 'N/A')
        st.write(f"Accuracy Score: {accuracy}/10 (Error rate: {error_rate}%)")
        st.write(f"Fluency Score: {fluency}/10 (Word count: {word_count})")
        dual_eval = getattr(st.session_state, 'gpt_debug_info', {}).get('dual_evaluation', False)
        st.write(f"Dual Evaluation System: {'âœ… Active' if dual_eval else 'âŒ Not used'}")
    else:
        st.write("**ğŸ”¬ Legacy Research Scores:** âŒ Not calculated")
    
    # GCS ì—°ë™ ìƒíƒœ í‘œì‹œ
    st.markdown("**â˜ï¸ Google Cloud Storage Status:**")
    if GCS_ENABLED:
        st.success("âœ… GCS upload is enabled (Service Account method - ZIP with research Excel)")
        if GCS_BUCKET_NAME:
            st.write(f"Bucket: {GCS_BUCKET_NAME}")
            st.write(f"Storage method: ZIP archives + nickname mapping")
            st.write(f"Research Excel: TOPIK-based analysis with grading support")
            st.write(f"Consent format: HTML (Korean language support)")
            st.write(f"Self-efficacy: 6 items (1-5 scale) included")
            st.write(f"Save timing: Auto-save after 2nd recording")
        else:
            st.warning("âš ï¸ No bucket specified")
        
        success, message = test_gcs_connection()
        if success:
            st.write("ğŸ”— Connection: âœ… Active")
        else:
            st.write(f"ğŸ”— Connection: âŒ {message}")
    else:
        st.warning("âŒ GCS upload is disabled")


def display_data_quality_info():
    """
    ë°ì´í„° í’ˆì§ˆ ì •ë³´ í‘œì‹œ (TOPIK ì ìˆ˜ í¬í•¨)
    """
    st.markdown("**ğŸ“Š Data Quality:**")
    col1, col2 = st.columns(2)
    
    with col1:
        duration1 = getattr(st.session_state, 'audio_duration_1', 0)
        if duration1 > 0:
            quality1 = get_quality_description(duration1)
            st.write(f"First recording: {duration1:.1f}s")
            st.caption(quality1)
        
        if st.session_state.feedback:
            issues_count = len(st.session_state.feedback.get('grammar_issues', []))
            vocab_count = len(st.session_state.feedback.get('vocabulary_suggestions', []))
            content_count = len(st.session_state.feedback.get('content_expansion_suggestions', []))
            st.write(f"Grammar issues: {issues_count}")
            st.write(f"Vocab suggestions: {vocab_count}")
            st.write(f"Content ideas: {content_count}")
            
            student_score = st.session_state.feedback.get('interview_readiness_score', 'N/A')
            st.write(f"Student UI Score: {student_score}/10")
        
        # ğŸ†• TOPIK ìë™ ì ìˆ˜ (1ì°¨)
        topik_data_1 = generate_research_data_for_attempt(1)
        if topik_data_1:
            st.write("**ğŸ¯ TOPIK Auto (1ì°¨):**")
            scores = topik_data_1['summary_indicators']
            st.write(f"ë‚´ìš©: {scores.get('content_task_performance_score', 'N/A')}/5")
            st.write(f"ì–¸ì–´: {scores.get('language_use_score', 'N/A')}/5")
            st.write(f"ì „ë‹¬: {scores.get('speech_delivery_score', 'N/A')}/5")
        
        # ìê¸°íš¨ëŠ¥ê° ìš”ì•½ (6ê°œ)
        efficacy_avg = calculate_self_efficacy_average()
        if efficacy_avg > 0:
            st.write(f"**ğŸ¯ Self-Efficacy:** {efficacy_avg}/5.0")
    
    with col2:
        duration2 = getattr(st.session_state, 'audio_duration_2', 0)
        if duration2 > 0:
            quality2 = get_quality_description(duration2)
            st.write(f"Second recording: {duration2:.1f}s")
            st.caption(quality2)
        
        if hasattr(st.session_state, 'improvement_assessment'):
            improvement = st.session_state.improvement_assessment
            score = improvement.get('improvement_score', 0)
            first_score = improvement.get('first_attempt_score', 0)
            second_score = improvement.get('second_attempt_score', 0)
            st.write(f"Improvement score: {score}/10")
            st.write(f"Progress: {first_score} â†’ {second_score}")
            improvements = len(improvement.get('specific_improvements', []))
            issues = len(improvement.get('remaining_issues', []))
            st.write(f"Improvements: {improvements}")
            st.write(f"Remaining issues: {issues}")
        
        # ğŸ†• TOPIK ìë™ ì ìˆ˜ (2ì°¨)
        topik_data_2 = generate_research_data_for_attempt(2)
        if topik_data_2:
            st.write("**ğŸ¯ TOPIK Auto (2ì°¨):**")
            scores = topik_data_2['summary_indicators']
            st.write(f"ë‚´ìš©: {scores.get('content_task_performance_score', 'N/A')}/5")
            st.write(f"ì–¸ì–´: {scores.get('language_use_score', 'N/A')}/5")
            st.write(f"ì „ë‹¬: {scores.get('speech_delivery_score', 'N/A')}/5")
            
            # ê°œì„ ë„ í‘œì‹œ
            if topik_data_1:
                scores_1 = topik_data_1['summary_indicators']
                improvement = scores['overall_auto_score'] - scores_1['overall_auto_score']
                st.write(f"ì „ì²´ ê°œì„ : {improvement:+.1f}")
        
        if hasattr(st.session_state, 'data_saved') and st.session_state.data_saved:
            st.write("ğŸ’¾ **Data Status:** âœ… Safely saved")
        else:
            st.write("ğŸ’¾ **Data Status:** âš ï¸ Not yet saved")


def get_quality_description(duration):
    """
    ìŒì„± ê¸¸ì´ì— ë”°ë¥¸ í’ˆì§ˆ ì„¤ëª… ë°˜í™˜ (1-2ë¶„ ëª©í‘œ ê¸°ì¤€)
    
    Args:
        duration: ìŒì„± ê¸¸ì´ (ì´ˆ)
        
    Returns:
        str: í’ˆì§ˆ ì„¤ëª…
    """
    if duration >= 90:
        return "âœ… Excellent (1.5min+ target reached!)"
    elif duration >= 75:
        return "ğŸŒŸ Good (1.25-1.5min, try for 1.5min+)"
    elif duration >= 60:
        return "âš ï¸ Fair (1-1.25min, needs improvement)"
    else:
        return "âŒ Very Short (under 1min, much more needed)"