"""
data_io.py
ì‹¤í—˜ ë°ì´í„° ì €ì¥, ë°±ì—…, ì—…ë¡œë“œ ë° ë¡œê·¸ ê´€ë¦¬ ëª¨ë“ˆ
"""

import os
import csv
import json
import zipfile
from datetime import datetime, timedelta
import streamlit as st
from config import (
    FOLDERS, 
    DATA_RETENTION_DAYS, 
    EXPERIMENT_QUESTION,
    GCS_ENABLED,
    GCS_BUCKET_NAME,
    GCS_SERVICE_ACCOUNT,
    GCS_SIMPLE_STRUCTURE,
    LOG_FORMAT,
    CURRENT_SESSION,
    SESSION_LABELS
)


def save_session_data():
    """
    ì„¸ì…˜ ë°ì´í„°ë¥¼ CSV í˜•ì‹ìœ¼ë¡œ ì €ì¥
    
    Returns:
        tuple: (csv_filename, excel_filename, audio_folder, saved_files, zip_filename, timestamp)
    """
    try:
        # ì¤‘ë³µ ì €ì¥ ë°©ì§€
        if hasattr(st.session_state, 'data_saved') and st.session_state.data_saved:
            if hasattr(st.session_state, 'saved_files'):
                st.info("â„¹ï¸ Data already saved, using existing files.")
                existing_timestamp = getattr(st.session_state, 'saved_timestamp', datetime.now().strftime("%Y%m%d_%H%M%S"))
                return st.session_state.saved_files + (existing_timestamp,)
        
        # í•„ìš”í•œ í´ë” ìƒì„±
        for folder in FOLDERS.values():
            os.makedirs(folder, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        session_data = build_session_data(timestamp)
        csv_filename = save_to_csv(session_data, timestamp)
        excel_filename = None  # Excel ê¸°ëŠ¥ ì œê±°ë¨
        audio_folder, saved_files = save_audio_files(timestamp)
        zip_filename = create_comprehensive_backup_zip(st.session_state.session_id, timestamp)
        
        return csv_filename, excel_filename, audio_folder, saved_files, zip_filename, timestamp
    
    except Exception as e:
        st.error(f"âŒ Error saving session data: {str(e)}")
        return None, None, None, [], None, None


def build_session_data(timestamp):
    """
    ì„¸ì…˜ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ êµ¬ì„±
    
    Args:
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        
    Returns:
        dict: ì™„ì„±ëœ ì„¸ì…˜ ë°ì´í„°
    """
    research_scores = getattr(st.session_state, 'research_scores', {})
    
    # ê¸°ë³¸ê°’ ì„¤ì •
    default_research_scores = {
        'accuracy_score': 0.0,
        'fluency_score': 0.0,
        'error_rate': 0.0,
        'word_count': 0,
        'duration_s': 0.0,
        'error_count': 0
    }
    
    for key, default_value in default_research_scores.items():
        if key not in research_scores:
            research_scores[key] = default_value

    return {
        'session_id': st.session_state.session_id,
        'session_number': getattr(st.session_state, 'session_number', CURRENT_SESSION),
        'session_label': getattr(st.session_state, 'session_label', SESSION_LABELS.get(CURRENT_SESSION, "Session 1")),
        'original_nickname': getattr(st.session_state, 'original_nickname', ''),
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        
        # ë°°ê²½ ì •ë³´
        'learning_duration': getattr(st.session_state, 'learning_duration', ''),
        'speaking_confidence': getattr(st.session_state, 'speaking_confidence', ''),
        
        # ê°•í™”ëœ ë™ì˜ ì¶”ì 
        'consent_given': getattr(st.session_state, 'consent_given', False),
        'consent_timestamp': getattr(st.session_state, 'consent_timestamp', ''),
        'consent_participation': getattr(st.session_state, 'consent_participation', False),
        'consent_audio_ai': getattr(st.session_state, 'consent_audio_ai', False),
        'consent_data_storage': getattr(st.session_state, 'consent_data_storage', False),
        'consent_privacy_rights': getattr(st.session_state, 'consent_privacy_rights', False),
        'consent_final_confirmation': getattr(st.session_state, 'consent_final_confirmation', False),
        'consent_zoom_interview': getattr(st.session_state, 'consent_zoom_interview', False),
        'gdpr_compliant': getattr(st.session_state, 'gdpr_compliant', False),
        'consent_pdf_generated': getattr(st.session_state, 'consent_pdf', '') != '',
        'consent_pdf_filename': getattr(st.session_state, 'consent_pdf', ''),
        
        # ì‹¤í—˜ ë°ì´í„°
        'question': EXPERIMENT_QUESTION,
        'transcription_1': st.session_state.transcription_1,
        'transcription_2': st.session_state.transcription_2,
        'gpt_feedback_json': json.dumps(st.session_state.feedback, ensure_ascii=False),
        
        # ì—°êµ¬ìš© ì ìˆ˜ í•„ë“œ
        'research_accuracy_score': research_scores.get('accuracy_score', 0.0),
        'research_fluency_score': research_scores.get('fluency_score', 0.0),
        'research_error_rate': research_scores.get('error_rate', 0.0),
        'research_word_count': research_scores.get('word_count', 0),
        'research_duration_s': research_scores.get('duration_s', 0.0),
        'research_error_count': research_scores.get('error_count', 0),
        'research_scores_json': json.dumps(research_scores, ensure_ascii=False),
        
        # ë°ì´í„° í’ˆì§ˆ ë¶„ì„ í•„ë“œ
        'audio_duration_1': getattr(st.session_state, 'audio_duration_1', 0.0),
        'audio_duration_2': getattr(st.session_state, 'audio_duration_2', 0.0),
        'audio_quality_check_1': get_audio_quality_label(getattr(st.session_state, 'audio_duration_1', 0)),
        'audio_quality_check_2': get_audio_quality_label(getattr(st.session_state, 'audio_duration_2', 0)),
        
        # ê°œì„ ë„ í‰ê°€ ë°ì´í„°
        'improvement_score': getattr(st.session_state, 'improvement_assessment', {}).get('improvement_score', 0),
        'improvement_reason': getattr(st.session_state, 'improvement_assessment', {}).get('improvement_reason', ''),
        'first_attempt_score': getattr(st.session_state, 'improvement_assessment', {}).get('first_attempt_score', 0),
        'second_attempt_score': getattr(st.session_state, 'improvement_assessment', {}).get('second_attempt_score', 0),
        'score_difference': getattr(st.session_state, 'improvement_assessment', {}).get('score_difference', 0),
        'feedback_application': getattr(st.session_state, 'improvement_assessment', {}).get('feedback_application', ''),
        'specific_improvements': json.dumps(getattr(st.session_state, 'improvement_assessment', {}).get('specific_improvements', []), ensure_ascii=False),
        'remaining_issues': json.dumps(getattr(st.session_state, 'improvement_assessment', {}).get('remaining_issues', []), ensure_ascii=False),
        'overall_assessment': getattr(st.session_state, 'improvement_assessment', {}).get('overall_assessment', ''),
        'improvement_assessment_json': json.dumps(getattr(st.session_state, 'improvement_assessment', {}), ensure_ascii=False),
        
        # í•™ìƒìš© í”¼ë“œë°± í•„ë“œë“¤
        'suggested_model_sentence': st.session_state.feedback.get('suggested_model_sentence', ''),
        'suggested_model_sentence_english': st.session_state.feedback.get('suggested_model_sentence_english', ''),
        'fluency_comment': st.session_state.feedback.get('fluency_comment', ''),
        'interview_readiness_score': st.session_state.feedback.get('interview_readiness_score', ''),
        'interview_readiness_reason': st.session_state.feedback.get('interview_readiness_reason', ''),
        'grammar_expression_tip': st.session_state.feedback.get('grammar_expression_tip', ''),
        
        # STT ë£¨ë¸Œë¦­ ê¸°ë°˜ í”¼ë“œë°± ë¶„ì„
        'grammar_issues_count': len(st.session_state.feedback.get('grammar_issues', [])),
        'vocabulary_suggestions_count': len(st.session_state.feedback.get('vocabulary_suggestions', [])),
        'content_expansion_suggestions_count': len(st.session_state.feedback.get('content_expansion_suggestions', [])),
        'content_expansion_suggestions_json': json.dumps(st.session_state.feedback.get('content_expansion_suggestions', []), ensure_ascii=False),
        'grammar_issues_json': json.dumps(st.session_state.feedback.get('grammar_issues', []), ensure_ascii=False),
        'vocabulary_suggestions_json': json.dumps(st.session_state.feedback.get('vocabulary_suggestions', []), ensure_ascii=False),
        'highlight_targets_json': json.dumps(st.session_state.feedback.get('highlight_targets', {}), ensure_ascii=False),
        
        # ë””ë²„ê·¸ ì •ë³´
        'gpt_model_used': st.session_state.gpt_debug_info.get('model_used', ''),
        'gpt_attempts': st.session_state.gpt_debug_info.get('attempts', 0),
        'dual_evaluation_used': st.session_state.gpt_debug_info.get('dual_evaluation', False),
        
        # ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´
        'audio_folder': f"{FOLDERS['audio_recordings']}/{getattr(st.session_state, 'session_number', CURRENT_SESSION)}_{st.session_state.session_id}_{timestamp}",
        
        # ë°ì´í„° ê´€ë¦¬ ì •ë³´
        'data_retention_until': (datetime.now() + timedelta(days=DATA_RETENTION_DAYS)).strftime('%Y-%m-%d'),
        'deletion_requested': False,
        'last_updated': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        
        # ì €ì¥ íƒ€ì´ë° ì •ë³´
        'saved_at_step': 'second_recording_complete',
        'save_trigger': 'auto_after_second_recording'
    }


def get_audio_quality_label(duration):
    """
    ìŒì„± ê¸¸ì´ì— ë”°ë¥¸ í’ˆì§ˆ ë¼ë²¨ ë°˜í™˜
    
    Args:
        duration: ìŒì„± ê¸¸ì´ (ì´ˆ)
        
    Returns:
        str: í’ˆì§ˆ ë¼ë²¨
    """
    if duration >= 60:
        return 'excellent'
    elif duration >= 45:
        return 'good'
    elif duration >= 30:
        return 'fair'
    else:
        return 'very_short'


def save_to_csv(session_data, timestamp):
    """
    ì„¸ì…˜ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥
    
    Args:
        session_data: ì„¸ì…˜ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        
    Returns:
        str: CSV íŒŒì¼ ê²½ë¡œ
    """
    session_num = getattr(st.session_state, 'session_number', CURRENT_SESSION)
    csv_filename = os.path.join(
        FOLDERS["data"], 
        f"korean_session{session_num}_{st.session_state.session_id}_{timestamp}.csv"
    )
    
    with open(csv_filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=session_data.keys())
        writer.writeheader()
        writer.writerow(session_data)
    
    return csv_filename


def save_audio_files(timestamp):
    """
    ìŒì„± íŒŒì¼ë“¤ì„ ì €ì¥
    
    Args:
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        
    Returns:
        tuple: (folder_path, saved_files_list)
    """
    try:
        session_num = getattr(st.session_state, 'session_number', CURRENT_SESSION)
        folder_name = os.path.join(
            FOLDERS["audio_recordings"], 
            f"session{session_num}_{st.session_state.session_id}_{timestamp}"
        )
        os.makedirs(folder_name, exist_ok=True)
        
        saved_files = []
        
        # ì²« ë²ˆì§¸ ë…¹ìŒ
        if hasattr(st.session_state, 'first_audio') and st.session_state.first_audio:
            file_path = os.path.join(folder_name, "first_audio.wav")
            with open(file_path, "wb") as f:
                f.write(st.session_state.first_audio["bytes"])
            saved_files.append("first_audio.wav")
        
        # ë‘ ë²ˆì§¸ ë…¹ìŒ
        if hasattr(st.session_state, 'second_audio') and st.session_state.second_audio:
            file_path = os.path.join(folder_name, "second_audio.wav")
            with open(file_path, "wb") as f:
                f.write(st.session_state.second_audio["bytes"])
            saved_files.append("second_audio.wav")
        
        # ëª¨ë¸ ìŒì„± (ì¼ë°˜ ì†ë„)
        if st.session_state.model_audio.get("normal"):
            file_path = os.path.join(folder_name, "model_normal.mp3")
            with open(file_path, "wb") as f:
                f.write(st.session_state.model_audio["normal"])
            saved_files.append("model_normal.mp3")
        
        # ëª¨ë¸ ìŒì„± (ëŠë¦° ì†ë„)
        if st.session_state.model_audio.get("slow"):
            file_path = os.path.join(folder_name, "model_slow.mp3")
            with open(file_path, "wb") as f:
                f.write(st.session_state.model_audio["slow"])
            saved_files.append("model_slow.mp3")
        
        return folder_name, saved_files
    
    except Exception as e:
        st.error(f"âŒ Error saving audio files: {str(e)}")
        return None, []


def create_participant_info_file(session_id, timestamp):
    """
    ì°¸ì—¬ì ì •ë³´ íŒŒì¼ ìƒì„±
    
    Args:
        session_id: ì„¸ì…˜ ID
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        
    Returns:
        str: ìƒì„±ëœ íŒŒì¼ ê²½ë¡œ
    """
    try:
        info_filename = os.path.join(FOLDERS["data"], f"{session_id}_participant_info.txt")
        
        original_nickname = getattr(st.session_state, 'original_nickname', 'Unknown')
        session_label = getattr(st.session_state, 'session_label', SESSION_LABELS.get(CURRENT_SESSION, "Session 1"))
        learning_duration = getattr(st.session_state, 'learning_duration', 'Not specified')
        speaking_confidence = getattr(st.session_state, 'speaking_confidence', 'Not specified')
        
        research_scores = getattr(st.session_state, 'research_scores', {})
        accuracy_score = research_scores.get('accuracy_score', 'N/A')
        fluency_score = research_scores.get('fluency_score', 'N/A')
        error_rate = research_scores.get('error_rate', 'N/A')
        word_count = research_scores.get('word_count', 'N/A')
        
        info_content = f"""=== PARTICIPANT INFORMATION ===
Anonymous ID: {session_id}
Original Nickname: {original_nickname}
Session: {session_label} (Session {CURRENT_SESSION})
Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Save Trigger: Auto-save after second recording completion

=== BACKGROUND INFORMATION ===
Learning Duration: {learning_duration}
Speaking Confidence: {speaking_confidence}

=== EXPERIMENT DETAILS ===
Question: {EXPERIMENT_QUESTION}
First Recording Duration: {getattr(st.session_state, 'audio_duration_1', 0):.1f} seconds
Second Recording Duration: {getattr(st.session_state, 'audio_duration_2', 0):.1f} seconds
Student UI Score: {st.session_state.feedback.get('interview_readiness_score', 'N/A')}/10

=== RESEARCH SCORES ===
Accuracy Score: {accuracy_score}/10 (Error rate: {error_rate}%)
Fluency Score: {fluency_score}/10 (Word count: {word_count})
Dual Evaluation System: {getattr(st.session_state, 'gpt_debug_info', {}).get('dual_evaluation', False)}

=== CONSENT INFORMATION ===
Consent Given: {getattr(st.session_state, 'consent_given', False)}
Consent Timestamp: {getattr(st.session_state, 'consent_timestamp', 'N/A')}
GDPR Compliant: {getattr(st.session_state, 'gdpr_compliant', False)}
Zoom Interview Consent: {getattr(st.session_state, 'consent_zoom_interview', False)}

=== DATA MANAGEMENT ===
Data Retention Until: {(datetime.now() + timedelta(days=DATA_RETENTION_DAYS)).strftime('%Y-%m-%d')}
Storage Method: GCS ZIP Archive (Auto-save after 2nd recording)
Last Updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

=== FOR RESEARCHER ===
This file contains the link between the anonymous ID and the original nickname.
Data was automatically saved after second recording completion.
Research scores are calculated using: Accuracy (error rate) + Fluency (word count).
Student UI scores are generated by GPT for educational purposes.
Contact: pen0226@gmail.com for any data requests or questions.
"""
        
        with open(info_filename, 'w', encoding='utf-8') as f:
            f.write(info_content)
        
        return info_filename
    
    except Exception as e:
        return None


def create_comprehensive_backup_zip(session_id, timestamp):
    """
    ëª¨ë“  ì„¸ì…˜ ë°ì´í„°ë¥¼ í¬í•¨í•œ ì™„ì „í•œ ë°±ì—… ZIP ìƒì„±
    
    Args:
        session_id: ì„¸ì…˜ ID
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        
    Returns:
        str: ZIP íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None
    """
    try:
        session_num = getattr(st.session_state, 'session_number', CURRENT_SESSION)
        zip_filename = os.path.join(
            FOLDERS["data"], 
            f"{session_id}_{timestamp}.zip"
        )
        
        with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:
            
            # ì°¸ì—¬ì ì •ë³´ íŒŒì¼ ìƒì„± ë° ì¶”ê°€
            participant_info_file = create_participant_info_file(session_id, timestamp)
            if participant_info_file and os.path.exists(participant_info_file):
                zipf.write(participant_info_file, "participant_info.txt")
            
            # CSV íŒŒì¼ ì¶”ê°€
            csv_file = os.path.join(FOLDERS["data"], f"korean_session{session_num}_{session_id}_{timestamp}.csv")
            if os.path.exists(csv_file):
                zipf.write(csv_file, f"session_data_{timestamp}.csv")
            
            # ë™ì˜ì„œ PDF ì¶”ê°€
            consent_pdf = os.path.join(FOLDERS["data"], f"{session_id}_consent.pdf")
            if os.path.exists(consent_pdf):
                zipf.write(consent_pdf, f"consent_form_{session_id}.pdf")
            
            # ìŒì„± íŒŒì¼ë“¤ ì¶”ê°€
            audio_folder = os.path.join(FOLDERS["audio_recordings"], f"session{session_num}_{session_id}_{timestamp}")
            if os.path.exists(audio_folder):
                for file in os.listdir(audio_folder):
                    file_path = os.path.join(audio_folder, file)
                    zipf.write(file_path, f"audio/{file}")
            
            # ZIP ë‚´ìš© ìš”ì•½ íŒŒì¼ ì¶”ê°€
            research_scores = getattr(st.session_state, 'research_scores', {})
            readme_content = f"""=== ZIP CONTENTS SUMMARY ===
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Participant: {session_id} (Session {session_num})
Save Trigger: Auto-save after second recording completion

Files included:
- participant_info.txt: Participant details and nickname mapping + Research scores
- session_data_{timestamp}.csv: Complete session data with dual evaluation scores
- consent_form_{session_id}.pdf: Signed consent form
- audio/: All recorded audio files (student + model pronunciations)

DUAL EVALUATION SYSTEM:
- Student UI Score: Educational feedback (GPT-generated)
- Research Scores: Objective metrics for academic analysis
  * Accuracy: {research_scores.get('accuracy_score', 'N/A')}/10 (based on error rate)
  * Fluency: {research_scores.get('fluency_score', 'N/A')}/10 (based on word count)

NOTE: Excel file generation has been removed for faster deployment.
The CSV file can be opened directly in Excel for analysis.

IMPORTANT: Data was automatically saved after second recording completion.
This ensures no data loss even if survey is not completed.

Contact researcher: pen0226@gmail.com
"""
            
            readme_path = os.path.join(FOLDERS["data"], f"{session_id}_readme.txt")
            with open(readme_path, 'w', encoding='utf-8') as f:
                f.write(readme_content)
            zipf.write(readme_path, "README.txt")
        
        # ì„ì‹œ íŒŒì¼ë“¤ ì •ë¦¬
        temp_files = [participant_info_file, readme_path]
        for temp_file in temp_files:
            if temp_file and os.path.exists(temp_file):
                try:
                    os.remove(temp_file)
                except:
                    pass
        
        return zip_filename
    except Exception as e:
        st.error(f"âŒ Error creating comprehensive backup ZIP: {e}")
        return None


def get_gcs_client():
    """
    GCS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    
    Returns:
        tuple: (client, bucket, status_message)
    """
    try:
        from google.cloud import storage
        import json
        
        if not GCS_ENABLED:
            return None, None, "GCS upload is disabled in configuration"
        
        if not GCS_SERVICE_ACCOUNT:
            return None, None, "GCS service account not configured"
        
        try:
            if isinstance(GCS_SERVICE_ACCOUNT, dict):
                credentials_dict = dict(GCS_SERVICE_ACCOUNT)
                print(f"Using TOML format service account (Project: {credentials_dict.get('project_id', 'Unknown')})")
            elif isinstance(GCS_SERVICE_ACCOUNT, str):
                credentials_dict = json.loads(GCS_SERVICE_ACCOUNT)
                print(f"Using JSON format service account (Project: {credentials_dict.get('project_id', 'Unknown')})")
            else:
                return None, None, f"Unexpected service account type: {type(GCS_SERVICE_ACCOUNT)}"
                
        except json.JSONDecodeError:
            return None, None, "Invalid JSON format in service account"
        except Exception as parse_error:
            return None, None, f"Service account parsing error: {str(parse_error)}"
        
        client = storage.Client.from_service_account_info(credentials_dict)
        bucket = client.bucket(GCS_BUCKET_NAME)
        
        return client, bucket, "Success"
        
    except ImportError as e:
        return None, None, f"Missing required libraries: {str(e)}. Run: pip install google-cloud-storage"
    except Exception as e:
        return None, None, f"GCS client initialization failed: {str(e)}"


def upload_to_gcs(local_path, blob_name):
    """
    GCSì— íŒŒì¼ ì—…ë¡œë“œ
    
    Args:
        local_path: ì—…ë¡œë“œí•  ë¡œì»¬ íŒŒì¼ ê²½ë¡œ
        blob_name: GCSì—ì„œ ì‚¬ìš©í•  íŒŒì¼ëª…
        
    Returns:
        tuple: (blob_url, status_message)
    """
    try:
        client, bucket, status = get_gcs_client()
        if not client:
            return None, f"GCS client error: {status}"
        
        if not os.path.exists(local_path):
            return None, f"File not found: {local_path}"
        
        blob = bucket.blob(blob_name)
        blob.upload_from_filename(local_path)
        
        blob_url = f"gs://{GCS_BUCKET_NAME}/{blob_name}"
        print(f"ZIP uploaded: {blob_name}")
        
        return blob_url, f"Successfully uploaded: {blob_name}"
        
    except Exception as e:
        return None, f"Upload failed: {str(e)}"


def auto_backup_to_gcs(csv_filename, excel_filename, zip_filename, session_id, timestamp):
    """
    ZIP íŒŒì¼ë§Œ GCSì— ìë™ ë°±ì—… + nickname_mapping.csv ë°±ì—…
    
    Args:
        csv_filename: CSV íŒŒì¼ ê²½ë¡œ
        excel_filename: Excel íŒŒì¼ ê²½ë¡œ (ì‚¬ìš© ì•ˆë¨)
        zip_filename: ZIP íŒŒì¼ ê²½ë¡œ
        session_id: ì„¸ì…˜ ID
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        
    Returns:
        tuple: (uploaded_files, errors)
    """
    uploaded_files = []
    errors = []
    
    if not GCS_ENABLED:
        errors.append("GCS upload is disabled in configuration")
        return uploaded_files, errors
    
    session_num = getattr(st.session_state, 'session_number', CURRENT_SESSION)
    session_folder = GCS_SIMPLE_STRUCTURE.get(session_num, GCS_SIMPLE_STRUCTURE[1])
    
    # ZIP íŒŒì¼ ì—…ë¡œë“œ
    if zip_filename and os.path.exists(zip_filename):
        try:
            blob_name = f"{session_folder}{session_id}_{timestamp}.zip"
            blob_url, result_msg = upload_to_gcs(zip_filename, blob_name)
            
            if blob_url:
                uploaded_files.append(blob_name)
            else:
                errors.append(f"ZIP upload failed: {result_msg}")
                
        except Exception as e:
            errors.append(f"ZIP upload error: {str(e)}")
    else:
        errors.append("ZIP file not found for upload")
    
    # nickname_mapping.csv ë°±ì—…
    mapping_file = os.path.join(FOLDERS["data"], 'nickname_mapping.csv')
    if os.path.exists(mapping_file):
        try:
            mapping_blob_name = "nickname_mapping.csv"
            blob_url, result_msg = upload_to_gcs(mapping_file, mapping_blob_name)
            
            if blob_url:
                uploaded_files.append(mapping_blob_name)
            else:
                errors.append(f"Mapping file upload failed: {result_msg}")
                
        except Exception as e:
            errors.append(f"Mapping file upload error: {str(e)}")
    
    return uploaded_files, errors


def test_gcs_connection():
    """
    GCS ì—°ê²° ìƒíƒœ í…ŒìŠ¤íŠ¸
    
    Returns:
        tuple: (success, message)
    """
    try:
        client, bucket, status = get_gcs_client()
        if not client:
            return False, f"GCS connection failed: {status}"
        
        if bucket.exists():
            project_id = "Unknown"
            if isinstance(GCS_SERVICE_ACCOUNT, dict):
                project_id = GCS_SERVICE_ACCOUNT.get('project_id', 'Unknown')
                format_type = "TOML format"
            else:
                import json
                try:
                    service_info = json.loads(GCS_SERVICE_ACCOUNT)
                    project_id = service_info.get('project_id', 'Unknown')
                    format_type = "JSON format"
                except:
                    format_type = "Unknown format"
            
            return True, f"Connected successfully to bucket: {GCS_BUCKET_NAME} (Project: {project_id} - {format_type})"
        else:
            return False, f"Bucket not found: {GCS_BUCKET_NAME}"
        
    except Exception as e:
        return False, f"Connection test failed: {str(e)}"


def log_upload_status(session_id, timestamp, uploaded_files, errors, email_sent=False):
    """
    GCS ì—…ë¡œë“œ ê²°ê³¼ë¥¼ ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡
    
    Args:
        session_id: ì„¸ì…˜ ID
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        uploaded_files: ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡
        errors: ì˜¤ë¥˜ ëª©ë¡
        email_sent: ì´ë©”ì¼ ì „ì†¡ ì—¬ë¶€
        
    Returns:
        bool: ë¡œê·¸ ê¸°ë¡ ì„±ê³µ ì—¬ë¶€
    """
    try:
        os.makedirs(FOLDERS["logs"], exist_ok=True)
        
        log_date = datetime.now().strftime('%Y%m%d')
        log_filename = os.path.join(
            FOLDERS["logs"], 
            f"upload_log_{log_date}.txt"
        )
        
        session_num = getattr(st.session_state, 'session_number', CURRENT_SESSION)
        session_label = getattr(st.session_state, 'session_label', SESSION_LABELS.get(CURRENT_SESSION, "Session 1"))
        original_nickname = getattr(st.session_state, 'original_nickname', 'Unknown')
        
        research_scores = getattr(st.session_state, 'research_scores', {})
        accuracy_score = research_scores.get('accuracy_score', 'N/A')
        fluency_score = research_scores.get('fluency_score', 'N/A')
        dual_eval_used = getattr(st.session_state, 'gpt_debug_info', {}).get('dual_evaluation', False)
        
        upload_status = "SUCCESS" if uploaded_files and not errors else "PARTIAL" if uploaded_files else "FAILED"
        
        log_entry = f"""
[{datetime.now().strftime(LOG_FORMAT['timestamp_format'])}] SESSION: {session_label} - {session_id}_{timestamp}
Nickname: {original_nickname}
Status: {upload_status}
Save Trigger: Auto-save after second recording completion
Dual Evaluation: {dual_eval_used} (Research scores: Accuracy={accuracy_score}, Fluency={fluency_score})
GCS Enabled: {GCS_ENABLED} (Service Account method - ZIP only)
Bucket: {GCS_BUCKET_NAME}
Files uploaded: {len(uploaded_files)} ({', '.join(uploaded_files) if uploaded_files else 'None'})
Errors: {len(errors)} ({'; '.join(errors) if errors else 'None'})
Email notification: {'Sent' if email_sent else 'Not sent/Failed'}
Data Safety: Secured before survey step
Excel conversion: Removed for faster deployment (CSV only)
Research Data: Objective scores calculated and stored
{'='*80}
"""
        
        with open(log_filename, 'a', encoding='utf-8') as log_file:
            log_file.write(log_entry)
        
        return True
    except Exception:
        return False


def display_download_buttons(csv_filename, excel_filename, zip_filename):
    """
    ì—°êµ¬ììš© ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ë“¤ í‘œì‹œ
    
    Args:
        csv_filename: CSV íŒŒì¼ ê²½ë¡œ
        excel_filename: Excel íŒŒì¼ ê²½ë¡œ (ì‚¬ìš© ì•ˆë¨)
        zip_filename: ZIP íŒŒì¼ ê²½ë¡œ
    """
    if GCS_ENABLED:
        st.info("ğŸ“¤ ZIP file should be automatically uploaded to Google Cloud Storage. Use these downloads as backup only.")
    else:
        st.warning("âš ï¸ GCS upload is disabled. Use these download buttons to save your data.")
    
    col1, col2 = st.columns(2)
    
    session_num = getattr(st.session_state, 'session_number', CURRENT_SESSION)
    timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    with col1:
        # ZIP ì™„ì „ ë°±ì—… ë‹¤ìš´ë¡œë“œ
        if zip_filename and os.path.exists(zip_filename):
            try:
                with open(zip_filename, 'rb') as f:
                    zip_data = f.read()
                st.download_button(
                    label="ğŸ“¦ Complete Backup ZIP",
                    data=zip_data,
                    file_name=f"{st.session_state.session_id}_{timestamp_str}.zip",
                    mime='application/zip',
                    use_container_width=True
                )
            except:
                st.info("ZIP unavailable")
        else:
            st.info("ZIP unavailable")
    
    with col2:
        # CSV ë‹¤ìš´ë¡œë“œ
        if csv_filename and os.path.exists(csv_filename):
            try:
                with open(csv_filename, 'r', encoding='utf-8') as f:
                    csv_data = f.read()
                st.download_button(
                    label="ğŸ“„ CSV Data (Open in Excel)",
                    data=csv_data,
                    file_name=f"session{session_num}_{st.session_state.session_id}_{timestamp_str}.csv",
                    mime='text/csv',
                    use_container_width=True
                )
            except:
                st.error("CSV download failed")
        else:
            st.info("CSV unavailable")
    
    st.caption("â„¹ï¸ Excel file generation has been removed for faster deployment. The CSV file can be opened directly in Excel.")


def display_session_details():
    """
    ì—°êµ¬ììš© ì„¸ì…˜ ìƒì„¸ ì •ë³´ í‘œì‹œ
    """
    st.markdown("**ğŸ“‹ Session Details:**")
    display_name = getattr(st.session_state, 'original_nickname', st.session_state.session_id)
    session_label = getattr(st.session_state, 'session_label', SESSION_LABELS.get(CURRENT_SESSION, "Session 1"))
    st.write(f"**Participant:** {display_name} (ID: {st.session_state.session_id})")
    st.write(f"**Session:** {session_label}")
    st.write(f"**Question:** {EXPERIMENT_QUESTION}")
    st.write(f"**Completed:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    st.write(f"**Data Saved:** After second recording completion")
    
    # ë°°ê²½ ì •ë³´ í‘œì‹œ
    learning_duration = getattr(st.session_state, 'learning_duration', '')
    speaking_confidence = getattr(st.session_state, 'speaking_confidence', '')
    if learning_duration:
        st.write(f"**Learning Duration:** {learning_duration}")
    if speaking_confidence:
        st.write(f"**Speaking Confidence:** {speaking_confidence}")
    
    # ì—°êµ¬ìš© ì ìˆ˜ ì •ë³´ í‘œì‹œ
    research_scores = getattr(st.session_state, 'research_scores', {})
    if research_scores:
        st.markdown("**ğŸ”¬ Research Scores:**")
        accuracy = research_scores.get('accuracy_score', 'N/A')
        fluency = research_scores.get('fluency_score', 'N/A')
        error_rate = research_scores.get('error_rate', 'N/A')
        word_count = research_scores.get('word_count', 'N/A')
        st.write(f"Accuracy Score: {accuracy}/10 (Error rate: {error_rate}%)")
        st.write(f"Fluency Score: {fluency}/10 (Word count: {word_count})")
        dual_eval = getattr(st.session_state, 'gpt_debug_info', {}).get('dual_evaluation', False)
        st.write(f"Dual Evaluation System: {'âœ… Active' if dual_eval else 'âŒ Not used'}")
    else:
        st.write("**ğŸ”¬ Research Scores:** âŒ Not calculated")
    
    # GCS ì—°ë™ ìƒíƒœ í‘œì‹œ
    st.markdown("**â˜ï¸ Google Cloud Storage Status:**")
    if GCS_ENABLED:
        st.success("âœ… GCS upload is enabled (Service Account method - ZIP only)")
        if GCS_BUCKET_NAME:
            st.write(f"Bucket: {GCS_BUCKET_NAME}")
            st.write(f"Storage method: ZIP archives + nickname mapping")
            st.write(f"Save timing: Auto-save after 2nd recording")
        else:
            st.warning("âš ï¸ No bucket specified")
        
        success, message = test_gcs_connection()
        if success:
            st.write("ğŸ”— Connection: âœ… Active")
        else:
            st.write(f"ğŸ”— Connection: âŒ {message}")
    else:
        st.warning("âŒ GCS upload is disabled")


def display_data_quality_info():
    """
    ë°ì´í„° í’ˆì§ˆ ì •ë³´ í‘œì‹œ
    """
    st.markdown("**ğŸ“Š Data Quality:**")
    col1, col2 = st.columns(2)
    
    with col1:
        duration1 = getattr(st.session_state, 'audio_duration_1', 0)
        if duration1 > 0:
            quality1 = get_quality_description(duration1)
            st.write(f"First recording: {duration1:.1f}s")
            st.caption(quality1)
        
        if st.session_state.feedback:
            issues_count = len(st.session_state.feedback.get('grammar_issues', []))
            vocab_count = len(st.session_state.feedback.get('vocabulary_suggestions', []))
            content_count = len(st.session_state.feedback.get('content_expansion_suggestions', []))
            st.write(f"Grammar issues: {issues_count}")
            st.write(f"Vocab suggestions: {vocab_count}")
            st.write(f"Content ideas: {content_count}")
            
            student_score = st.session_state.feedback.get('interview_readiness_score', 'N/A')
            st.write(f"Student UI Score: {student_score}/10")
        
        research_scores = getattr(st.session_state, 'research_scores', {})
        if research_scores:
            st.write("**ğŸ”¬ Research Scores:**")
            st.write(f"Accuracy: {research_scores.get('accuracy_score', 'N/A')}/10")
            st.write(f"Fluency: {research_scores.get('fluency_score', 'N/A')}/10")
    
    with col2:
        duration2 = getattr(st.session_state, 'audio_duration_2', 0)
        if duration2 > 0:
            quality2 = get_quality_description(duration2)
            st.write(f"Second recording: {duration2:.1f}s")
            st.caption(quality2)
        
        if hasattr(st.session_state, 'improvement_assessment'):
            improvement = st.session_state.improvement_assessment
            score = improvement.get('improvement_score', 0)
            first_score = improvement.get('first_attempt_score', 0)
            second_score = improvement.get('second_attempt_score', 0)
            st.write(f"Improvement score: {score}/10")
            st.write(f"Progress: {first_score} â†’ {second_score}")
            improvements = len(improvement.get('specific_improvements', []))
            issues = len(improvement.get('remaining_issues', []))
            st.write(f"Improvements: {improvements}")
            st.write(f"Remaining issues: {issues}")
        
        if hasattr(st.session_state, 'data_saved') and st.session_state.data_saved:
            st.write("ğŸ’¾ **Data Status:** âœ… Safely saved")
        else:
            st.write("ğŸ’¾ **Data Status:** âš ï¸ Not yet saved")


def get_quality_description(duration):
    """
    ìŒì„± ê¸¸ì´ì— ë”°ë¥¸ í’ˆì§ˆ ì„¤ëª… ë°˜í™˜
    
    Args:
        duration: ìŒì„± ê¸¸ì´ (ì´ˆ)
        
    Returns:
        str: í’ˆì§ˆ ì„¤ëª…
    """
    if duration >= 60:
        return "âœ… Excellent (60s+ target reached!)"
    elif duration >= 45:
        return "ğŸŒŸ Good (45-60s, try for 60+)"
    elif duration >= 30:
        return "âš ï¸ Fair (30-45s, needs improvement)"
    else:
        return "âŒ Very Short (under 30s, much more needed)"