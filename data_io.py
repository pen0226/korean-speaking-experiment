"""
data_io.py
ì‹¤í—˜ ë°ì´í„° ì €ì¥, ë°±ì—…, ì—…ë¡œë“œ ë° ë¡œê·¸ ê´€ë¦¬ ëª¨ë“ˆ (Excel ë³€í™˜ ì œê±° - ê°„ì†Œí™” ë²„ì „)
"""

import os
import csv
import json
import zipfile
from datetime import datetime, timedelta
import streamlit as st
from config import (
    FOLDERS, 
    DATA_RETENTION_DAYS, 
    EXPERIMENT_QUESTION,
    GCS_ENABLED,
    GCS_BUCKET_NAME,
    GCS_SERVICE_ACCOUNT,
    GCS_SIMPLE_STRUCTURE,
    LOG_FORMAT,
    CURRENT_SESSION,
    SESSION_LABELS
)


def save_session_data():
    """
    ì„¸ì…˜ ë°ì´í„°ë¥¼ CSV í˜•ì‹ìœ¼ë¡œ ì €ì¥ (Excel ë³€í™˜ ì œê±°)
    
    Returns:
        tuple: (csv_filename, excel_filename, audio_folder, saved_files, zip_filename, timestamp)
    """
    try:
        # ğŸ¯ ì¤‘ë³µ ì €ì¥ ë°©ì§€ ë¡œì§
        if hasattr(st.session_state, 'data_saved') and st.session_state.data_saved:
            if hasattr(st.session_state, 'saved_files'):
                st.info("â„¹ï¸ Data already saved, using existing files.")
                # ê¸°ì¡´ timestampë„ í•¨ê»˜ ë°˜í™˜
                existing_timestamp = getattr(st.session_state, 'saved_timestamp', datetime.now().strftime("%Y%m%d_%H%M%S"))
                return st.session_state.saved_files + (existing_timestamp,)
        
        # í•„ìš”í•œ í´ë” ìƒì„±
        for folder in FOLDERS.values():
            os.makedirs(folder, exist_ok=True)
        
        # ê³ ìœ í•œ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ì„¸ì…˜ ë°ì´í„° êµ¬ì„±
        session_data = build_session_data(timestamp)
        
        # CSV íŒŒì¼ ì €ì¥
        csv_filename = save_to_csv(session_data, timestamp)
        
        # Excel ë³€í™˜ ì œê±° - None ë°˜í™˜
        excel_filename = None
        
        # ìŒì„± íŒŒì¼ë“¤ ì €ì¥
        audio_folder, saved_files = save_audio_files(timestamp)
        
        # ë°±ì—… ZIP ìƒì„± (participant_info.txt í¬í•¨)
        zip_filename = create_comprehensive_backup_zip(st.session_state.session_id, timestamp)
        
        return csv_filename, excel_filename, audio_folder, saved_files, zip_filename, timestamp
    
    except Exception as e:
        st.error(f"âŒ Error saving session data: {str(e)}")
        return None, None, None, [], None, None


def build_session_data(timestamp):
    """
    ì„¸ì…˜ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ êµ¬ì„± (ë°°ê²½ ì •ë³´ í¬í•¨)
    
    Args:
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        
    Returns:
        dict: ì™„ì„±ëœ ì„¸ì…˜ ë°ì´í„°
    """
    return {
        'session_id': st.session_state.session_id,
        'session_number': getattr(st.session_state, 'session_number', CURRENT_SESSION),
        'session_label': getattr(st.session_state, 'session_label', SESSION_LABELS.get(CURRENT_SESSION, "Session 1")),
        'original_nickname': getattr(st.session_state, 'original_nickname', ''),  # ë‹‰ë„¤ì„ ì¶”ê°€
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        
        # === ë°°ê²½ ì •ë³´ ===
        'learning_duration': getattr(st.session_state, 'learning_duration', ''),
        'speaking_confidence': getattr(st.session_state, 'speaking_confidence', ''),
        
        # === ê°•í™”ëœ ë™ì˜ ì¶”ì  ===
        'consent_given': getattr(st.session_state, 'consent_given', False),
        'consent_timestamp': getattr(st.session_state, 'consent_timestamp', ''),
        'consent_participation': getattr(st.session_state, 'consent_participation', False),
        'consent_audio_ai': getattr(st.session_state, 'consent_audio_ai', False),
        'consent_data_storage': getattr(st.session_state, 'consent_data_storage', False),
        'consent_privacy_rights': getattr(st.session_state, 'consent_privacy_rights', False),
        'consent_final_confirmation': getattr(st.session_state, 'consent_final_confirmation', False),
        'consent_zoom_interview': getattr(st.session_state, 'consent_zoom_interview', False),
        'gdpr_compliant': getattr(st.session_state, 'gdpr_compliant', False),
        'consent_pdf_generated': getattr(st.session_state, 'consent_pdf', '') != '',
        'consent_pdf_filename': getattr(st.session_state, 'consent_pdf', ''),
        
        # === ì‹¤í—˜ ë°ì´í„° ===
        'question': EXPERIMENT_QUESTION,
        'transcription_1': st.session_state.transcription_1,
        'transcription_2': st.session_state.transcription_2,
        'gpt_feedback_json': json.dumps(st.session_state.feedback, ensure_ascii=False),
        
        # === ë°ì´í„° í’ˆì§ˆ ë¶„ì„ í•„ë“œ ===
        'audio_duration_1': getattr(st.session_state, 'audio_duration_1', 0.0),
        'audio_duration_2': getattr(st.session_state, 'audio_duration_2', 0.0),
        'audio_quality_check_1': get_audio_quality_label(getattr(st.session_state, 'audio_duration_1', 0)),
        'audio_quality_check_2': get_audio_quality_label(getattr(st.session_state, 'audio_duration_2', 0)),
        
        # === ê°œì„ ë„ í‰ê°€ ë°ì´í„° (STT ë£¨ë¸Œë¦­ ê¸°ë°˜) ===
        'improvement_score': getattr(st.session_state, 'improvement_assessment', {}).get('improvement_score', 0),
        'improvement_reason': getattr(st.session_state, 'improvement_assessment', {}).get('improvement_reason', ''),
        'first_attempt_score': getattr(st.session_state, 'improvement_assessment', {}).get('first_attempt_score', 0),
        'second_attempt_score': getattr(st.session_state, 'improvement_assessment', {}).get('second_attempt_score', 0),
        'score_difference': getattr(st.session_state, 'improvement_assessment', {}).get('score_difference', 0),
        'feedback_application': getattr(st.session_state, 'improvement_assessment', {}).get('feedback_application', ''),
        'specific_improvements': json.dumps(getattr(st.session_state, 'improvement_assessment', {}).get('specific_improvements', []), ensure_ascii=False),
        'remaining_issues': json.dumps(getattr(st.session_state, 'improvement_assessment', {}).get('remaining_issues', []), ensure_ascii=False),
        'overall_assessment': getattr(st.session_state, 'improvement_assessment', {}).get('overall_assessment', ''),
        'improvement_assessment_json': json.dumps(getattr(st.session_state, 'improvement_assessment', {}), ensure_ascii=False),
        
        # === ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” í”¼ë“œë°± í•„ë“œë“¤ë§Œ ===
        'suggested_model_sentence': st.session_state.feedback.get('suggested_model_sentence', ''),
        'suggested_model_sentence_english': st.session_state.feedback.get('suggested_model_sentence_english', ''),
        'fluency_comment': st.session_state.feedback.get('fluency_comment', ''),
        'interview_readiness_score': st.session_state.feedback.get('interview_readiness_score', ''),
        'interview_readiness_reason': st.session_state.feedback.get('interview_readiness_reason', ''),
        'grammar_expression_tip': st.session_state.feedback.get('grammar_expression_tip', ''),
        
        # === STT ë£¨ë¸Œë¦­ ê¸°ë°˜ í”¼ë“œë°± ë¶„ì„ ===
        'grammar_issues_count': len(st.session_state.feedback.get('grammar_issues', [])),
        'vocabulary_suggestions_count': len(st.session_state.feedback.get('vocabulary_suggestions', [])),
        'content_expansion_suggestions_count': len(st.session_state.feedback.get('content_expansion_suggestions', [])),
        'content_expansion_suggestions_json': json.dumps(st.session_state.feedback.get('content_expansion_suggestions', []), ensure_ascii=False),
        'grammar_issues_json': json.dumps(st.session_state.feedback.get('grammar_issues', []), ensure_ascii=False),
        'vocabulary_suggestions_json': json.dumps(st.session_state.feedback.get('vocabulary_suggestions', []), ensure_ascii=False),
        'highlight_targets_json': json.dumps(st.session_state.feedback.get('highlight_targets', {}), ensure_ascii=False),
        
        # ë””ë²„ê·¸ ì •ë³´
        'gpt_model_used': st.session_state.gpt_debug_info.get('model_used', ''),
        'gpt_attempts': st.session_state.gpt_debug_info.get('attempts', 0),
        
        # ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´ (ì„¸ì…˜ ë²ˆí˜¸ í¬í•¨)
        'audio_folder': f"{FOLDERS['audio_recordings']}/{getattr(st.session_state, 'session_number', CURRENT_SESSION)}_{st.session_state.session_id}_{timestamp}",
        
        # === ë°ì´í„° ê´€ë¦¬ ì •ë³´ ===
        'data_retention_until': (datetime.now() + timedelta(days=DATA_RETENTION_DAYS)).strftime('%Y-%m-%d'),
        'deletion_requested': False,
        'last_updated': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        
        # === ì €ì¥ íƒ€ì´ë° ì •ë³´ ì¶”ê°€ ===
        'saved_at_step': 'second_recording_complete',  # ì–¸ì œ ì €ì¥ë˜ì—ˆëŠ”ì§€ ê¸°ë¡
        'save_trigger': 'auto_after_second_recording'  # ì €ì¥ íŠ¸ë¦¬ê±° ê¸°ë¡
    }


def get_audio_quality_label(duration):
    """
    ìŒì„± ê¸¸ì´ì— ë”°ë¥¸ í’ˆì§ˆ ë¼ë²¨ ë°˜í™˜ (60ì´ˆ ëª©í‘œ)
    
    Args:
        duration: ìŒì„± ê¸¸ì´ (ì´ˆ)
        
    Returns:
        str: í’ˆì§ˆ ë¼ë²¨
    """
    if duration >= 60:
        return 'excellent'
    elif duration >= 45:
        return 'good'
    elif duration >= 30:
        return 'fair'
    else:
        return 'very_short'


def save_to_csv(session_data, timestamp):
    """
    ì„¸ì…˜ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥
    
    Args:
        session_data: ì„¸ì…˜ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        
    Returns:
        str: CSV íŒŒì¼ ê²½ë¡œ
    """
    # ì„¸ì…˜ ë²ˆí˜¸ë¥¼ íŒŒì¼ëª…ì— í¬í•¨
    session_num = getattr(st.session_state, 'session_number', CURRENT_SESSION)
    csv_filename = os.path.join(
        FOLDERS["data"], 
        f"korean_session{session_num}_{st.session_state.session_id}_{timestamp}.csv"
    )
    
    with open(csv_filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=session_data.keys())
        writer.writeheader()
        writer.writerow(session_data)
    
    return csv_filename


def convert_csv_to_excel(csv_filename):
    """
    CSVë¥¼ Excelë¡œ ë³€í™˜ - ê¸°ëŠ¥ ì œê±° (ìš©ëŸ‰ ì ˆì•½)
    
    Args:
        csv_filename: CSV íŒŒì¼ ê²½ë¡œ
        
    Returns:
        None: Excel ë³€í™˜ ê¸°ëŠ¥ ì œê±°ë¨
    """
    # Excel ë³€í™˜ ê¸°ëŠ¥ ì œê±° - pandas/openpyxl ì˜ì¡´ì„± ì œê±°
    # ì—°êµ¬ìëŠ” CSV íŒŒì¼ì„ Excelì—ì„œ ì§ì ‘ ì—´ì–´ì„œ ì‚¬ìš©
    return None


def save_audio_files(timestamp):
    """
    ìŒì„± íŒŒì¼ë“¤ì„ ì €ì¥
    
    Args:
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        
    Returns:
        tuple: (folder_path, saved_files_list)
    """
    try:
        # ì˜¤ë””ì˜¤ í´ë” ìƒì„± (ì„¸ì…˜ ë²ˆí˜¸ í¬í•¨)
        session_num = getattr(st.session_state, 'session_number', CURRENT_SESSION)
        folder_name = os.path.join(
            FOLDERS["audio_recordings"], 
            f"session{session_num}_{st.session_state.session_id}_{timestamp}"
        )
        os.makedirs(folder_name, exist_ok=True)
        
        saved_files = []
        
        # ì²« ë²ˆì§¸ ë…¹ìŒ
        if hasattr(st.session_state, 'first_audio') and st.session_state.first_audio:
            file_path = os.path.join(folder_name, "first_audio.wav")
            with open(file_path, "wb") as f:
                f.write(st.session_state.first_audio["bytes"])
            saved_files.append("first_audio.wav")
        
        # ë‘ ë²ˆì§¸ ë…¹ìŒ
        if hasattr(st.session_state, 'second_audio') and st.session_state.second_audio:
            file_path = os.path.join(folder_name, "second_audio.wav")
            with open(file_path, "wb") as f:
                f.write(st.session_state.second_audio["bytes"])
            saved_files.append("second_audio.wav")
        
        # ëª¨ë¸ ìŒì„± (ì¼ë°˜ ì†ë„)
        if st.session_state.model_audio.get("normal"):
            file_path = os.path.join(folder_name, "model_normal.mp3")
            with open(file_path, "wb") as f:
                f.write(st.session_state.model_audio["normal"])
            saved_files.append("model_normal.mp3")
        
        # ëª¨ë¸ ìŒì„± (ëŠë¦° ì†ë„)
        if st.session_state.model_audio.get("slow"):
            file_path = os.path.join(folder_name, "model_slow.mp3")
            with open(file_path, "wb") as f:
                f.write(st.session_state.model_audio["slow"])
            saved_files.append("model_slow.mp3")
        
        return folder_name, saved_files
    
    except Exception as e:
        st.error(f"âŒ Error saving audio files: {str(e)}")
        return None, []


def create_participant_info_file(session_id, timestamp):
    """
    ì°¸ì—¬ì ì •ë³´ íŒŒì¼ ìƒì„± (ZIPì— í¬í•¨ë  í…ìŠ¤íŠ¸ íŒŒì¼)
    
    Args:
        session_id: ì„¸ì…˜ ID
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        
    Returns:
        str: ìƒì„±ëœ íŒŒì¼ ê²½ë¡œ
    """
    try:
        info_filename = os.path.join(FOLDERS["data"], f"{session_id}_participant_info.txt")
        
        # ì°¸ì—¬ì ì •ë³´ ìˆ˜ì§‘
        original_nickname = getattr(st.session_state, 'original_nickname', 'Unknown')
        session_label = getattr(st.session_state, 'session_label', SESSION_LABELS.get(CURRENT_SESSION, "Session 1"))
        learning_duration = getattr(st.session_state, 'learning_duration', 'Not specified')
        speaking_confidence = getattr(st.session_state, 'speaking_confidence', 'Not specified')
        
        # ì •ë³´ íŒŒì¼ ë‚´ìš© ìƒì„±
        info_content = f"""=== PARTICIPANT INFORMATION ===
Anonymous ID: {session_id}
Original Nickname: {original_nickname}
Session: {session_label} (Session {CURRENT_SESSION})
Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Save Trigger: Auto-save after second recording completion

=== BACKGROUND INFORMATION ===
Learning Duration: {learning_duration}
Speaking Confidence: {speaking_confidence}

=== EXPERIMENT DETAILS ===
Question: {EXPERIMENT_QUESTION}
First Recording Duration: {getattr(st.session_state, 'audio_duration_1', 0):.1f} seconds
Second Recording Duration: {getattr(st.session_state, 'audio_duration_2', 0):.1f} seconds
Interview Readiness Score: {st.session_state.feedback.get('interview_readiness_score', 'N/A')}/10

=== CONSENT INFORMATION ===
Consent Given: {getattr(st.session_state, 'consent_given', False)}
Consent Timestamp: {getattr(st.session_state, 'consent_timestamp', 'N/A')}
GDPR Compliant: {getattr(st.session_state, 'gdpr_compliant', False)}
Zoom Interview Consent: {getattr(st.session_state, 'consent_zoom_interview', False)}

=== DATA MANAGEMENT ===
Data Retention Until: {(datetime.now() + timedelta(days=DATA_RETENTION_DAYS)).strftime('%Y-%m-%d')}
Storage Method: GCS ZIP Archive (Auto-save after 2nd recording)
Last Updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

=== FOR RESEARCHER ===
This file contains the link between the anonymous ID and the original nickname.
Data was automatically saved after second recording completion.
Contact: pen0226@gmail.com for any data requests or questions.
"""
        
        # íŒŒì¼ ì €ì¥
        with open(info_filename, 'w', encoding='utf-8') as f:
            f.write(info_content)
        
        return info_filename
    
    except Exception as e:
        print(f"Error creating participant info file: {e}")
        return None


def create_comprehensive_backup_zip(session_id, timestamp):
    """
    ëª¨ë“  ì„¸ì…˜ ë°ì´í„°ë¥¼ í¬í•¨í•œ ì™„ì „í•œ ë°±ì—… ZIP ìƒì„± (Excel íŒŒì¼ ì œì™¸)
    
    Args:
        session_id: ì„¸ì…˜ ID
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        
    Returns:
        str: ZIP íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None
    """
    try:
        # ì„¸ì…˜ ë²ˆí˜¸ë¥¼ ZIP íŒŒì¼ëª…ì— í¬í•¨
        session_num = getattr(st.session_state, 'session_number', CURRENT_SESSION)
        zip_filename = os.path.join(
            FOLDERS["data"], 
            f"{session_id}_{timestamp}.zip"
        )
        
        with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:
            
            # ğŸ¯ ì°¸ì—¬ì ì •ë³´ íŒŒì¼ ìƒì„± ë° ì¶”ê°€
            participant_info_file = create_participant_info_file(session_id, timestamp)
            if participant_info_file and os.path.exists(participant_info_file):
                zipf.write(participant_info_file, "participant_info.txt")
            
            # CSV íŒŒì¼ ì¶”ê°€
            csv_file = os.path.join(FOLDERS["data"], f"korean_session{session_num}_{session_id}_{timestamp}.csv")
            if os.path.exists(csv_file):
                zipf.write(csv_file, f"session_data_{timestamp}.csv")
            
            # Excel íŒŒì¼ ì¶”ê°€ ì œê±° (ê¸°ëŠ¥ ì œê±°ë¨)
            # excel_file = csv_file.replace('.csv', '.xlsx')
            # if os.path.exists(excel_file):
            #     zipf.write(excel_file, f"session_data_{timestamp}.xlsx")
            
            # ë™ì˜ì„œ PDF ì¶”ê°€
            consent_pdf = os.path.join(FOLDERS["data"], f"{session_id}_consent.pdf")
            if os.path.exists(consent_pdf):
                zipf.write(consent_pdf, f"consent_form_{session_id}.pdf")
            
            # ìŒì„± íŒŒì¼ë“¤ ì¶”ê°€
            audio_folder = os.path.join(FOLDERS["audio_recordings"], f"session{session_num}_{session_id}_{timestamp}")
            if os.path.exists(audio_folder):
                for file in os.listdir(audio_folder):
                    file_path = os.path.join(audio_folder, file)
                    zipf.write(file_path, f"audio/{file}")
            
            # ğŸ“ ZIP ë‚´ìš© ìš”ì•½ íŒŒì¼ ì¶”ê°€ (Excel ì œê±° ë°˜ì˜)
            readme_content = f"""=== ZIP CONTENTS SUMMARY ===
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Participant: {session_id} (Session {session_num})
Save Trigger: Auto-save after second recording completion

Files included:
- participant_info.txt: Participant details and nickname mapping
- session_data_{timestamp}.csv: Complete session data in CSV format
- consent_form_{session_id}.pdf: Signed consent form
- audio/: All recorded audio files (student + model pronunciations)

NOTE: Excel file generation has been removed for faster deployment.
The CSV file can be opened directly in Excel for analysis.

IMPORTANT: Data was automatically saved after second recording completion.
This ensures no data loss even if survey is not completed.

Contact researcher: pen0226@gmail.com
"""
            
            readme_path = os.path.join(FOLDERS["data"], f"{session_id}_readme.txt")
            with open(readme_path, 'w', encoding='utf-8') as f:
                f.write(readme_content)
            zipf.write(readme_path, "README.txt")
        
        # ì„ì‹œ íŒŒì¼ë“¤ ì •ë¦¬
        temp_files = [participant_info_file, readme_path]
        for temp_file in temp_files:
            if temp_file and os.path.exists(temp_file):
                try:
                    os.remove(temp_file)
                except:
                    pass
        
        return zip_filename
    except Exception as e:
        st.error(f"âŒ Error creating comprehensive backup ZIP: {e}")
        return None


# === Google Cloud Storage í•¨ìˆ˜ë“¤ (ZIP ì „ìš©) ===

def get_gcs_client():
    """
    GCS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    
    Returns:
        tuple: (client, bucket, status_message)
    """
    try:
        from google.cloud import storage
        import json
        
        if not GCS_ENABLED:
            return None, None, "GCS upload is disabled in configuration"
        
        if not GCS_SERVICE_ACCOUNT:
            return None, None, "GCS service account not configured"
        
        # ì„œë¹„ìŠ¤ ê³„ì • ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        if isinstance(GCS_SERVICE_ACCOUNT, dict):
            credentials_dict = dict(GCS_SERVICE_ACCOUNT)
        else:
            credentials_dict = json.loads(GCS_SERVICE_ACCOUNT)
        
        # GCS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        client = storage.Client.from_service_account_info(credentials_dict)
        
        # ë²„í‚· ê°ì²´ ìƒì„±
        bucket = client.bucket(GCS_BUCKET_NAME)
        
        return client, bucket, "Success"
        
    except ImportError as e:
        return None, None, f"Missing required libraries: {str(e)}. Run: pip install google-cloud-storage"
    except Exception as e:
        return None, None, f"GCS client initialization failed: {str(e)}"


def upload_to_gcs(local_path, blob_name):
    """
    GCSì— íŒŒì¼ ì—…ë¡œë“œ
    
    Args:
        local_path: ì—…ë¡œë“œí•  ë¡œì»¬ íŒŒì¼ ê²½ë¡œ
        blob_name: GCSì—ì„œ ì‚¬ìš©í•  íŒŒì¼ëª… (ê²½ë¡œ í¬í•¨)
        
    Returns:
        tuple: (blob_url, status_message)
    """
    try:
        client, bucket, status = get_gcs_client()
        if not client:
            return None, f"GCS client error: {status}"
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(local_path):
            return None, f"File not found: {local_path}"
        
        # ë¸”ë¡­ ìƒì„± ë° ì—…ë¡œë“œ
        blob = bucket.blob(blob_name)
        blob.upload_from_filename(local_path)
        
        # ê³µê°œ URL ìƒì„± (í•„ìš”í•œ ê²½ìš°)
        blob_url = f"gs://{GCS_BUCKET_NAME}/{blob_name}"
        
        return blob_url, f"Successfully uploaded: {blob_name}"
        
    except Exception as e:
        return None, f"Upload failed: {str(e)}"


def auto_backup_to_gcs(csv_filename, excel_filename, zip_filename, session_id, timestamp):
    """
    ZIP íŒŒì¼ë§Œ GCSì— ìë™ ë°±ì—… + nickname_mapping.csv ë°±ì—…
    
    Args:
        csv_filename: CSV íŒŒì¼ ê²½ë¡œ
        excel_filename: Excel íŒŒì¼ ê²½ë¡œ (None - ê¸°ëŠ¥ ì œê±°ë¨)
        zip_filename: ZIP íŒŒì¼ ê²½ë¡œ (ë©”ì¸ ì—…ë¡œë“œ)
        session_id: ì„¸ì…˜ ID
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        
    Returns:
        tuple: (uploaded_files, errors)
    """
    uploaded_files = []
    errors = []
    
    if not GCS_ENABLED:
        errors.append("GCS upload is disabled in configuration")
        return uploaded_files, errors
    
    # ì„¸ì…˜ ë²ˆí˜¸ì™€ ê°„ë‹¨í•œ í´ë” êµ¬ì¡° ì„¤ì •
    session_num = getattr(st.session_state, 'session_number', CURRENT_SESSION)
    session_folder = GCS_SIMPLE_STRUCTURE.get(session_num, GCS_SIMPLE_STRUCTURE[1])
    
    # ğŸ¯ ZIP íŒŒì¼ë§Œ ì—…ë¡œë“œ
    if zip_filename and os.path.exists(zip_filename):
        try:
            # ê°„ë‹¨í•œ ë¸”ë¡­ ì´ë¦„: session1/Student01_20250117_123456.zip
            blob_name = f"{session_folder}{session_id}_{timestamp}.zip"
            
            blob_url, result_msg = upload_to_gcs(zip_filename, blob_name)
            
            if blob_url:
                uploaded_files.append(blob_name)
                print(f"âœ… ZIP uploaded: {blob_name}")
            else:
                errors.append(f"ZIP upload failed: {result_msg}")
                
        except Exception as e:
            errors.append(f"ZIP upload error: {str(e)}")
    else:
        errors.append("ZIP file not found for upload")
    
    # ğŸ¯ nickname_mapping.csv GCS ë°±ì—… (ì „ì²´ ë§¤í•‘ í…Œì´ë¸”)
    mapping_file = os.path.join(FOLDERS["data"], 'nickname_mapping.csv')
    if os.path.exists(mapping_file):
        try:
            # ìµœìƒìœ„ ë ˆë²¨ì— ë§¤í•‘ íŒŒì¼ ì €ì¥
            mapping_blob_name = "nickname_mapping.csv"
            
            blob_url, result_msg = upload_to_gcs(mapping_file, mapping_blob_name)
            
            if blob_url:
                uploaded_files.append(mapping_blob_name)
                print(f"âœ… Mapping file updated: {mapping_blob_name}")
            else:
                errors.append(f"Mapping file upload failed: {result_msg}")
                
        except Exception as e:
            errors.append(f"Mapping file upload error: {str(e)}")
    
    return uploaded_files, errors


def test_gcs_connection():
    """
    GCS ì—°ê²° í…ŒìŠ¤íŠ¸
    
    Returns:
        tuple: (success, message)
    """
    try:
        client, bucket, status = get_gcs_client()
        if not client:
            return False, f"GCS connection failed: {status}"
        
        # ë²„í‚· ì¡´ì¬ í™•ì¸
        if bucket.exists():
            return True, f"âœ… Connected successfully to bucket: {GCS_BUCKET_NAME}"
        else:
            return False, f"âŒ Bucket not found: {GCS_BUCKET_NAME}"
        
    except Exception as e:
        return False, f"Connection test failed: {str(e)}"


def log_upload_status(session_id, timestamp, uploaded_files, errors, email_sent=False):
    """
    GCS ì—…ë¡œë“œ ê²°ê³¼ë¥¼ ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡
    
    Args:
        session_id: ì„¸ì…˜ ID
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        uploaded_files: ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡
        errors: ì˜¤ë¥˜ ëª©ë¡
        email_sent: ì´ë©”ì¼ ì „ì†¡ ì—¬ë¶€
        
    Returns:
        bool: ë¡œê·¸ ê¸°ë¡ ì„±ê³µ ì—¬ë¶€
    """
    try:
        # ë¡œê·¸ í´ë” ìƒì„±
        os.makedirs(FOLDERS["logs"], exist_ok=True)
        
        # ì¼ë³„ ë¡œê·¸ íŒŒì¼
        log_date = datetime.now().strftime('%Y%m%d')
        log_filename = os.path.join(
            FOLDERS["logs"], 
            f"upload_log_{log_date}.txt"
        )
        
        # ì„¸ì…˜ ì •ë³´ í¬í•¨
        session_num = getattr(st.session_state, 'session_number', CURRENT_SESSION)
        session_label = getattr(st.session_state, 'session_label', SESSION_LABELS.get(CURRENT_SESSION, "Session 1"))
        original_nickname = getattr(st.session_state, 'original_nickname', 'Unknown')
        
        # ì—…ë¡œë“œ ìƒíƒœ ê²°ì •
        upload_status = "SUCCESS" if uploaded_files and not errors else "PARTIAL" if uploaded_files else "FAILED"
        
        # ë¡œê·¸ ì—”íŠ¸ë¦¬ ìƒì„± (ZIP ì „ìš© ë°©ì‹ + ì €ì¥ íƒ€ì´ë° ì •ë³´ í‘œì‹œ)
        log_entry = f"""
[{datetime.now().strftime(LOG_FORMAT['timestamp_format'])}] SESSION: {session_label} - {session_id}_{timestamp}
Nickname: {original_nickname}
Status: {upload_status}
Save Trigger: Auto-save after second recording completion
GCS Enabled: {GCS_ENABLED} (Service Account method - ZIP only)
Bucket: {GCS_BUCKET_NAME}
Files uploaded: {len(uploaded_files)} ({', '.join(uploaded_files) if uploaded_files else 'None'})
Errors: {len(errors)} ({'; '.join(errors) if errors else 'None'})
Email notification: {'Sent' if email_sent else 'Not sent/Failed'}
Data Safety: âœ… Secured before survey step
Excel conversion: âŒ Removed for faster deployment (CSV only)
{'='*80}
"""
        
        # ë¡œê·¸ íŒŒì¼ì— ì¶”ê°€
        with open(log_filename, 'a', encoding='utf-8') as log_file:
            log_file.write(log_entry)
        
        return True
    except Exception as e:
        print(f"Logging failed: {e}")
        return False


def display_download_buttons(csv_filename, excel_filename, zip_filename):
    """
    ì—°êµ¬ììš© ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ë“¤ í‘œì‹œ (Excel ì œê±° ë²„ì „)
    
    Args:
        csv_filename: CSV íŒŒì¼ ê²½ë¡œ
        excel_filename: Excel íŒŒì¼ ê²½ë¡œ (None - ê¸°ëŠ¥ ì œê±°ë¨)
        zip_filename: ZIP íŒŒì¼ ê²½ë¡œ
    """
    if GCS_ENABLED:
        st.info("ğŸ“¤ ZIP file should be automatically uploaded to Google Cloud Storage. Use these downloads as backup only.")
    else:
        st.warning("âš ï¸ GCS upload is disabled. Use these download buttons to save your data.")
    
    # Excel ì œê±°ë¡œ 2ê°œ ì»¬ëŸ¼ë§Œ ì‚¬ìš©
    col1, col2 = st.columns(2)
    
    # ì„¸ì…˜ ì •ë³´ë¥¼ ë‹¤ìš´ë¡œë“œ íŒŒì¼ëª…ì— í¬í•¨
    session_num = getattr(st.session_state, 'session_number', CURRENT_SESSION)
    timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    with col1:
        # ğŸ“¦ ZIP ì™„ì „ ë°±ì—… ë‹¤ìš´ë¡œë“œ (ë©”ì¸)
        if zip_filename and os.path.exists(zip_filename):
            try:
                with open(zip_filename, 'rb') as f:
                    zip_data = f.read()
                st.download_button(
                    label="ğŸ“¦ Complete Backup ZIP",
                    data=zip_data,
                    file_name=f"{st.session_state.session_id}_{timestamp_str}.zip",
                    mime='application/zip',
                    use_container_width=True
                )
            except:
                st.info("ZIP unavailable")
        else:
            st.info("ZIP unavailable")
    
    with col2:
        # CSV ë‹¤ìš´ë¡œë“œ
        if csv_filename and os.path.exists(csv_filename):
            try:
                with open(csv_filename, 'r', encoding='utf-8') as f:
                    csv_data = f.read()
                st.download_button(
                    label="ğŸ“„ CSV Data (Open in Excel)",
                    data=csv_data,
                    file_name=f"session{session_num}_{st.session_state.session_id}_{timestamp_str}.csv",
                    mime='text/csv',
                    use_container_width=True
                )
            except:
                st.error("CSV download failed")
        else:
            st.info("CSV unavailable")
    
    # Excel ì œê±° ì•ˆë‚´
    st.caption("â„¹ï¸ Excel file generation has been removed for faster deployment. The CSV file can be opened directly in Excel.")


def display_session_details():
    """
    ì—°êµ¬ììš© ì„¸ì…˜ ìƒì„¸ ì •ë³´ í‘œì‹œ (ë‹‰ë„¤ì„ ì •ë³´ í¬í•¨ + GCS ìƒíƒœ)
    """
    st.markdown("**ğŸ“‹ Session Details:**")
    display_name = getattr(st.session_state, 'original_nickname', st.session_state.session_id)
    session_label = getattr(st.session_state, 'session_label', SESSION_LABELS.get(CURRENT_SESSION, "Session 1"))
    st.write(f"**Participant:** {display_name} (ID: {st.session_state.session_id})")
    st.write(f"**Session:** {session_label}")
    st.write(f"**Question:** {EXPERIMENT_QUESTION}")
    st.write(f"**Completed:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    st.write(f"**Data Saved:** After second recording completion")
    
    # === ë°°ê²½ ì •ë³´ í‘œì‹œ ===
    learning_duration = getattr(st.session_state, 'learning_duration', '')
    speaking_confidence = getattr(st.session_state, 'speaking_confidence', '')
    if learning_duration:
        st.write(f"**Learning Duration:** {learning_duration}")
    if speaking_confidence:
        st.write(f"**Speaking Confidence:** {speaking_confidence}")
    
    # === GCS ì—°ë™ ìƒíƒœ í‘œì‹œ (ZIP ì „ìš©) ===
    st.markdown("**â˜ï¸ Google Cloud Storage Status:**")
    if GCS_ENABLED:
        st.success("âœ… GCS upload is enabled (Service Account method - ZIP only)")
        if GCS_BUCKET_NAME:
            st.write(f"Bucket: {GCS_BUCKET_NAME}")
            st.write(f"Storage method: ZIP archives + nickname mapping")
            st.write(f"Save timing: Auto-save after 2nd recording")
        else:
            st.warning("âš ï¸ No bucket specified")
        
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        success, message = test_gcs_connection()
        if success:
            st.write("ğŸ”— Connection: âœ… Active")
        else:
            st.write(f"ğŸ”— Connection: âŒ {message}")
    else:
        st.warning("âŒ GCS upload is disabled")


def display_data_quality_info():
    """
    ë°ì´í„° í’ˆì§ˆ ì •ë³´ í‘œì‹œ (STT ë£¨ë¸Œë¦­ ê¸°ë°˜ - 60ì´ˆ ëª©í‘œ)
    """
    st.markdown("**ğŸ“Š Data Quality (STT Rubric-Based):**")
    col1, col2 = st.columns(2)
    
    with col1:
        duration1 = getattr(st.session_state, 'audio_duration_1', 0)
        if duration1 > 0:
            quality1 = get_quality_description(duration1)
            st.write(f"First recording: {duration1:.1f}s")
            st.caption(quality1)
        
        if st.session_state.feedback:
            issues_count = len(st.session_state.feedback.get('grammar_issues', []))
            vocab_count = len(st.session_state.feedback.get('vocabulary_suggestions', []))
            content_count = len(st.session_state.feedback.get('content_expansion_suggestions', []))
            st.write(f"Grammar issues: {issues_count}")
            st.write(f"Vocab suggestions: {vocab_count}")
            st.write(f"Content ideas: {content_count}")
            
            rubric_score = st.session_state.feedback.get('interview_readiness_score', 'N/A')
            st.write(f"STT Rubric Score: {rubric_score}/10")
    
    with col2:
        duration2 = getattr(st.session_state, 'audio_duration_2', 0)
        if duration2 > 0:
            quality2 = get_quality_description(duration2)
            st.write(f"Second recording: {duration2:.1f}s")
            st.caption(quality2)
        
        if hasattr(st.session_state, 'improvement_assessment'):
            improvement = st.session_state.improvement_assessment
            score = improvement.get('improvement_score', 0)
            first_score = improvement.get('first_attempt_score', 0)
            second_score = improvement.get('second_attempt_score', 0)
            st.write(f"Improvement score: {score}/10")
            st.write(f"Progress: {first_score} â†’ {second_score}")
            improvements = len(improvement.get('specific_improvements', []))
            issues = len(improvement.get('remaining_issues', []))
            st.write(f"Improvements: {improvements}")
            st.write(f"Remaining issues: {issues}")
        
        # ì €ì¥ ìƒíƒœ í‘œì‹œ
        if hasattr(st.session_state, 'data_saved') and st.session_state.data_saved:
            st.write("ğŸ’¾ **Data Status:** âœ… Safely saved")
        else:
            st.write("ğŸ’¾ **Data Status:** âš ï¸ Not yet saved")


def get_quality_description(duration):
    """
    ìŒì„± ê¸¸ì´ì— ë”°ë¥¸ í’ˆì§ˆ ì„¤ëª… ë°˜í™˜ (60ì´ˆ ëª©í‘œ)
    
    Args:
        duration: ìŒì„± ê¸¸ì´ (ì´ˆ)
        
    Returns:
        str: í’ˆì§ˆ ì„¤ëª…
    """
    if duration >= 60:
        return "âœ… Excellent (60s+ target reached!)"
    elif duration >= 45:
        return "ğŸŒŸ Good (45-60s, try for 60+)"
    elif duration >= 30:
        return "âš ï¸ Fair (30-45s, needs improvement)"
    else:
        return "âŒ Very Short (under 30s, much more needed)"


def cleanup_old_files(days_old=7):
    """
    ì˜¤ë˜ëœ ì„ì‹œ íŒŒì¼ë“¤ ì •ë¦¬
    
    Args:
        days_old: ì‚­ì œí•  íŒŒì¼ ë‚˜ì´ (ì¼)
    """
    try:
        cutoff_date = datetime.now() - timedelta(days=days_old)
        
        for folder in FOLDERS.values():
            if os.path.exists(folder):
                for filename in os.listdir(folder):
                    file_path = os.path.join(folder, filename)
                    if os.path.isfile(file_path):
                        file_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                        if file_time < cutoff_date:
                            os.remove(file_path)
                            print(f"Cleaned up old file: {filename}")
    except Exception as e:
        print(f"Cleanup failed: {e}")


def retry_gcs_upload():
    """
    GCS ì—…ë¡œë“œ ì¬ì‹œë„ (ì„ íƒì  ê¸°ëŠ¥)
    
    Returns:
        tuple: (success, message)
    """
    if not hasattr(st.session_state, 'saved_files') or not st.session_state.saved_files[4]:
        return False, "No local files to upload"
    
    try:
        zip_filename = st.session_state.saved_files[4]
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        uploaded_files, errors = auto_backup_to_gcs(
            None, None, zip_filename,
            st.session_state.session_id,
            timestamp
        )
        
        if uploaded_files and not errors:
            return True, "Upload successful"
        else:
            return False, f"Upload failed: {'; '.join(errors)}"
            
    except Exception as e:
        return False, f"Retry failed: {str(e)}"