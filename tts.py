"""
tts.py
ElevenLabsë¥¼ ì´ìš©í•œ í…ìŠ¤íŠ¸-ìŒì„± ë³€í™˜ ë° ì˜¤ë””ì˜¤ ì¬ìƒ ëª¨ë“ˆ (ìµœì¢… í´ë¦° ë²„ì „)
"""

import streamlit as st
import re
from config import (
    ELEVENLABS_API_KEY, 
    ELEVEN_VOICE_ID, 
    ELEVENLABS_MODEL, 
    TTS_SETTINGS
)


def fix_tts_sentence_punctuation(text):
    """
    ìì—°ìŠ¤ëŸ¬ìš´ ì–µì–‘ì„ ìœ„í•œ ë§ˆì¹¨í‘œ ìë™ ë³´ì • (ì–µì–‘ ë‚´ë¦¼ ìœ ë„)
    
    Args:
        text: ë³´ì •í•  í…ìŠ¤íŠ¸
        
    Returns:
        str: ë§ˆì¹¨í‘œê°€ ë³´ì •ëœ í…ìŠ¤íŠ¸
    """
    text = text.strip()
    
    # ğŸ¯ í•œêµ­ì–´ TTS ì–µì–‘ ê°œì„ : ëª¨ë“  ë¬¸ì¥ ëì— ëª…í™•í•œ ë§ˆì¹¨í‘œ
    if text.endswith(('?', '!')):
        # ì˜ë¬¸ë¬¸, ê°íƒ„ë¬¸ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
        return text
    elif text.endswith(('.', '...')):
        # ì´ë¯¸ ë§ˆì¹¨í‘œê°€ ìˆìœ¼ë©´ ì •ë¦¬ë§Œ
        return text.rstrip('.') + '.'
    else:
        # í•œêµ­ì–´ ì–´ë¯¸ë¡œ ëë‚˜ë”ë¼ë„ ëª…í™•í•œ ë§ˆì¹¨í‘œ ì¶”ê°€
        return text + '.'


def apply_slow_speed_formatting(text):
    """
    SSMLì„ ì‚¬ìš©í•œ ëŠë¦° ì†ë„ í¬ë§·íŒ… (fallbackìš© - 500ms ì¼ì‹œì •ì§€ + 70% ì†ë„)
    
    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸
        
    Returns:
        str: SSMLë¡œ í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸
    """
    # 1. ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬ (í•œêµ­ì–´ ë¬¸ì¥ êµ¬ë¶„ì ê¸°ì¤€)
    sentences = re.split(r'([.!?])', text)
    
    # 2. ê° ë¬¸ì¥ ëì— 500ms ì¼ì‹œì •ì§€ ì¶”ê°€
    formatted_parts = []
    for i in range(0, len(sentences)-1, 2):
        if i+1 < len(sentences):
            sentence = sentences[i] + sentences[i+1]  # ë¬¸ì¥ + êµ¬ë¶„ì
            if sentence.strip():
                formatted_parts.append(sentence + '<break time="500ms"/>')
    
    # ë§ˆì§€ë§‰ ë¶€ë¶„ì´ ë‚¨ì•„ìˆë‹¤ë©´ ì¶”ê°€
    if len(sentences) % 2 == 1 and sentences[-1].strip():
        formatted_parts.append(sentences[-1])
    
    # 3. ì „ì²´ë¥¼ prosody rate 70%ë¡œ ê°ì‹¸ê¸° (ElevenLabs speed ì œí•œì— ë§ì¶¤)
    formatted_text = ''.join(formatted_parts)
    return f'<prosody rate="70%">{formatted_text}</prosody>'


def apply_fallback_slow_formatting(text):
    """
    SSML ì§€ì›í•˜ì§€ ì•Šì„ ê²½ìš° í…ìŠ¤íŠ¸ ê¸°ë°˜ ëŠë¦° ì†ë„ êµ¬í˜„ (fallbackìš©)
    
    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸
        
    Returns:
        str: ëŠë¦° ì†ë„ìš©ìœ¼ë¡œ í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸
    """
    # ë¬¸ì¥ë§ˆë‹¤ ì¶”ê°€ ë§ˆì¹¨í‘œë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ì¼ì‹œì •ì§€ ìƒì„±
    sentences = re.split(r'([.!?])', text)
    slow_parts = []
    
    for i in range(0, len(sentences)-1, 2):
        if i+1 < len(sentences):
            sentence = sentences[i] + sentences[i+1]
            if sentence.strip():
                # ë¬¸ì¥ ëì— ì¶”ê°€ ë§ˆì¹¨í‘œì™€ ê³µë°±ìœ¼ë¡œ ì¼ì‹œì •ì§€ íš¨ê³¼
                slow_parts.append(sentence + '. ')
    
    # ë§ˆì§€ë§‰ ë¶€ë¶„ ì²˜ë¦¬
    if len(sentences) % 2 == 1 and sentences[-1].strip():
        slow_parts.append(sentences[-1])
    
    return ''.join(slow_parts)


def apply_natural_pacing(text):
    """
    ìì—°ìŠ¤ëŸ¬ìš´ ë§í•˜ê¸° ì†ë„ë¥¼ ìœ„í•œ í¬ë§·íŒ…
    
    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸
        
    Returns:
        str: ìì—°ìŠ¤ëŸ½ê²Œ í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸
    """
    # ì¼ë°˜ ì†ë„ëŠ” ì›ë³¸ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
    return text


def synthesize_audio(text, speed="normal"):
    """
    í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜ (ElevenLabs ê³µì‹ speed íŒŒë¼ë¯¸í„° ì‚¬ìš©)
    
    Args:
        text: ë³€í™˜í•  í…ìŠ¤íŠ¸
        speed: ì†ë„ ("normal" ë˜ëŠ” "slow")
        
    Returns:
        bytes: ìƒì„±ëœ ì˜¤ë””ì˜¤ ë°ì´í„° ë˜ëŠ” None
    """
    if not ELEVENLABS_API_KEY:
        return None
    
    try:
        from elevenlabs.client import ElevenLabs
        
        client = ElevenLabs(api_key=ELEVENLABS_API_KEY)
        
        # ğŸ¯ ìì—°ìŠ¤ëŸ¬ìš´ ì–µì–‘ì„ ìœ„í•œ ë§ˆì¹¨í‘œ ë³´ì •
        text = fix_tts_sentence_punctuation(text)
        original_text = text
        
        # ì†ë„ë³„ voice_settings ì„¤ì •
        voice_settings = TTS_SETTINGS.get(speed, TTS_SETTINGS["normal"]).copy()
        
        # ğŸš€ ElevenLabs ê³µì‹ speed íŒŒë¼ë¯¸í„° ì‚¬ìš©
        if speed == "slow":
            voice_settings["stability"] = 0.95  # ë§¤ìš° ë†’ì€ ì•ˆì •ì„±
            voice_settings["style"] = 0.05      # ìµœì†Œí•œì˜ ìŠ¤íƒ€ì¼ (ë‹¨ì¡°ë¡œìš´ ì–µì–‘)
            voice_settings["similarity_boost"] = 0.95  # ë†’ì€ ì¼ê´€ì„±
        else:
            voice_settings["stability"] = 0.75  # ì¼ë°˜ ì†ë„ ì•ˆì •ì„±
            voice_settings["style"] = 0.45      # ì ë‹¹í•œ ìŠ¤íƒ€ì¼
            voice_settings["similarity_boost"] = 0.80  # ì¼ê´€ì„±
        
        # ê³µì‹ speed íŒŒë¼ë¯¸í„° ì‚¬ìš©
        clean_settings = voice_settings.copy()
        if 'speed_modifier' in clean_settings:
            del clean_settings['speed_modifier']
        
        # ElevenLabs ê³µì‹ speed íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•œ ì˜¤ë””ì˜¤ ìƒì„±
        try:
            audio_generator = client.generate(
                text=text,
                voice=ELEVEN_VOICE_ID,
                model=ELEVENLABS_MODEL,
                voice_settings=clean_settings
            )
            
            # Convert generator to bytes
            audio_data = b"".join(audio_generator)
            
            if audio_data:
                return audio_data
            else:
                raise Exception("No audio data generated")
                
        except Exception as speed_error:
            # ê³µì‹ speed íŒŒë¼ë¯¸í„° ì‹¤íŒ¨ì‹œ SSML fallback ì‹œë„
            if speed == "slow":
                # Fallback 1: SSML ì†ë„ ì œì–´
                ssml_text = apply_slow_speed_formatting(original_text)
                
                # speed íŒŒë¼ë¯¸í„° ì œê±°í•˜ê³  SSMLë¡œ ì‹œë„
                fallback_settings = clean_settings.copy()
                if 'speed' in fallback_settings:
                    del fallback_settings['speed']
                
                try:
                    audio_generator = client.generate(
                        text=ssml_text,
                        voice=ELEVEN_VOICE_ID,
                        model=ELEVENLABS_MODEL,
                        voice_settings=fallback_settings
                    )
                    
                    audio_data = b"".join(audio_generator)
                    
                    if audio_data:
                        return audio_data
                    
                except Exception as ssml_error:
                    # Fallback 2: í…ìŠ¤íŠ¸ ê¸°ë°˜ ëŠë¦° ì†ë„
                    fallback_text = apply_fallback_slow_formatting(original_text)
                    
                    # voice_settingsë„ ë” ê·¹ë‹¨ì ìœ¼ë¡œ ì¡°ì •
                    fallback_settings["stability"] = 0.98
                    fallback_settings["style"] = 0.02
                    
                    try:
                        audio_generator = client.generate(
                            text=fallback_text,
                            voice=ELEVEN_VOICE_ID,
                            model=ELEVENLABS_MODEL,
                            voice_settings=fallback_settings
                        )
                        
                        audio_data = b"".join(audio_generator)
                        
                        if audio_data:
                            return audio_data
                        
                    except Exception as final_error:
                        st.warning(f"TTS generation failed: {final_error}")
                        return None
            else:
                # ì¼ë°˜ ì†ë„ì—ì„œëŠ” ì›ë³¸ í…ìŠ¤íŠ¸ë¡œ ì¬ì‹œë„ (speed íŒŒë¼ë¯¸í„° ì—†ì´)
                fallback_settings = clean_settings.copy()
                if 'speed' in fallback_settings:
                    del fallback_settings['speed']
                
                try:
                    audio_generator = client.generate(
                        text=original_text,
                        voice=ELEVEN_VOICE_ID,
                        model=ELEVENLABS_MODEL,
                        voice_settings=fallback_settings
                    )
                    
                    audio_data = b"".join(audio_generator)
                    
                    if audio_data:
                        return audio_data
                        
                except Exception as normal_error:
                    st.warning(f"TTS generation failed: {normal_error}")
                    return None
    
    except ImportError as ie:
        st.warning(f"ElevenLabs import error: {str(ie)}")
        return None
    except Exception as e:
        st.warning(f"TTS generation failed: {str(e)}")
        return None


def generate_model_audio(text):
    """
    ì¼ë°˜ì†ë„ì™€ ëŠë¦°ì†ë„ ëª¨ë¸ ìŒì„± ìƒì„± (ElevenLabs ê³µì‹ speed íŒŒë¼ë¯¸í„° ì‚¬ìš©)
    
    Args:
        text: ë³€í™˜í•  í…ìŠ¤íŠ¸
        
    Returns:
        dict: {"normal": audio_data, "slow": audio_data}
    """
    model_audio = {}
    
    with st.spinner("ğŸ”Š Generating model pronunciation..."):
        # ì¼ë°˜ ì†ë„ ìƒì„±
        with st.spinner("ğŸš€ Creating natural speed version..."):
            normal_audio = synthesize_audio(text, "normal")
            if normal_audio:
                model_audio["normal"] = normal_audio
        
        # ëŠë¦° ì†ë„ ìƒì„± (ElevenLabs ê³µì‹ speed íŒŒë¼ë¯¸í„° ì‚¬ìš©)
        with st.spinner("ğŸŒ Creating slow speed version..."):
            slow_audio = synthesize_audio(text, "slow")
            if slow_audio:
                model_audio["slow"] = slow_audio
    
    return model_audio


def audio_card(audio_data, title, description=""):
    """
    í†µì¼ëœ ì˜¤ë””ì˜¤ ì¹´ë“œ ì»´í¬ë„ŒíŠ¸
    
    Args:
        audio_data: ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ë°ì´í„°
        title: ì¹´ë“œ ì œëª©
        description: ì„¤ëª… í…ìŠ¤íŠ¸
    """
    if audio_data:
        st.markdown(
            f"""<div style='padding: 15px; border: 1px solid #e2e8f0; border-radius: 8px; margin: 10px 0; background-color: #ffffff;'>
            <h5 style='margin: 0 0 10px 0; color: #374151;'>{title}</h5>
            </div>""",
            unsafe_allow_html=True
        )
        st.audio(audio_data)
        if description:
            st.caption(description)
    else:
        st.info(f"{title} (ElevenLabs API not configured)")


def display_model_audio(model_audio_dict):
    """
    ëª¨ë¸ ë°œìŒ ì˜¤ë””ì˜¤ë¥¼ í‘œì‹œ (í•™ìƒ ì¹œí™”ì  ë©”ì‹œì§€ë¡œ ìˆ˜ì •)
    
    Args:
        model_audio_dict: {"normal": audio_data, "slow": audio_data}
    """
    if not model_audio_dict:
        st.info("ğŸ”Š Model pronunciation (ElevenLabs API not configured)")
        return
    
    st.markdown("#### ğŸ¯ Model Pronunciation")
    st.info("ğŸ§ **Two different speeds** - Listen to both and practice speaking along!")
    
    col1, col2 = st.columns(2)
    
    with col1:
        audio_card(
            model_audio_dict.get('slow'), 
            "ğŸŒ Slow & Clear", 
            "ğŸ“š Perfect for learning - slower and clearer"
        )
    
    with col2:
        audio_card(
            model_audio_dict.get('normal'), 
            "ğŸš€ Natural Speed", 
            "ğŸ¯ Interview pace - practice matching this speed"
        )


def check_tts_availability():
    """
    TTS ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    
    Returns:
        tuple: (is_available, status_message)
    """
    if not ELEVENLABS_API_KEY:
        return False, "ElevenLabs API key not configured"
    
    if not ELEVEN_VOICE_ID:
        return False, "Voice ID not configured"
    
    try:
        from elevenlabs.client import ElevenLabs
        return True, "TTS ready"
    except ImportError:
        return False, "ElevenLabs library not installed"


def display_tts_status():
    """
    AI Model Voice ìƒíƒœë¥¼ ì‚¬ì´ë“œë°”ì— í‘œì‹œ
    """
    is_available, status = check_tts_availability()
    
    if is_available:
        st.write("AI Model Voice: âœ… Ready ")
    else:
        st.write(f"AI Model Voice: âŒ {status}")


def save_audio_to_session(model_audio_dict, session_key="model_audio"):
    """
    ìƒì„±ëœ ì˜¤ë””ì˜¤ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    
    Args:
        model_audio_dict: ì˜¤ë””ì˜¤ ë”•ì…”ë„ˆë¦¬
        session_key: ì„¸ì…˜ ì €ì¥ í‚¤
    """
    if session_key not in st.session_state:
        st.session_state[session_key] = {}
    
    st.session_state[session_key].update(model_audio_dict)


def get_audio_from_session(session_key="model_audio"):
    """
    ì„¸ì…˜ì—ì„œ ì˜¤ë””ì˜¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    
    Args:
        session_key: ì„¸ì…˜ í‚¤
        
    Returns:
        dict: ì˜¤ë””ì˜¤ ë”•ì…”ë„ˆë¦¬
    """
    return st.session_state.get(session_key, {})


def create_audio_download_links(model_audio_dict, prefix="model"):
    """
    ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„±
    
    Args:
        model_audio_dict: ì˜¤ë””ì˜¤ ë”•ì…”ë„ˆë¦¬
        prefix: íŒŒì¼ëª… ì ‘ë‘ì‚¬
    """
    if not model_audio_dict:
        return
    
    st.markdown("ğŸ“¥ **Download Audio Files:**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if model_audio_dict.get("normal"):
            st.download_button(
                label="ğŸ“ Download Natural Speed",
                data=model_audio_dict["normal"],
                file_name=f"{prefix}_natural.mp3",
                mime="audio/mpeg"
            )
    
    with col2:
        if model_audio_dict.get("slow"):
            st.download_button(
                label="ğŸ“ Download Slow Speed", 
                data=model_audio_dict["slow"],
                file_name=f"{prefix}_slow.mp3",
                mime="audio/mpeg"
            )


def validate_text_for_tts(text):
    """
    TTS ìƒì„±ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ìœ íš¨ì„± ê²€ì‚¬
    
    Args:
        text: ê²€ì‚¬í•  í…ìŠ¤íŠ¸
        
    Returns:
        tuple: (is_valid, error_message)
    """
    if not text or not text.strip():
        return False, "Empty text provided"
    
    if len(text) > 1000:
        return False, "Text too long (max 1000 characters)"
    
    # í•œêµ­ì–´ ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    has_korean = any('\uac00' <= char <= '\ud7af' for char in text)
    if not has_korean:
        return False, "No Korean text detected"
    
    return True, "Valid text"


def process_feedback_audio(feedback_dict):
    """
    í”¼ë“œë°±ì—ì„œ ëª¨ë¸ ë¬¸ì¥ì„ ì¶”ì¶œí•˜ì—¬ ì˜¤ë””ì˜¤ ìƒì„± (ElevenLabs ê³µì‹ speed íŒŒë¼ë¯¸í„° ì‚¬ìš©)
    
    Args:
        feedback_dict: GPT í”¼ë“œë°± ë”•ì…”ë„ˆë¦¬
        
    Returns:
        dict: ìƒì„±ëœ ì˜¤ë””ì˜¤ ë”•ì…”ë„ˆë¦¬
    """
    model_sentence = feedback_dict.get('suggested_model_sentence', '')
    
    # ğŸ¯ ìì—°ìŠ¤ëŸ¬ìš´ ì–µì–‘ ìœ ë„: ë§ˆì¹¨í‘œ ìë™ ì¶”ê°€
    model_sentence = fix_tts_sentence_punctuation(model_sentence)
    
    if not model_sentence:
        st.warning("âš ï¸ No model sentence found in feedback")
        return {}
    
    # í…ìŠ¤íŠ¸ ìœ íš¨ì„± ê²€ì‚¬
    is_valid, error_msg = validate_text_for_tts(model_sentence)
    if not is_valid:
        st.error(f"âŒ TTS Error: {error_msg}")
        return {}
    
    # TTS ê°€ìš©ì„± í™•ì¸
    is_available, status = check_tts_availability()
    if not is_available:
        st.info(f"â„¹ï¸ TTS not available: {status}")
        return {}
    
    # ì˜¤ë””ì˜¤ ìƒì„±
    return generate_model_audio(model_sentence)


def display_audio_generation_progress():
    """
    ì˜¤ë””ì˜¤ ìƒì„± ì§„í–‰ìƒí™© í‘œì‹œ
    """
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # ë‹¨ê³„ë³„ ì§„í–‰ìƒí™© ì‹œë®¬ë ˆì´ì…˜
    steps = [
        "ğŸ”Š Initializing TTS engine...",
        "ğŸ¯ Processing Korean text...", 
        "ğŸš€ Generating natural speed audio...",
        "ğŸŒ Generating slow speed audio...",
        "âœ… Audio generation complete!"
    ]
    
    for i, step in enumerate(steps):
        status_text.text(step)
        progress_bar.progress((i + 1) / len(steps))
        
    # ì™„ë£Œ í›„ ì •ë¦¬
    status_text.empty()
    progress_bar.empty()