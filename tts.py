"""
tts.py
ElevenLabsë¥¼ ì´ìš©í•œ í…ìŠ¤íŠ¸-ìŒì„± ë³€í™˜ ë° ì˜¤ë””ì˜¤ ì¬ìƒ ëª¨ë“ˆ (ìµœì‹  SDK í˜¸í™˜ ë²„ì „)
"""

import streamlit as st
import re
from config import (
    ELEVENLABS_API_KEY, 
    ELEVEN_VOICE_ID, 
    ELEVENLABS_MODEL, 
    TTS_SETTINGS
)


def fix_tts_sentence_punctuation(text):
    """
    ìì—°ìŠ¤ëŸ¬ìš´ ì–µì–‘ì„ ìœ„í•œ ë§ˆì¹¨í‘œ ìë™ ë³´ì • (ì–µì–‘ ë‚´ë¦¼ ìœ ë„)
    
    Args:
        text: ë³´ì •í•  í…ìŠ¤íŠ¸
        
    Returns:
        str: ë§ˆì¹¨í‘œê°€ ë³´ì •ëœ í…ìŠ¤íŠ¸
    """
    text = text.strip()
    
    # ğŸ¯ í•œêµ­ì–´ TTS ì–µì–‘ ê°œì„ : ëª¨ë“  ë¬¸ì¥ ëì— ëª…í™•í•œ ë§ˆì¹¨í‘œ
    if text.endswith(('?', '!')):
        # ì˜ë¬¸ë¬¸, ê°íƒ„ë¬¸ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
        return text
    elif text.endswith(('.', '...')):
        # ì´ë¯¸ ë§ˆì¹¨í‘œê°€ ìˆìœ¼ë©´ ì •ë¦¬ë§Œ
        return text.rstrip('.') + '.'
    else:
        # í•œêµ­ì–´ ì–´ë¯¸ë¡œ ëë‚˜ë”ë¼ë„ ëª…í™•í•œ ë§ˆì¹¨í‘œ ì¶”ê°€
        return text + '.'


def apply_slow_speed_formatting(text):
    """
    ëŠë¦° ì†ë„ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ í¬ë§·íŒ… (ì‰¼í‘œ ì¶”ê°€ ì œê±°)
    
    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸
        
    Returns:
        str: ëŠë¦° ì†ë„ìš©ìœ¼ë¡œ í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸
    """
    # 1. ë¬¸ì¥ ì‚¬ì´ ê³µë°± ì •ë¦¬ë§Œ
    text = re.sub(r'([.!?])\s*', r'\1 ', text)
    
    # 2. ë‹¨ì–´ ê°„ê²©ì„ ì•½ê°„ ëŠ˜ë¦¬ê¸° (ë„ì–´ì“°ê¸° ëŠ˜ë¦¬ê¸°)
    text = re.sub(r'\s+', '  ', text)  # ë‹¨ì¼ ê³µë°±ì„ ë‘ ê°œë¡œ
    
    # ì‰¼í‘œ ì¶”ê°€ ë¡œì§ ì™„ì „ ì œê±°
    return text


def apply_natural_pacing(text):
    """
    ìì—°ìŠ¤ëŸ¬ìš´ ë§í•˜ê¸° ì†ë„ë¥¼ ìœ„í•œ í¬ë§·íŒ… (ì‰¼í‘œ ì¶”ê°€ ì œê±°)
    
    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸
        
    Returns:
        str: ìì—°ìŠ¤ëŸ½ê²Œ í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸
    """
    # ì‰¼í‘œ ì¶”ê°€ ë¡œì§ ì™„ì „ ì œê±° - ê·¸ëƒ¥ ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜
    return text


def get_elevenlabs_client():
    """
    ElevenLabs í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ìµœì‹  SDK í˜¸í™˜)
    
    Returns:
        ElevenLabs: í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ë˜ëŠ” None
    """
    if not ELEVENLABS_API_KEY:
        return None
    
    try:
        # ìµœì‹  SDK ë°©ì‹ (1.0.0+)
        from elevenlabs import ElevenLabs
        return ElevenLabs(api_key=ELEVENLABS_API_KEY)
    except ImportError:
        try:
            # êµ¬ë²„ì „ fallback
            from elevenlabs.client import ElevenLabs
            return ElevenLabs(api_key=ELEVENLABS_API_KEY)
        except ImportError:
            return None


def synthesize_audio(text, speed="normal"):
    """
    í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜ (voice_settingsë§Œìœ¼ë¡œ ì†ë„ ì°¨ì´ êµ¬í˜„)
    
    Args:
        text: ë³€í™˜í•  í…ìŠ¤íŠ¸
        speed: ì†ë„ ("normal" ë˜ëŠ” "slow")
        
    Returns:
        bytes: ìƒì„±ëœ ì˜¤ë””ì˜¤ ë°ì´í„° ë˜ëŠ” None
    """
    if not ELEVENLABS_API_KEY:
        print("ElevenLabs API key not configured")
        return None
    
    try:
        client = get_elevenlabs_client()
        if not client:
            print("Failed to initialize ElevenLabs client")
            return None
        
        # ğŸ¯ ìì—°ìŠ¤ëŸ¬ìš´ ì–µì–‘ì„ ìœ„í•œ ë§ˆì¹¨í‘œ ë³´ì •ë§Œ
        text = fix_tts_sentence_punctuation(text)
        
        # ğŸŒ ì†ë„ë³„ í…ìŠ¤íŠ¸ í¬ë§·íŒ… ì ìš© (ì‰¼í‘œ ì—†ì´)
        if speed == "slow":
            text = apply_slow_speed_formatting(text)
            print(f"Slow speed text: {text}")
        else:
            text = apply_natural_pacing(text)
            print(f"Normal speed text: {text}")
        
        print("Starting TTS generation...")
        print("Text:", text[:100] + "..." if len(text) > 100 else text)
        print("Voice ID:", ELEVEN_VOICE_ID)
        print("Speed:", speed)
        
        # ì†ë„ë³„ voice_settings ì„¤ì • (ì–µì–‘ ì•ˆì •í™”)
        voice_settings = TTS_SETTINGS.get(speed, TTS_SETTINGS["normal"]).copy()
        
        # ğŸ¯ í•œêµ­ì–´ ì–µì–‘ ê°œì„ : ë” ì•ˆì •ì ì¸ ì„¤ì •
        if speed == "slow":
            voice_settings["stability"] = 0.90  # ë” ë†’ì€ ì•ˆì •ì„± (ì–µì–‘ ë³€í™” ìµœì†Œí™”)
            voice_settings["style"] = 0.15      # ë” ë‚®ì€ ìŠ¤íƒ€ì¼ (ë‹¨ì¡°ë¡œìš´ ì–µì–‘)
        else:
            voice_settings["stability"] = 0.75  # ì¼ë°˜ ì†ë„ë„ ì•ˆì •ì„± ì¦ê°€
            voice_settings["style"] = 0.45      # ìŠ¤íƒ€ì¼ ì•½ê°„ ê°ì†Œ
        
        # speed_modifier ì œê±° (ElevenLabs APIì—ì„œ ì§€ì›í•˜ì§€ ì•ŠìŒ)
        clean_settings = {k: v for k, v in voice_settings.items() if k != 'speed_modifier'}
        
        print(f"Voice settings ({speed}) - Enhanced for Korean:", clean_settings)
        
        # Generate audio using client with voice settings
        audio_generator = client.generate(
            text=text,
            voice=ELEVEN_VOICE_ID,
            model=ELEVENLABS_MODEL,
            voice_settings=clean_settings
        )
        
        # Convert generator to bytes
        audio_data = b"".join(audio_generator)
        
        if audio_data:
            print(f"TTS Success ({speed})! Audio length:", len(audio_data))
            return audio_data
        else:
            print("No audio data received")
            st.warning("TTS generation returned no audio data.")
            return None
    
    except ImportError as ie:
        print("Import error:", str(ie))
        st.warning(f"ElevenLabs import error: {str(ie)}")
        return None
    except Exception as e:
        print("TTS error:", str(e))
        st.warning(f"TTS generation failed: {str(e)}")
        return None


def generate_model_audio(text):
    """
    ì¼ë°˜ì†ë„ì™€ ëŠë¦°ì†ë„ ëª¨ë¸ ìŒì„± ìƒì„± (voice_settingsë¡œë§Œ ì†ë„ ì°¨ì´)
    
    Args:
        text: ë³€í™˜í•  í…ìŠ¤íŠ¸
        
    Returns:
        dict: {"normal": audio_data, "slow": audio_data}
    """
    model_audio = {}
    
    with st.spinner("ğŸ”Š Generating model pronunciation..."):
        # ì¼ë°˜ ì†ë„ ìƒì„±
        with st.spinner("ğŸš€ Creating natural speed version..."):
            normal_audio = synthesize_audio(text, "normal")
            if normal_audio:
                model_audio["normal"] = normal_audio
        
        # ëŠë¦° ì†ë„ ìƒì„± (voice_settingsë¡œë§Œ ì°¨ì´)
        with st.spinner("ğŸŒ Creating slow speed version..."):
            slow_audio = synthesize_audio(text, "slow")
            if slow_audio:
                model_audio["slow"] = slow_audio
    
    return model_audio


def audio_card(audio_data, title, description=""):
    """
    í†µì¼ëœ ì˜¤ë””ì˜¤ ì¹´ë“œ ì»´í¬ë„ŒíŠ¸
    
    Args:
        audio_data: ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ë°ì´í„°
        title: ì¹´ë“œ ì œëª©
        description: ì„¤ëª… í…ìŠ¤íŠ¸
    """
    if audio_data:
        st.markdown(
            f"""<div style='padding: 15px; border: 1px solid #e2e8f0; border-radius: 8px; margin: 10px 0; background-color: #ffffff;'>
            <h5 style='margin: 0 0 10px 0; color: #374151;'>{title}</h5>
            </div>""",
            unsafe_allow_html=True
        )
        st.audio(audio_data)
        if description:
            st.caption(description)
    else:
        st.info(f"{title} (ElevenLabs API not configured)")


def display_model_audio(model_audio_dict):
    """
    ëª¨ë¸ ë°œìŒ ì˜¤ë””ì˜¤ë¥¼ í‘œì‹œ (voice_settings ê¸°ë°˜ ì†ë„ ì°¨ì´)
    
    Args:
        model_audio_dict: {"normal": audio_data, "slow": audio_data}
    """
    if not model_audio_dict:
        st.info("ğŸ”Š Model pronunciation (ElevenLabs API not configured)")
        return
    
    st.markdown("#### ğŸ¯ Model Pronunciation")
    st.info("ğŸ§ **Two different speeds** - Listen to both and practice speaking along!")
    
    col1, col2 = st.columns(2)
    
    with col1:
        audio_card(
            model_audio_dict.get('slow'), 
            "ğŸŒ Slow & Clear", 
            "ğŸ“š Perfect for learning - clearer pronunciation"
        )
    
    with col2:
        audio_card(
            model_audio_dict.get('normal'), 
            "ğŸš€ Natural Speed", 
            "ğŸ¯ Interview pace - practice matching this speed"
        )
    
    # ì†ë„ ì°¨ì´ ì„¤ëª… ìˆ˜ì •
    if model_audio_dict.get('slow') and model_audio_dict.get('normal'):
        st.success("âœ… **Speed difference implemented!** Different voice settings create natural speed variation.")


def check_tts_availability():
    """
    TTS ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    
    Returns:
        tuple: (is_available, status_message)
    """
    if not ELEVENLABS_API_KEY:
        return False, "ElevenLabs API key not configured"
    
    if not ELEVEN_VOICE_ID:
        return False, "Voice ID not configured"
    
    # ìµœì‹  SDK í˜¸í™˜ì„± í™•ì¸
    try:
        # ìµœì‹  SDK ë°©ì‹ (1.0.0+)
        from elevenlabs import ElevenLabs
        return True, "TTS ready (Latest SDK)"
    except ImportError:
        try:
            # êµ¬ë²„ì „ fallback
            from elevenlabs.client import ElevenLabs
            return True, "TTS ready (Legacy SDK)"
        except ImportError:
            return False, "ElevenLabs library not installed"


def display_tts_status():
    """
    AI Model Voice ìƒíƒœë¥¼ ì‚¬ì´ë“œë°”ì— í‘œì‹œ
    """
    is_available, status = check_tts_availability()
    
    if is_available:
        st.write("AI Model Voice: âœ… Ready")
    else:
        st.write(f"AI Model Voice: âŒ {status}")


def save_audio_to_session(model_audio_dict, session_key="model_audio"):
    """
    ìƒì„±ëœ ì˜¤ë””ì˜¤ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    
    Args:
        model_audio_dict: ì˜¤ë””ì˜¤ ë”•ì…”ë„ˆë¦¬
        session_key: ì„¸ì…˜ ì €ì¥ í‚¤
    """
    if session_key not in st.session_state:
        st.session_state[session_key] = {}
    
    st.session_state[session_key].update(model_audio_dict)


def get_audio_from_session(session_key="model_audio"):
    """
    ì„¸ì…˜ì—ì„œ ì˜¤ë””ì˜¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    
    Args:
        session_key: ì„¸ì…˜ í‚¤
        
    Returns:
        dict: ì˜¤ë””ì˜¤ ë”•ì…”ë„ˆë¦¬
    """
    return st.session_state.get(session_key, {})


def create_audio_download_links(model_audio_dict, prefix="model"):
    """
    ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„±
    
    Args:
        model_audio_dict: ì˜¤ë””ì˜¤ ë”•ì…”ë„ˆë¦¬
        prefix: íŒŒì¼ëª… ì ‘ë‘ì‚¬
    """
    if not model_audio_dict:
        return
    
    st.markdown("ğŸ“¥ **Download Audio Files:**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if model_audio_dict.get("normal"):
            st.download_button(
                label="ğŸ“ Download Natural Speed",
                data=model_audio_dict["normal"],
                file_name=f"{prefix}_natural.mp3",
                mime="audio/mpeg"
            )
    
    with col2:
        if model_audio_dict.get("slow"):
            st.download_button(
                label="ğŸ“ Download Slow Speed", 
                data=model_audio_dict["slow"],
                file_name=f"{prefix}_slow.mp3",
                mime="audio/mpeg"
            )


def validate_text_for_tts(text):
    """
    TTS ìƒì„±ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ìœ íš¨ì„± ê²€ì‚¬
    
    Args:
        text: ê²€ì‚¬í•  í…ìŠ¤íŠ¸
        
    Returns:
        tuple: (is_valid, error_message)
    """
    if not text or not text.strip():
        return False, "Empty text provided"
    
    if len(text) > 1000:
        return False, "Text too long (max 1000 characters)"
    
    # í•œêµ­ì–´ ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    has_korean = any('\uac00' <= char <= '\ud7af' for char in text)
    if not has_korean:
        return False, "No Korean text detected"
    
    return True, "Valid text"


def process_feedback_audio(feedback_dict):
    """
    í”¼ë“œë°±ì—ì„œ ëª¨ë¸ ë¬¸ì¥ì„ ì¶”ì¶œí•˜ì—¬ ì˜¤ë””ì˜¤ ìƒì„± (voice_settings ê¸°ë°˜)
    
    Args:
        feedback_dict: GPT í”¼ë“œë°± ë”•ì…”ë„ˆë¦¬
        
    Returns:
        dict: ìƒì„±ëœ ì˜¤ë””ì˜¤ ë”•ì…”ë„ˆë¦¬
    """
    model_sentence = feedback_dict.get('suggested_model_sentence', '')
    
    # ğŸ¯ ìì—°ìŠ¤ëŸ¬ìš´ ì–µì–‘ ìœ ë„: ë§ˆì¹¨í‘œ ìë™ ì¶”ê°€ë§Œ
    model_sentence = fix_tts_sentence_punctuation(model_sentence)
    
    if not model_sentence:
        st.warning("âš ï¸ No model sentence found in feedback")
        return {}
    
    # í…ìŠ¤íŠ¸ ìœ íš¨ì„± ê²€ì‚¬
    is_valid, error_msg = validate_text_for_tts(model_sentence)
    if not is_valid:
        st.error(f"âŒ TTS Error: {error_msg}")
        return {}
    
    # TTS ê°€ìš©ì„± í™•ì¸
    is_available, status = check_tts_availability()
    if not is_available:
        st.info(f"â„¹ï¸ TTS not available: {status}")
        return {}
    
    # ì˜¤ë””ì˜¤ ìƒì„±
    return generate_model_audio(model_sentence)


def display_audio_generation_progress():
    """
    ì˜¤ë””ì˜¤ ìƒì„± ì§„í–‰ìƒí™© í‘œì‹œ
    """
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # ë‹¨ê³„ë³„ ì§„í–‰ìƒí™© ì‹œë®¬ë ˆì´ì…˜
    steps = [
        "ğŸ”Š Initializing TTS engine...",
        "ğŸ¯ Processing Korean text...", 
        "ğŸš€ Generating natural speed audio...",
        "ğŸŒ Generating slow speed audio with different voice settings...",
        "âœ… Audio generation complete!"
    ]
    
    for i, step in enumerate(steps):
        status_text.text(step)
        progress_bar.progress((i + 1) / len(steps))
        
    # ì™„ë£Œ í›„ ì •ë¦¬
    status_text.empty()
    progress_bar.empty()