"""
stt.py
Whisperë¥¼ ì´ìš©í•œ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ ëª¨ë“ˆ (ìµœì¢… ë²„ì „ - 40ì´ˆ ëª©í‘œ)
"""

import whisper
import tempfile
import os
import streamlit as st
from config import WHISPER_MODEL


@st.cache_resource
def load_whisper():
    """Whisper ëª¨ë¸ ë¡œë“œ (ìºì‹œ ì‚¬ìš©)"""
    try:
        return whisper.load_model(WHISPER_MODEL)
    except Exception as e:
        st.error(f"Whisper model loading failed: {str(e)}")
        return None


def transcribe_audio(audio_bytes):
    """
    ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ë¥¼ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    
    Args:
        audio_bytes: ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ë°”ì´íŠ¸ ë°ì´í„°
        
    Returns:
        tuple: (transcription_text, duration_seconds)
    """
    if not audio_bytes:
        return "", 0.0
    
    # ì„ì‹œ íŒŒì¼ ìƒì„±
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
        tmp.write(audio_bytes)
        temp_path = tmp.name
    
    try:
        # Whisper ëª¨ë¸ ë¡œë“œ
        model = load_whisper()
        if model is None:
            return "", 0.0
        
        # ìŒì„± ì¸ì‹ ìˆ˜í–‰
        result = model.transcribe(temp_path, language='ko', verbose=True)
        
        # ìŒì„± ê¸¸ì´ ê³„ì‚°
        duration = calculate_audio_duration(result, audio_bytes)
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬
        transcription = result["text"].strip()
        
        return transcription, duration
        
    except Exception as e:
        st.error(f"Transcription error: {str(e)}")
        return "", 0.0
    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        try:
            os.unlink(temp_path)
        except:
            pass


def calculate_audio_duration(whisper_result, audio_bytes):
    """
    ìŒì„± ê¸¸ì´ ê³„ì‚°
    
    Args:
        whisper_result: Whisper ê²°ê³¼ ê°ì²´
        audio_bytes: ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ë°ì´í„°
        
    Returns:
        float: ìŒì„± ê¸¸ì´ (ì´ˆ)
    """
    try:
        # Whisper segmentsì—ì„œ ì •í™•í•œ ê¸¸ì´ ì¶”ì¶œ
        if 'segments' in whisper_result and whisper_result['segments']:
            return whisper_result['segments'][-1]['end']
        else:
            # segmentsê°€ ì—†ìœ¼ë©´ ì¶”ì •ê°’ ì‚¬ìš© (16kHz, 16bit ê°€ì •)
            return len(audio_bytes) / (16000 * 2)
    except:
        # ëª¨ë“  ë°©ë²•ì´ ì‹¤íŒ¨í•˜ë©´ ê¸°ë³¸ê°’
        return len(audio_bytes) / (16000 * 2)


def get_audio_quality_assessment(duration):
    """
    ìŒì„± ê¸¸ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í’ˆì§ˆ í‰ê°€ (40ì´ˆ ëª©í‘œ)
    
    Args:
        duration: ìŒì„± ê¸¸ì´ (ì´ˆ)
        
    Returns:
        dict: í’ˆì§ˆ í‰ê°€ ì •ë³´
    """
    from config import AUDIO_QUALITY
    
    if duration >= AUDIO_QUALITY["excellent_min_duration"]:  # 40ì´ˆ ì´ìƒ
        if duration <= AUDIO_QUALITY["max_recommended_duration"]:
            return {
                "status": "excellent",
                "icon": "âœ…",
                "message": f"Great! Your recording is {duration:.1f}s â€” perfect length for the interview!",
                "color": "success"
            }
        else:
            return {
                "status": "long",
                "icon": "ğŸ“",
                "message": f"Excellent! ({duration:.1f}s) Lots of content for the AI to work with!",
                "color": "info"
            }
    elif duration >= AUDIO_QUALITY["good_min_duration"]:  # 30-40ì´ˆ
        return {
            "status": "good",
            "icon": "ğŸŒŸ",
            "message": f"Good! ({duration:.1f}s) Try to reach 40+ seconds for an even better score.",
            "color": "info"
        }
    elif duration >= AUDIO_QUALITY["fair_min_duration"]:  # 20-30ì´ˆ
        return {
            "status": "fair",
            "icon": "âš ï¸",
            "message": f"Fair start! ({duration:.1f}s) Aim for 40+ seconds to show better fluency.",
            "color": "warning"
        }
    else:  # 20ì´ˆ ë¯¸ë§Œ
        return {
            "status": "very_short",
            "icon": "âŒ",
            "message": f"Too brief! ({duration:.1f}s) Please speak for at least 20+ seconds, ideally 40+ seconds.",
            "color": "error"
        }


def display_audio_quality_feedback(duration):
    """
    ìŒì„± ê¸¸ì´ì— ëŒ€í•œ í”¼ë“œë°±ì„ Streamlitì— í‘œì‹œ
    
    Args:
        duration: ìŒì„± ê¸¸ì´ (ì´ˆ)
    """
    assessment = get_audio_quality_assessment(duration)
    
    if assessment["color"] == "success":
        st.success(f"{assessment['icon']} {assessment['message']}")
    elif assessment["color"] == "info":
        st.info(f"{assessment['icon']} {assessment['message']}")
    elif assessment["color"] == "warning":
        st.warning(f"{assessment['icon']} {assessment['message']}")
    else:  # error
        st.error(f"{assessment['icon']} {assessment['message']}")


def validate_audio_file(uploaded_file):
    """
    ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬
    
    Args:
        uploaded_file: Streamlit ì—…ë¡œë“œ íŒŒì¼ ê°ì²´
        
    Returns:
        tuple: (is_valid, error_message)
    """
    from config import SUPPORTED_AUDIO_FORMATS
    
    if uploaded_file is None:
        return False, "No file uploaded"
    
    # íŒŒì¼ í™•ì¥ì í™•ì¸
    file_extension = uploaded_file.name.split('.')[-1].lower()
    if file_extension not in SUPPORTED_AUDIO_FORMATS:
        return False, f"Unsupported format. Use: {', '.join(SUPPORTED_AUDIO_FORMATS)}"
    
    # íŒŒì¼ í¬ê¸° í™•ì¸ (50MB ì œí•œ)
    if uploaded_file.size > 50 * 1024 * 1024:
        return False, "File too large. Maximum size: 50MB"
    
    return True, "Valid file"


def process_audio_input(audio_data, source_type="recording"):
    """
    ì˜¤ë””ì˜¤ ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³  ì „ì‚¬
    
    Args:
        audio_data: ì˜¤ë””ì˜¤ ë°ì´í„° (ë…¹ìŒ ë˜ëŠ” ì—…ë¡œë“œ)
        source_type: ì…ë ¥ ì†ŒìŠ¤ íƒ€ì… ("recording" ë˜ëŠ” "upload")
        
    Returns:
        tuple: (transcription, duration, success)
    """
    try:
        if source_type == "upload":
            # ì—…ë¡œë“œëœ íŒŒì¼ ì²˜ë¦¬
            is_valid, error_msg = validate_audio_file(audio_data)
            if not is_valid:
                st.error(error_msg)
                return "", 0.0, False
            
            audio_bytes = audio_data.read()
            audio_data.seek(0)  # í¬ì¸í„° ë¦¬ì…‹
        else:
            # ë…¹ìŒëœ ì˜¤ë””ì˜¤ ì²˜ë¦¬
            audio_bytes = audio_data['bytes']
        
        # ì „ì‚¬ ìˆ˜í–‰
        with st.spinner("ğŸ™ï¸ Converting speech to text..."):
            transcription, duration = transcribe_audio(audio_bytes)
        
        if transcription:
            st.success(f"âœ… Transcribed: {transcription}")
            display_audio_quality_feedback(duration)
            return transcription, duration, True
        else:
            st.error("âŒ Could not transcribe audio. Please try again.")
            return "", 0.0, False
            
    except Exception as e:
        st.error(f"Audio processing error: {str(e)}")
        return "", 0.0, False