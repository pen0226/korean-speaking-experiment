"""
stt.py
OpenAI API Whisperë¥¼ ì´ìš©í•œ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ ëª¨ë“ˆ (íŒŒì¼ í˜•ì‹ ë° API í˜¸ì¶œ ê°œì„  ë²„ì „)
"""

import tempfile
import os
import streamlit as st
from config import OPENAI_API_KEY


def get_openai_client():
    """
    OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (proxies ì¶©ëŒ ë°©ì§€ & SDK í˜¸í™˜)
    
    Returns:
        OpenAI: í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ë˜ëŠ” None
    """
    if not OPENAI_API_KEY:
        return None
    
    try:
        # ìµœì‹  openai SDK (>=1.0.0) ë°©ì‹
        from openai import OpenAI
        # proxies ê´€ë ¨ ìë™ ì„¤ì • ë°©ì§€ë¥¼ ìœ„í•´ ëª…ì‹œì ìœ¼ë¡œ í•„ìš”í•œ ì¸ìë§Œ ì „ë‹¬
        return OpenAI(api_key=OPENAI_API_KEY)
    except ImportError:
        try:
            # êµ¬ë²„ì „ fallback (í•„ìš”í•œ ê²½ìš°)
            import openai
            openai.api_key = OPENAI_API_KEY
            return openai
        except ImportError:
            return None


def get_file_extension_and_mime(audio_data, source_type):
    """
    ì˜¤ë””ì˜¤ ë°ì´í„°ì˜ íŒŒì¼ í™•ì¥ìì™€ MIME íƒ€ì… ê²°ì •
    
    Args:
        audio_data: ì˜¤ë””ì˜¤ ë°ì´í„°
        source_type: "recording" ë˜ëŠ” "upload"
        
    Returns:
        tuple: (file_extension, mime_type)
    """
    if source_type == "upload" and hasattr(audio_data, 'name'):
        # ì—…ë¡œë“œëœ íŒŒì¼ì˜ ì›ë³¸ í™•ì¥ì ì¶”ì¶œ
        file_ext = os.path.splitext(audio_data.name)[1].lower()
        if not file_ext:
            file_ext = ".wav"  # í™•ì¥ìê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
    else:
        # ë§ˆì´í¬ ë…¹ìŒì€ ê¸°ë³¸ì ìœ¼ë¡œ wav
        file_ext = ".wav"
    
    # MIME íƒ€ì… ë§¤í•‘
    mime_types = {
        ".wav": "audio/wav",
        ".mp3": "audio/mp3",
        ".m4a": "audio/m4a", 
        ".flac": "audio/flac",
        ".ogg": "audio/ogg",
        ".webm": "audio/webm",
        ".mp4": "audio/mp4",
        ".mpeg": "audio/mpeg",
        ".mpga": "audio/mpeg",
        ".oga": "audio/ogg"
    }
    
    mime_type = mime_types.get(file_ext, "audio/wav")
    return file_ext, mime_type


def load_whisper():
    """
    API ë°©ì‹ì—ì„œëŠ” ëª¨ë¸ ë¡œë”©ì´ ë¶ˆí•„ìš”
    í˜¸í™˜ì„±ì„ ìœ„í•´ None ë°˜í™˜
    """
    return None


def transcribe_audio(audio_bytes, file_extension=".wav", source_type="recording", original_filename=None):
    """
    OpenAI API Whisperë¥¼ ì‚¬ìš©í•œ ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ í…ìŠ¤íŠ¸ ë³€í™˜ (ê°œì„ ëœ ë²„ì „)
    
    Args:
        audio_bytes: ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ë°”ì´íŠ¸ ë°ì´í„°
        file_extension: íŒŒì¼ í™•ì¥ì
        source_type: "recording" ë˜ëŠ” "upload"
        original_filename: ì›ë³¸ íŒŒì¼ëª… (ì—…ë¡œë“œ ì‹œ)
        
    Returns:
        tuple: (transcription_text, duration_seconds)
    """
    if not audio_bytes:
        return "", 0.0
    
    if not OPENAI_API_KEY:
        st.error("âŒ OpenAI API key is required for speech transcription!")
        return "", 0.0
    
    # ì›ë³¸ í™•ì¥ìë¥¼ ìœ ì§€í•˜ì—¬ ì„ì‹œ íŒŒì¼ ìƒì„±
    with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as tmp:
        tmp.write(audio_bytes)
        temp_path = tmp.name
    
    try:
        # ì•ˆì „í•œ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (proxies ì¶©ëŒ ë°©ì§€)
        client = get_openai_client()
        if not client:
            st.error("âŒ Failed to initialize OpenAI client")
            return "", 0.0
        
        # MIME íƒ€ì… ê²°ì •
        _, mime_type = get_file_extension_and_mime(None, source_type)
        if file_extension:
            mime_types = {
                ".wav": "audio/wav",
                ".mp3": "audio/mp3", 
                ".m4a": "audio/m4a",
                ".flac": "audio/flac",
                ".ogg": "audio/ogg",
                ".webm": "audio/webm"
            }
            mime_type = mime_types.get(file_extension, "audio/wav")
        
        # APIë¥¼ í†µí•œ ìŒì„± ì¸ì‹ ìˆ˜í–‰ (ê°œì„ ëœ ë°©ì‹)
        with open(temp_path, "rb") as audio_file:
            # íŒŒì¼ëª…ê³¼ MIME íƒ€ì…ì„ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
            filename = original_filename or f"audio{file_extension}"
            
            # OpenAI Whisper API í˜¸ì¶œ (íŠœí”Œ í˜•íƒœë¡œ íŒŒì¼ ì •ë³´ ì „ë‹¬)
            transcription = client.audio.transcriptions.create(
                model="whisper-1",
                file=(filename, audio_file, mime_type),
                language="ko",
                response_format="verbose_json"  # timestamp ì •ë³´ í¬í•¨
            )
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        transcription_text = transcription.text.strip()
        
        # ìŒì„± ê¸¸ì´ ê³„ì‚° (API ì‘ë‹µì—ì„œ duration ì¶”ì¶œ)
        duration = getattr(transcription, 'duration', None)
        if duration is None:
            # durationì´ ì—†ìœ¼ë©´ ì¶”ì •ê°’ ì‚¬ìš©
            duration = estimate_audio_duration(audio_bytes)
        
        return transcription_text, duration
        
    except Exception as e:
        error_msg = str(e)
        # ìƒì„¸í•œ ì—ëŸ¬ ë©”ì‹œì§€ ì œê³µ
        if "Invalid file format" in error_msg:
            st.error(f"âŒ File format error: {original_filename or 'audio file'}")
            st.info("ğŸ’¡ Try converting to MP3 or WAV format and upload again")
        elif "File not supported" in error_msg:
            st.error(f"âŒ File not supported: {file_extension}")
            st.info("ğŸ’¡ Supported formats: WAV, MP3, M4A, FLAC, OGG, WEBM")
        else:
            st.error(f"âŒ Transcription error: {error_msg}")
        return "", 0.0
    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        try:
            os.unlink(temp_path)
        except:
            pass


def estimate_audio_duration(audio_bytes):
    """
    ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ì—ì„œ ëŒ€ëµì ì¸ ê¸¸ì´ ì¶”ì •
    
    Args:
        audio_bytes: ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ë°ì´í„°
        
    Returns:
        float: ì¶”ì •ëœ ìŒì„± ê¸¸ì´ (ì´ˆ)
    """
    try:
        # WAV íŒŒì¼ ê¸°ì¤€ ì¶”ì • (16kHz, 16bit ê°€ì •)
        # ì‹¤ì œ ì •í™•í•œ ê¸¸ì´ëŠ” APIì—ì„œ ì œê³µí•˜ëŠ” duration ì‚¬ìš©
        estimated_duration = len(audio_bytes) / (16000 * 2)
        return max(estimated_duration, 1.0)  # ìµœì†Œ 1ì´ˆ
    except:
        return 1.0  # ê¸°ë³¸ê°’


def get_audio_quality_assessment(duration):
    """
    ìŒì„± ê¸¸ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í’ˆì§ˆ í‰ê°€ (60ì´ˆ ëª©í‘œ)
    
    Args:
        duration: ìŒì„± ê¸¸ì´ (ì´ˆ)
        
    Returns:
        dict: í’ˆì§ˆ í‰ê°€ ì •ë³´
    """
    from config import AUDIO_QUALITY
    
    if duration >= AUDIO_QUALITY["excellent_min_duration"]:  # 60ì´ˆ ì´ìƒ
        if duration <= AUDIO_QUALITY["max_recommended_duration"]:
            return {
                "status": "excellent",
                "icon": "âœ…",
                "message": f"Great! Your recording is {duration:.1f}s â€” perfect length for the interview!",
                "color": "success"
            }
        else:
            return {
                "status": "long",
                "icon": "ğŸ“",
                "message": f"Excellent! ({duration:.1f}s) Lots of content for the AI to work with!",
                "color": "info"
            }
    elif duration >= AUDIO_QUALITY["good_min_duration"]:  # 45-60ì´ˆ
        return {
            "status": "good",
            "icon": "ğŸŒŸ",
            "message": f"Good! ({duration:.1f}s) Try to reach 60+ seconds for an even better score.",
            "color": "info"
        }
    elif duration >= AUDIO_QUALITY["fair_min_duration"]:  # 30-45ì´ˆ
        return {
            "status": "fair",
            "icon": "âš ï¸",
            "message": f"Fair start! ({duration:.1f}s) Aim for 60+ seconds to show better fluency.",
            "color": "warning"
        }
    else:  # 30ì´ˆ ë¯¸ë§Œ
        return {
            "status": "very_short",
            "icon": "âŒ",
            "message": f"Too brief! ({duration:.1f}s) Please speak for at least 30+ seconds, ideally 60+ seconds.",
            "color": "error"
        }


def display_audio_quality_feedback(duration):
    """
    ìŒì„± ê¸¸ì´ì— ëŒ€í•œ í”¼ë“œë°±ì„ Streamlitì— í‘œì‹œ
    
    Args:
        duration: ìŒì„± ê¸¸ì´ (ì´ˆ)
    """
    assessment = get_audio_quality_assessment(duration)
    
    if assessment["color"] == "success":
        st.success(f"{assessment['icon']} {assessment['message']}")
    elif assessment["color"] == "info":
        st.info(f"{assessment['icon']} {assessment['message']}")
    elif assessment["color"] == "warning":
        st.warning(f"{assessment['icon']} {assessment['message']}")
    else:  # error
        st.error(f"{assessment['icon']} {assessment['message']}")


def validate_audio_file(uploaded_file):
    """
    ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬ (ê°„ë‹¨í•œ ê²€ì¦)
    
    Args:
        uploaded_file: Streamlit ì—…ë¡œë“œ íŒŒì¼ ê°ì²´
        
    Returns:
        tuple: (is_valid, error_message)
    """
    # OpenAI Whisper API ì§€ì› í˜•ì‹ (í™•ì¥ëœ ëª©ë¡)
    SUPPORTED_FORMATS = ["wav", "mp3", "m4a", "flac", "ogg", "webm", "mp4", "mpeg", "mpga", "oga"]
    
    if uploaded_file is None:
        return False, "No file uploaded"
    
    # íŒŒì¼ í™•ì¥ì í™•ì¸
    file_extension = uploaded_file.name.split('.')[-1].lower()
    if file_extension not in SUPPORTED_FORMATS:
        return False, f"âŒ Unsupported format '{file_extension}'. Supported: {', '.join(SUPPORTED_FORMATS)}"
    
    # íŒŒì¼ í¬ê¸° í™•ì¸ (OpenAI API ì œí•œ: 25MB)
    if uploaded_file.size > 25 * 1024 * 1024:
        return False, "âŒ File too large. Maximum size: 25MB (OpenAI API limit)"
    
    # ê¸°ë³¸ì ì¸ íŒŒì¼ í¬ê¸° ê²€ì¦ (ë„ˆë¬´ ì‘ì€ íŒŒì¼ ì œì™¸)
    if uploaded_file.size < 1024:  # 1KB ë¯¸ë§Œ
        return False, "âŒ File too small. Please upload a valid audio file"
    
    return True, "âœ… Valid audio file"


def process_audio_input(audio_data, source_type="recording"):
    """
    ì˜¤ë””ì˜¤ ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³  ì „ì‚¬ (OpenAI API ë°©ì‹, ê°œì„ ëœ ë²„ì „)
    
    Args:
        audio_data: ì˜¤ë””ì˜¤ ë°ì´í„° (ë…¹ìŒ ë˜ëŠ” ì—…ë¡œë“œ)
        source_type: ì…ë ¥ ì†ŒìŠ¤ íƒ€ì… ("recording" ë˜ëŠ” "upload")
        
    Returns:
        tuple: (transcription, duration, success)
    """
    try:
        if source_type == "upload":
            # ì—…ë¡œë“œëœ íŒŒì¼ ì²˜ë¦¬
            is_valid, error_msg = validate_audio_file(audio_data)
            if not is_valid:
                st.error(error_msg)
                return "", 0.0, False
            
            # ì›ë³¸ íŒŒì¼ ì •ë³´ ì¶”ì¶œ
            original_filename = audio_data.name
            file_ext = os.path.splitext(original_filename)[1].lower()
            
            audio_bytes = audio_data.read()
            audio_data.seek(0)  # í¬ì¸í„° ë¦¬ì…‹
        else:
            # ë…¹ìŒëœ ì˜¤ë””ì˜¤ ì²˜ë¦¬
            audio_bytes = audio_data['bytes']
            original_filename = "recording.wav"
            file_ext = ".wav"
        
        # OpenAI API ì „ì‚¬ ìˆ˜í–‰ (ê°œì„ ëœ ë²„ì „)
        with st.spinner("ğŸ™ï¸ Converting speech to text using OpenAI Whisper..."):
            transcription, duration = transcribe_audio(
                audio_bytes, 
                file_extension=file_ext,
                source_type=source_type,
                original_filename=original_filename
            )
        
        if transcription:
            st.success(f"âœ… Transcribed: {transcription}")
            display_audio_quality_feedback(duration)
            return transcription, duration, True
        else:
            st.error("âŒ Could not transcribe audio. Please try again.")
            return "", 0.0, False
            
    except Exception as e:
        st.error(f"âŒ Audio processing error: {str(e)}")
        return "", 0.0, False


def check_whisper_availability():
    """
    Whisper API ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    
    Returns:
        tuple: (is_available, status_message)
    """
    if not OPENAI_API_KEY:
        return False, "OpenAI API key not configured"
    
    try:
        # ì•ˆì „í•œ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” í™•ì¸
        client = get_openai_client()
        if client:
            return True, "OpenAI API Whisper ready"
        else:
            return False, "Failed to initialize OpenAI client"
    except Exception as e:
        return False, f"OpenAI client error: {str(e)}"


def display_whisper_status():
    """
    Whisper API ìƒíƒœë¥¼ ì‚¬ì´ë“œë°”ì— í‘œì‹œ
    """
    is_available, status = check_whisper_availability()
    
    if is_available:
        st.write("Speech Recognition: âœ… Ready (OpenAI API)")
    else:
        st.write(f"Speech Recognition: âŒ {status}")


def test_whisper_api():
    """
    Whisper API ì—°ê²° í…ŒìŠ¤íŠ¸ (ê°œë°œìš©)
    
    Returns:
        bool: í…ŒìŠ¤íŠ¸ ì„±ê³µ ì—¬ë¶€
    """
    try:
        # ì•ˆì „í•œ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
        client = get_openai_client()
        if client:
            return True
        else:
            return False
        
    except Exception as e:
        print(f"Whisper API test failed: {e}")
        return False