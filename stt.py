"""
stt.py
OpenAI API Whisperë¥¼ ì´ìš©í•œ ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ ëª¨ë“ˆ (íŒŒì¼ëª… ì ‘ê·¼ ìˆ˜ì • ë²„ì „)
"""

import tempfile
import os
import streamlit as st
from config import OPENAI_API_KEY


def detect_openai_version():
    """
    OpenAI SDK ë²„ì „ ê°ì§€
    
    Returns:
        str: "v1" (modern) ë˜ëŠ” "v0" (legacy)
    """
    try:
        import openai
        # v1.0.0+ ì—ì„œëŠ” openai.OpenAI í´ë˜ìŠ¤ê°€ ì¡´ì¬
        if hasattr(openai, 'OpenAI'):
            return "v1"
        else:
            return "v0"
    except ImportError:
        return None


def is_streamlit_cloud():
    """
    Streamlit Cloud í™˜ê²½ì¸ì§€ ì •í™•íˆ ê°ì§€ (ìˆ˜ì • ë²„ì „)
    
    Returns:
        bool: Streamlit Cloud ì—¬ë¶€
    """
    try:
        # ğŸ”¥ ë” ì •í™•í•œ Streamlit Cloud ê°ì§€
        cloud_indicators = [
            # í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ê°ì§€
            os.environ.get('STREAMLIT_CLOUD') == 'true',
            'streamlit.app' in os.environ.get('HOSTNAME', ''),
            'share.streamlit.io' in os.environ.get('HOSTNAME', ''),
            
            # secrets ì‹¤ì œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (ì¤‘ìš”!)
            hasattr(st, 'secrets') and _check_secrets_available()
        ]
        
        # ëª¨ë“  ì¡°ê±´ ì¤‘ í•˜ë‚˜ë¼ë„ ì¶©ì¡±ë˜ë©´ í´ë¼ìš°ë“œ
        return any(cloud_indicators)
    except:
        return False


def _check_secrets_available():
    """
    st.secretsê°€ ì‹¤ì œë¡œ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
    
    Returns:
        bool: secrets ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
    """
    try:
        # secretsì— ì‹¤ì œë¡œ ì ‘ê·¼í•´ë³´ê¸°
        _ = len(st.secrets)
        return True
    except:
        # secrets ì ‘ê·¼ ì‹¤íŒ¨ = ë¡œì»¬ í™˜ê²½
        return False


def get_openai_client():
    """
    OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (í™˜ê²½ ê°ì§€ ìˆ˜ì •)
    
    Returns:
        client: OpenAI í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ë˜ëŠ” None
    """
    if not OPENAI_API_KEY:
        return None
    
    version = detect_openai_version()
    
    if version == "v1":
        # ğŸ”¥ Modern SDK (v1.0.0+) ë°©ì‹
        try:
            from openai import OpenAI
            
            # ğŸ”¥ ìˆ˜ì •ëœ í™˜ê²½ ê°ì§€
            is_cloud = is_streamlit_cloud()
            
            if is_cloud:
                # Streamlit Cloud: proxies ë¬¸ì œ ëŒ€ì‘
                try:
                    return OpenAI(api_key=OPENAI_API_KEY)
                except TypeError as e:
                    if "proxies" in str(e):
                        # proxies ë¬¸ì œ ë°œìƒì‹œ í™˜ê²½ë³€ìˆ˜ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„
                        import openai
                        openai.api_key = OPENAI_API_KEY
                        return openai
                    raise e
            else:
                # ë¡œì»¬ í™˜ê²½: ì •ìƒì ì¸ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
                return OpenAI(api_key=OPENAI_API_KEY)
                
        except ImportError:
            return None
    
    elif version == "v0":
        # ğŸ”¥ Legacy SDK (v0.x) ë°©ì‹
        try:
            import openai
            openai.api_key = OPENAI_API_KEY
            return openai
        except ImportError:
            return None
    
    else:
        return None


def get_file_extension_and_mime(audio_data, source_type):
    """
    ì˜¤ë””ì˜¤ ë°ì´í„°ì˜ íŒŒì¼ í™•ì¥ìì™€ MIME íƒ€ì… ê²°ì •
    
    Args:
        audio_data: ì˜¤ë””ì˜¤ ë°ì´í„°
        source_type: "recording" ë˜ëŠ” "upload"
        
    Returns:
        tuple: (file_extension, mime_type)
    """
    if source_type == "upload":
        # ğŸ”¥ ì—…ë¡œë“œ íŒŒì¼ íŒŒì¼ëª… ì ‘ê·¼ ìˆ˜ì •
        if isinstance(audio_data, dict):
            # main.pyì—ì„œ ë³€í™˜ëœ ë”•ì…”ë„ˆë¦¬ í˜•íƒœ
            filename = audio_data.get('name', 'uploaded_file')
        else:
            # ì›ë³¸ UploadedFile ê°ì²´
            filename = getattr(audio_data, 'name', 'uploaded_file')
        
        # ì—…ë¡œë“œëœ íŒŒì¼ì˜ ì›ë³¸ í™•ì¥ì ì¶”ì¶œ
        file_ext = os.path.splitext(filename)[1].lower()
        if not file_ext:
            file_ext = ".wav"  # í™•ì¥ìê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
    else:
        # ë§ˆì´í¬ ë…¹ìŒì€ ê¸°ë³¸ì ìœ¼ë¡œ wav
        file_ext = ".wav"
    
    # MIME íƒ€ì… ë§¤í•‘
    mime_types = {
        ".wav": "audio/wav",
        ".mp3": "audio/mp3",
        ".m4a": "audio/m4a", 
        ".flac": "audio/flac",
        ".ogg": "audio/ogg",
        ".webm": "audio/webm",
        ".mp4": "audio/mp4",
        ".mpeg": "audio/mpeg",
        ".mpga": "audio/mpeg",
        ".oga": "audio/ogg"
    }
    
    mime_type = mime_types.get(file_ext, "audio/wav")
    return file_ext, mime_type


def load_whisper():
    """
    API ë°©ì‹ì—ì„œëŠ” ëª¨ë¸ ë¡œë”©ì´ ë¶ˆí•„ìš”
    í˜¸í™˜ì„±ì„ ìœ„í•´ None ë°˜í™˜
    """
    return None


def transcribe_audio_modern(client, temp_path, file_extension, original_filename):
    """
    Modern SDK (v1.0.0+)ë¥¼ ì‚¬ìš©í•œ ì „ì‚¬
    
    Args:
        client: OpenAI í´ë¼ì´ì–¸íŠ¸
        temp_path: ì„ì‹œ íŒŒì¼ ê²½ë¡œ
        file_extension: íŒŒì¼ í™•ì¥ì
        original_filename: ì›ë³¸ íŒŒì¼ëª…
        
    Returns:
        tuple: (transcription_text, duration)
    """
    with open(temp_path, "rb") as audio_file:
        filename = original_filename or f"audio{file_extension}"
        
        # Modern SDK API í˜¸ì¶œ
        transcription = client.audio.transcriptions.create(
            model="whisper-1",
            file=(filename, audio_file, f"audio/{file_extension[1:]}"),
            language="ko",
            response_format="verbose_json"
        )
    
    # í…ìŠ¤íŠ¸ ë° duration ì¶”ì¶œ
    transcription_text = transcription.text.strip()
    duration = getattr(transcription, 'duration', None)
    
    return transcription_text, duration


def transcribe_audio_legacy(client, temp_path):
    """
    Legacy SDK (v0.x)ë¥¼ ì‚¬ìš©í•œ ì „ì‚¬
    
    Args:
        client: OpenAI í´ë¼ì´ì–¸íŠ¸ (ëª¨ë“ˆ)
        temp_path: ì„ì‹œ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        tuple: (transcription_text, duration)
    """
    with open(temp_path, "rb") as audio_file:
        # Legacy SDK API í˜¸ì¶œ
        transcription = client.Audio.transcribe(
            model="whisper-1",
            file=audio_file,
            language="ko",
            response_format="verbose_json"
        )
    
    # í…ìŠ¤íŠ¸ ë° duration ì¶”ì¶œ
    if isinstance(transcription, dict):
        transcription_text = transcription.get('text', '').strip()
        duration = transcription.get('duration', None)
    else:
        transcription_text = str(transcription).strip()
        duration = None
    
    return transcription_text, duration


def transcribe_audio(audio_bytes, file_extension=".wav", source_type="recording", original_filename=None):
    """
    OpenAI API Whisperë¥¼ ì‚¬ìš©í•œ ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ í…ìŠ¤íŠ¸ ë³€í™˜ (í™˜ê²½ ê°ì§€ ìˆ˜ì •)
    
    Args:
        audio_bytes: ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ë°”ì´íŠ¸ ë°ì´í„°
        file_extension: íŒŒì¼ í™•ì¥ì
        source_type: "recording" ë˜ëŠ” "upload"
        original_filename: ì›ë³¸ íŒŒì¼ëª… (ì—…ë¡œë“œ ì‹œ)
        
    Returns:
        tuple: (transcription_text, duration_seconds)
    """
    if not audio_bytes:
        return "", 0.0
    
    if not OPENAI_API_KEY:
        st.error("âŒ OpenAI API key is required for speech transcription!")
        return "", 0.0
    
    # ì›ë³¸ í™•ì¥ìë¥¼ ìœ ì§€í•˜ì—¬ ì„ì‹œ íŒŒì¼ ìƒì„±
    with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as tmp:
        tmp.write(audio_bytes)
        temp_path = tmp.name
    
    try:
        # ğŸ”¥ í™˜ê²½ ê°ì§€ ë° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        client = get_openai_client()
        if not client:
            st.error("âŒ Failed to initialize OpenAI client")
            return "", 0.0
        
        # ğŸ”¥ í™˜ê²½ ì •ë³´ ì¶œë ¥ (ë””ë²„ê·¸ìš©)
        is_cloud = is_streamlit_cloud()
        version = detect_openai_version()
        
        print(f"ğŸ” Environment: {'Streamlit Cloud' if is_cloud else 'Local'}")
        print(f"ğŸ” OpenAI SDK: v{version}")
        print(f"ğŸ” API Key: {'âœ…' if OPENAI_API_KEY else 'âŒ'}")
        
        # SDK ë²„ì „ì— ë”°ë¥¸ API í˜¸ì¶œ
        if version == "v1":
            # Modern SDK ì‚¬ìš©
            transcription_text, duration = transcribe_audio_modern(
                client, temp_path, file_extension, original_filename
            )
        elif version == "v0":
            # Legacy SDK ì‚¬ìš©
            transcription_text, duration = transcribe_audio_legacy(
                client, temp_path
            )
        else:
            raise Exception("Unsupported OpenAI SDK version")
        
        # durationì´ ì—†ìœ¼ë©´ ì¶”ì •ê°’ ì‚¬ìš©
        if duration is None:
            duration = estimate_audio_duration(audio_bytes)
        
        return transcription_text, duration
        
    except Exception as e:
        error_msg = str(e)
        
        # ğŸ”¥ ìƒì„¸í•œ ì—ëŸ¬ ì²˜ë¦¬
        if "secrets" in error_msg.lower():
            st.error("âŒ Configuration error detected")
            st.info("ğŸ’¡ Please check your .env file contains OPENAI_API_KEY")
        elif "proxies" in error_msg.lower():
            st.error("âŒ Streamlit Cloud compatibility issue detected")
            st.info("ğŸ’¡ This is a known issue. Please try again.")
        elif "api_key" in error_msg.lower():
            st.error("âŒ Invalid OpenAI API key")
            st.info("ğŸ’¡ Please check your API key configuration")
        elif "quota" in error_msg.lower():
            st.error("âŒ OpenAI API quota exceeded")
            st.info("ğŸ’¡ Please check your OpenAI account usage")
        elif "timeout" in error_msg.lower():
            st.error("âŒ Request timeout - file may be too large")
            st.info("ğŸ’¡ Try with a shorter audio file (under 25MB)")
        elif "file" in error_msg.lower() and "format" in error_msg.lower():
            st.error(f"âŒ File format error: {original_filename or 'audio file'}")
            st.info("ğŸ’¡ Supported formats: WAV, MP3, M4A, FLAC, OGG, WEBM")
        else:
            st.error(f"âŒ Transcription error: {error_msg}")
            
        return "", 0.0
    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        try:
            os.unlink(temp_path)
        except:
            pass


def estimate_audio_duration(audio_bytes):
    """
    ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ì—ì„œ ëŒ€ëµì ì¸ ê¸¸ì´ ì¶”ì •
    
    Args:
        audio_bytes: ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ë°ì´í„°
        
    Returns:
        float: ì¶”ì •ëœ ìŒì„± ê¸¸ì´ (ì´ˆ)
    """
    try:
        # WAV íŒŒì¼ ê¸°ì¤€ ì¶”ì • (16kHz, 16bit ê°€ì •)
        estimated_duration = len(audio_bytes) / (16000 * 2)
        return max(estimated_duration, 1.0)  # ìµœì†Œ 1ì´ˆ
    except:
        return 1.0  # ê¸°ë³¸ê°’


def get_audio_quality_assessment(duration):
    """
    ìŒì„± ê¸¸ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í’ˆì§ˆ í‰ê°€ (1ë¶„~2ë¶„ ëª©í‘œë¡œ ìˆ˜ì •)
    
    Args:
        duration: ìŒì„± ê¸¸ì´ (ì´ˆ)
        
    Returns:
        dict: í’ˆì§ˆ í‰ê°€ ì •ë³´
    """
    from config import AUDIO_QUALITY
    
    TARGET_MIN_DURATION = 60  # 1ë¶„
    TARGET_MAX_DURATION = 120 # 2ë¶„

    if TARGET_MIN_DURATION <= duration <= TARGET_MAX_DURATION:
        return {
            "status": "excellent",
            "icon": "âœ…",
            "message": f"Excellent! Your recording is {duration:.1f}s â€” a perfect length (1-2 minutes) for the interview!",
            "color": "success"
        }
    elif duration > TARGET_MAX_DURATION:
        return {
            "status": "long",
            "icon": "ğŸ“",
            "message": f"Great! ({duration:.1f}s) You've provided plenty of content",
            "color": "info"
        }
    elif duration >= AUDIO_QUALITY["good_min_duration"]:  # config.pyì˜ "good_min_duration" ê°’ì— ë”°ë¼ 1ë¶„ ë¯¸ë§Œì´ì§€ë§Œ ì–‘í˜¸í•œ ë²”ìœ„
        return {
            "status": "good",
            "icon": "ğŸŒŸ",
            "message": f"Good start! ({duration:.1f}s) Aim for 1-2 minutes for best results.",
            "color": "info"
        }
    elif duration >= AUDIO_QUALITY["fair_min_duration"]:  # config.pyì˜ "fair_min_duration" ê°’ì— ë”°ë¼ ë‹¤ì†Œ ì§§ì€ ë²”ìœ„
        return {
            "status": "fair",
            "icon": "âš ï¸",
            "message": f"Fair start! ({duration:.1f}s) Aim for 1-2 minutes to show better fluency.",
            "color": "warning"
        }
    else:  # ìµœì†Œ ê¸¸ì´ ë¯¸ë§Œ
        return {
            "status": "very_short",
            "icon": "âŒ",
            "message": f"Too brief! ({duration:.1f}s) Please speak for at least 1 minute, ideally 60â€“120 seconds.",
            "color": "error"
        }


def display_audio_quality_feedback(duration):
    """
    ìŒì„± ê¸¸ì´ì— ëŒ€í•œ í”¼ë“œë°±ì„ Streamlitì— í‘œì‹œ
    
    Args:
        duration: ìŒì„± ê¸¸ì´ (ì´ˆ)
    """
    assessment = get_audio_quality_assessment(duration)
    
    if assessment["color"] == "success":
        st.success(f"{assessment['icon']} {assessment['message']}")
    elif assessment["color"] == "info":
        st.info(f"{assessment['icon']} {assessment['message']}")
    elif assessment["color"] == "warning":
        st.warning(f"{assessment['icon']} {assessment['message']}")
    else:  # error
        st.error(f"{assessment['icon']} {assessment['message']}")


def validate_audio_file(uploaded_file):
    """
    ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬
    
    Args:
        uploaded_file: Streamlit ì—…ë¡œë“œ íŒŒì¼ ê°ì²´ ë˜ëŠ” ë”•ì…”ë„ˆë¦¬
        
    Returns:
        tuple: (is_valid, error_message)
    """
    # OpenAI Whisper API ì§€ì› í˜•ì‹
    SUPPORTED_FORMATS = ["wav", "mp3", "m4a", "flac", "ogg", "webm", "mp4", "mpeg", "mpga", "oga"]
    
    if uploaded_file is None:
        return False, "No file uploaded"
    
    # ğŸ”¥ íŒŒì¼ëª… ì ‘ê·¼ ìˆ˜ì •
    if isinstance(uploaded_file, dict):
        # main.pyì—ì„œ ë³€í™˜ëœ ë”•ì…”ë„ˆë¦¬ í˜•íƒœ
        filename = uploaded_file.get('name', 'uploaded_file')
        file_size = len(uploaded_file.get('bytes', b''))
    else:
        # ì›ë³¸ UploadedFile ê°ì²´
        filename = getattr(uploaded_file, 'name', 'uploaded_file')
        file_size = getattr(uploaded_file, 'size', 0)
    
    # íŒŒì¼ í™•ì¥ì í™•ì¸
    file_extension = filename.split('.')[-1].lower()
    if file_extension not in SUPPORTED_FORMATS:
        return False, f"âŒ Unsupported format '{file_extension}'. Supported: {', '.join(SUPPORTED_FORMATS)}"
    
    # íŒŒì¼ í¬ê¸° í™•ì¸ (OpenAI API ì œí•œ: 25MB)
    if file_size > 25 * 1024 * 1024:
        return False, "âŒ File too large. Maximum size: 25MB (OpenAI API limit)"
    
    # ê¸°ë³¸ì ì¸ íŒŒì¼ í¬ê¸° ê²€ì¦
    if file_size < 1024:  # 1KB ë¯¸ë§Œ
        return False, "âŒ File too small. Please upload a valid audio file"
    
    return True, "âœ… Valid audio file"


def process_audio_input(audio_data, source_type="recording"):
    """
    ì˜¤ë””ì˜¤ ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³  ì „ì‚¬ (íŒŒì¼ëª… ì ‘ê·¼ ìˆ˜ì •)
    
    Args:
        audio_data: ì˜¤ë””ì˜¤ ë°ì´í„° (ë…¹ìŒ ë˜ëŠ” ì—…ë¡œë“œ - ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” ì›ë³¸ ê°ì²´)
        source_type: ì…ë ¥ ì†ŒìŠ¤ íƒ€ì… ("recording" ë˜ëŠ” "upload")
        
    Returns:
        tuple: (transcription, duration, success)
    """
    try:
        if source_type == "upload":
            # ì—…ë¡œë“œëœ íŒŒì¼ ì²˜ë¦¬
            is_valid, error_msg = validate_audio_file(audio_data)
            if not is_valid:
                st.error(error_msg)
                return "", 0.0, False
            
            # ğŸ”¥ íŒŒì¼ëª… ì ‘ê·¼ ìˆ˜ì • - ë”•ì…”ë„ˆë¦¬ì™€ ì›ë³¸ ê°ì²´ ëª¨ë‘ ì²˜ë¦¬
            if isinstance(audio_data, dict):
                # main.pyì—ì„œ ë³€í™˜ëœ ë”•ì…”ë„ˆë¦¬ í˜•íƒœ
                original_filename = audio_data.get('name', 'uploaded_file')
                audio_bytes = audio_data.get('bytes', b'')
            else:
                # ì›ë³¸ UploadedFile ê°ì²´ (í˜¹ì‹œ ë³€í™˜ ì•ˆ ëœ ê²½ìš°)
                original_filename = getattr(audio_data, 'name', 'uploaded_file')
                audio_bytes = audio_data.read()
                audio_data.seek(0)  # í¬ì¸í„° ë¦¬ì…‹
            
            file_ext = os.path.splitext(original_filename)[1].lower()
        else:
            # ë…¹ìŒëœ ì˜¤ë””ì˜¤ ì²˜ë¦¬
            audio_bytes = audio_data['bytes']
            original_filename = "recording.wav"
            file_ext = ".wav"
        
        # ğŸ”¥ í™˜ê²½ ì •ë³´ í‘œì‹œ
        is_cloud = is_streamlit_cloud()
        version = detect_openai_version()
        env_info = f"{'Streamlit Cloud' if is_cloud else 'Local'} + OpenAI SDK v{version}"
        
        with st.spinner(f"ğŸ™ï¸ Converting speech to text ..."):
            transcription, duration = transcribe_audio(
                audio_bytes, 
                file_extension=file_ext,
                source_type=source_type,
                original_filename=original_filename
            )
        
        if transcription:
            st.success(f"âœ… Transcribed: {transcription}")
            display_audio_quality_feedback(duration)
            return transcription, duration, True
        else:
            st.error("âŒ Could not transcribe audio. Please try again.")
            return "", 0.0, False
            
    except Exception as e:
        error_msg = str(e)
        st.error(f"âŒ Audio processing error: {error_msg}")
        return "", 0.0, False


def check_whisper_availability():
    """
    Whisper API ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ (í™˜ê²½ ê°ì§€ ìˆ˜ì •)
    
    Returns:
        tuple: (is_available, status_message)
    """
    if not OPENAI_API_KEY:
        return False, "OpenAI API key not configured"
    
    try:
        client = get_openai_client()
        version = detect_openai_version()
        is_cloud = is_streamlit_cloud()
        
        if client and version:
            env_info = f"{'Cloud' if is_cloud else 'Local'} + SDK v{version}"
            return True, f"OpenAI API Whisper ready"
        else:
            return False, "Failed to initialize OpenAI client"
    except Exception as e:
        return False, f"OpenAI client error: {str(e)}"


def display_whisper_status():
    """
    Whisper API ìƒíƒœë¥¼ ì‚¬ì´ë“œë°”ì— í‘œì‹œ (í™˜ê²½ ì •ë³´ í¬í•¨)
    """
    is_available, status = check_whisper_availability()
    
    if is_available:
        st.write(f"Speech Recognition: âœ… Ready ({status})")
    else:
        st.write(f"Speech Recognition: âŒ {status}")


def test_whisper_api():
    """
    Whisper API ì—°ê²° í…ŒìŠ¤íŠ¸ (í™˜ê²½ ê°ì§€ ìˆ˜ì •)
    
    Returns:
        bool: í…ŒìŠ¤íŠ¸ ì„±ê³µ ì—¬ë¶€
    """
    try:
        client = get_openai_client()
        version = detect_openai_version()
        
        if client and version:
            return True
        else:
            return False
        
    except Exception as e:
        print(f"Whisper API test failed: {e}")
        return False